{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training a Cursive Transformer\n",
        "Sam Greydanus | 2024"
      ],
      "metadata": {
        "id": "y3v2biu1Ttg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip -q install wandb\n",
        "! wandb login"
      ],
      "metadata": {
        "id": "0QvXUjGZHl7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97ae1eba-1b1a-4504-d31f-8ffe0e5640e0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.2/300.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage import rotate\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.colab import files\n",
        "import os, sys, time, math, argparse, io, copy, json, pdb\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "from math import comb\n",
        "\n",
        "import wandb\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Try attaching to GPU\n",
        "DEVICE = str(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
        "print('Using:', DEVICE)"
      ],
      "metadata": {
        "id": "g0WRHSM_Kksp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd4d072-d7b7-4e22-dd6b-02df759cc98b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing and Tokenization"
      ],
      "metadata": {
        "id": "FxM2-WQjBJ8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_strokes(stroke, title, fig=None, ax=None):\n",
        "    \"\"\"Plot a single stroke\"\"\"\n",
        "    if fig is None or ax is None:\n",
        "        fig, ax = plt.subplots(figsize=(12, 2))\n",
        "\n",
        "    # Separate strokes based on pen lifts\n",
        "    strokes = []\n",
        "    current_stroke = []\n",
        "    for point in stroke:\n",
        "        if point[2] == 1:  # Pen is down\n",
        "            current_stroke.append(point)\n",
        "        else:  # Pen is up\n",
        "            if current_stroke:\n",
        "                strokes.append(current_stroke)\n",
        "                current_stroke = []\n",
        "    if current_stroke:\n",
        "        strokes.append(current_stroke)\n",
        "\n",
        "    # Plot each stroke\n",
        "    for stroke in strokes:\n",
        "        x, y = zip(*[(p[0], 1 - p[1]) for p in stroke])  # Invert y-axis\n",
        "        ax.plot(x, y, 'b-')\n",
        "\n",
        "    ax.set_aspect('equal') ; ax.set_title(title)\n",
        "\n",
        "    if fig is None:\n",
        "        plt.show()\n",
        "\n",
        "    return fig, ax\n",
        "\n",
        "def load_and_parse_data(min_ascii_length=3):\n",
        "    uploaded = files.upload()\n",
        "    file_content = next(iter(uploaded.values()))\n",
        "    data = json.loads(file_content.decode('utf-8'))\n",
        "    for i in range(len(data)):\n",
        "      strokes = np.array(data[i]['points'])\n",
        "      strokes[:,0:1] *= data[i]['metadata']['aspectRatio']\n",
        "      strokes[:, 0] -= strokes[0, 0]\n",
        "      data[i]['points'] = strokes\n",
        "    data = [d for d in data if len(d['metadata']['asciiSequence']) >= min_ascii_length]\n",
        "    return data\n",
        "\n",
        "# data = load_and_parse_data()\n",
        "# print(len(data))"
      ],
      "metadata": {
        "id": "kfFC9VAC3oPz"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_handwriting_examples(examples, space_width=0.17):\n",
        "    assert len(set(ex['metadata']['author'] for ex in examples)) == 1, \"All examples must have the same author\"\n",
        "\n",
        "    combined_metadata = {\n",
        "        'author': examples[0]['metadata']['author'],\n",
        "        'asciiSequence': ' '.join(ex['metadata']['asciiSequence'] for ex in examples),\n",
        "        'pointCount': sum(ex['metadata']['pointCount'] for ex in examples),\n",
        "        'strokeCount': sum(ex['metadata']['strokeCount'] for ex in examples),\n",
        "        'aspectRatio': examples[0]['metadata']['aspectRatio']\n",
        "    }\n",
        "\n",
        "    combined_points, current_x_offset, total_width = [], 0, 0\n",
        "\n",
        "    for i, example in enumerate(examples):\n",
        "        points = example['points']\n",
        "        word_width = np.max(points[:, 0]) - np.min(points[:, 0])\n",
        "        total_width += word_width\n",
        "\n",
        "        normalized_points = points.copy()\n",
        "        normalized_points[:, 0] -= np.min(points[:, 0])\n",
        "        normalized_points[:, 0] += current_x_offset\n",
        "\n",
        "        combined_points.append(normalized_points)\n",
        "        current_x_offset += word_width\n",
        "\n",
        "        if i < len(examples) - 1:\n",
        "            combined_points.append(np.array([[current_x_offset + space_width, normalized_points[-1, 1], 0]]))\n",
        "            current_x_offset += space_width\n",
        "            total_width += space_width\n",
        "            combined_metadata['pointCount'] += 1\n",
        "\n",
        "    combined_points = np.vstack(combined_points)\n",
        "    return {'metadata': combined_metadata, 'points': combined_points}\n",
        "\n",
        "def generate_word_combos(raw_json, desired_num_combos=10000, num_words=3):\n",
        "  num_combos = comb(len(raw_json), num_words)\n",
        "  print(f'For a dataset of {len(raw_json)} examples we can generate {num_combos} combinations of {num_words} examples.')\n",
        "  print(f'Generating {desired_num_combos} random (and thus possibly overlapping) combos...')\n",
        "  combo_json = []\n",
        "  for i in range(desired_num_combos):\n",
        "    ixs = np.random.choice(len(raw_json), size=num_words, replace=False)\n",
        "    words_to_merge = [raw_json[i] for i in ixs]\n",
        "    combo_json.append( combine_handwriting_examples(words_to_merge) )\n",
        "  return combo_json\n",
        "\n",
        "def load_and_combine_examples(examples, desired_num_combos=10000, num_words=3):\n",
        "  data = load_and_parse_data()\n",
        "  return generate_word_combos(data, desired_num_combos, num_words)"
      ],
      "metadata": {
        "id": "4jHeGQgJnxaZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# combo_json = load_and_combine_examples()\n",
        "# combo = combo_json[0]\n",
        "# print(len(combo['points']))\n",
        "# _ = plot_strokes(combo['points'], title=combo['metadata']['asciiSequence'])"
      ],
      "metadata": {
        "id": "vI1DBe7bnxcp"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "OobnYMcDKf78"
      },
      "outputs": [],
      "source": [
        "def decompose_offsets(offsets, eps=1e-8):\n",
        "    magnitudes = np.linalg.norm(offsets[:, :2], axis=1, keepdims=True)  # Calculate magnitudes of vectors\n",
        "    unit_vectors = np.where(magnitudes == 0, np.zeros_like(offsets[:, :2]), offsets[:, :2] / (eps+magnitudes))  # Avoid division by zero\n",
        "    new_format = np.hstack((unit_vectors, magnitudes, offsets[:, 2:3]))  # Concatenate unit vectors, magnitudes and pen_down flags\n",
        "    return new_format\n",
        "\n",
        "def reconstruct_offsets(decomposed_data):\n",
        "    unit_vectors = decomposed_data[:, :2]\n",
        "    magnitudes = decomposed_data[:, 2:3]\n",
        "    pen_down = decomposed_data[:, 3:4]\n",
        "    reconstructed_offsets = unit_vectors * magnitudes  # Multiply unit vector components by magnitudes\n",
        "    reconstructed_data = np.hstack((reconstructed_offsets, pen_down))  # Concatenate the reconstructed offsets with pen_down flags\n",
        "    return reconstructed_data\n",
        "\n",
        "def strokes_to_offsets(points):\n",
        "    # Calculate differences (dx, dy), not considering pen_down\n",
        "    offsets = np.zeros_like(points)\n",
        "    offsets[1:, 0:2] = np.diff(points[:, 0:2], axis=0)  # Compute dx, dy\n",
        "    offsets[:, 2] = points[:, 2]  # Copy pen_down directly\n",
        "\n",
        "    # Decouple direction from magnitude (this will help with tokenization)\n",
        "    offsets_dec = decompose_offsets(offsets)\n",
        "    return offsets_dec\n",
        "\n",
        "def offsets_to_strokes(offsets_dec):\n",
        "    # Calculate cumulative sums to get absolute positions\n",
        "    offsets = reconstruct_offsets(offsets_dec)\n",
        "\n",
        "    absolute_coords = np.cumsum(offsets[:, :2], axis=0)\n",
        "    stroke_data = np.hstack((absolute_coords, offsets[:, 2:3]))\n",
        "    return stroke_data\n",
        "\n",
        "def horizontal_shear(stroke, shear_range=(-0.4, 0.4)):\n",
        "    shear_factor = np.random.uniform(*shear_range)\n",
        "    shear_matrix = np.array([\n",
        "        [1, shear_factor],\n",
        "        [0, 1]])\n",
        "    stroke[:, :2] = np.dot(stroke[:, :2], shear_matrix.T)\n",
        "    return stroke\n",
        "\n",
        "def remove_random_points(stroke, remove_percentage=0.04):\n",
        "    num_points = np.random.randint(len(stroke))\n",
        "    num_remove = int(num_points * remove_percentage)\n",
        "    indices = np.random.choice(range(1, num_points - 1), num_remove, replace=False).astype(np.int32)\n",
        "    return np.delete(stroke, indices, axis=0)\n",
        "\n",
        "def downsample(arr, fraction):\n",
        "    if not 0 <= fraction <= 1:\n",
        "        raise ValueError(\"Fraction must be between 0 and 1\")\n",
        "    if fraction == 1:\n",
        "        return arr\n",
        "    new_length = int(len(arr) * (1 - fraction))\n",
        "    indices = np.linspace(0, len(arr) - 1, new_length, dtype=int)\n",
        "    return arr[indices]\n",
        "\n",
        "\n",
        "class StrokeDataset(Dataset):\n",
        "    def __init__(self, strokes, texts, chars, max_seq_length=None, max_text_length=None, name='', augment=False):\n",
        "        self.name = name\n",
        "        self.strokes = strokes  # List of Nx4 arrays, each representing a cursive sentence\n",
        "        self.texts = texts  # List of corresponding text strings\n",
        "        self.chars = chars  # String of all possible characters\n",
        "        self.augment = augment\n",
        "\n",
        "        self.dx_bins = np.linspace(-1, 1, 101)  # 200 bins\n",
        "        self.dy_bins = np.linspace(-1, 1, 151)  # 200 bins\n",
        "\n",
        "        # Modify mag_bins to incorporate pen_down information\n",
        "        mag_bins_pen_down = np.concatenate([\n",
        "            np.asarray([0]),\n",
        "            np.linspace(0.005, 0.050, 40),  # Close around 0.01, 30 bins\n",
        "            np.geomspace(0.051, 4, 61)[:-1]  # 150 exponential bins\n",
        "        ])\n",
        "        mag_bins_pen_up = mag_bins_pen_down + max(mag_bins_pen_down) + 1  # Offset for pen-up states\n",
        "        self.mag_bins = np.concatenate([mag_bins_pen_down, mag_bins_pen_up])\n",
        "\n",
        "        self.feature_sizes = [len(self.dx_bins), len(self.dy_bins), len(self.mag_bins)]\n",
        "        self.cumulative_sizes = np.cumsum([0] + self.feature_sizes)\n",
        "\n",
        "        # Add special tokens for strokes\n",
        "        self.PAD_TOKEN = sum(self.feature_sizes)\n",
        "        self.END_TOKEN = sum(self.feature_sizes) + 1\n",
        "\n",
        "        # Character tokenization\n",
        "        self.stoi = {ch:i+1 for i,ch in enumerate(chars)}\n",
        "        self.itos = {i:s for s,i in self.stoi.items()}\n",
        "        self.char_PAD_TOKEN = 0\n",
        "\n",
        "        if max_seq_length is None:\n",
        "            self.max_seq_length = max(len(stroke) for stroke in strokes) * 3 + 1  # *3 for unraveling, +1 for END token\n",
        "        else:\n",
        "            self.max_seq_length = max_seq_length\n",
        "\n",
        "        if max_text_length is None:\n",
        "            self.max_text_length = max(len(text) for text in texts)\n",
        "        else:\n",
        "            self.max_text_length = max_text_length\n",
        "\n",
        "    def augment_stroke(self, stroke):\n",
        "\n",
        "        stroke = remove_random_points(stroke, remove_percentage=0.03) # Drop some points\n",
        "        stroke = horizontal_shear(stroke, shear_range=(-0.3, 0.3)) # Horizontal shear\n",
        "\n",
        "        stroke[:, 0:1] *= np.random.uniform(0.8, 1.2)\n",
        "        stroke[:, 1:2] *= np.random.uniform(0.8, 1.2)\n",
        "\n",
        "        noise = np.random.normal(0, 0.001, stroke[:, :2].shape) # Random noise\n",
        "        stroke[:, :2] += noise\n",
        "\n",
        "        angle = np.random.uniform(-3, 3) # Random rotation\n",
        "        rad = np.deg2rad(angle)\n",
        "        rotation_matrix = np.array([\n",
        "            [np.cos(rad), -np.sin(rad)],\n",
        "             [np.sin(rad), np.cos(rad)]])\n",
        "        stroke[:, :2] = np.dot(stroke[:, :2], rotation_matrix.T)\n",
        "\n",
        "        # Random starting point\n",
        "        stroke = stroke[np.random.randint(1, 8):-np.random.randint(1, 8)]\n",
        "\n",
        "        # Downsample stroke\n",
        "        stroke[1:,2:3] *= stroke[:-1,2:3] # pen_up will now always come in sets of 3+\n",
        "        stroke[2:,2:3] *= stroke[:-2,2:3]\n",
        "        stroke = downsample(stroke, .65) # stroke[::2]\n",
        "        return stroke\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.strokes)\n",
        "\n",
        "    def get_vocab_size(self):\n",
        "        return sum(self.feature_sizes) + 2  # +2 for PAD and END tokens\n",
        "\n",
        "    def get_char_vocab_size(self):\n",
        "        return len(self.chars) + 1  # +1 for PAD token\n",
        "\n",
        "    def get_output_length(self):\n",
        "        return self.max_seq_length\n",
        "\n",
        "    def encode_stroke(self, stroke):\n",
        "        dx_idx = np.digitize(stroke[:, 0], self.dx_bins) - 1\n",
        "        dy_idx = np.digitize(stroke[:, 1], self.dy_bins) - 1\n",
        "\n",
        "        # Encode magnitude and pen state together\n",
        "        mag_idx = np.digitize(stroke[:, 2], self.mag_bins[:len(self.mag_bins)//2]) - 1\n",
        "        mag_idx[stroke[:, 3] == 0] += len(self.mag_bins) // 2  # Offset for pen-up states\n",
        "\n",
        "        encoded = np.column_stack([\n",
        "            dx_idx + self.cumulative_sizes[0],\n",
        "            dy_idx + self.cumulative_sizes[1],\n",
        "            mag_idx + self.cumulative_sizes[2]\n",
        "        ])\n",
        "        return encoded.flatten()\n",
        "\n",
        "    def decode_stroke(self, ix):\n",
        "        if isinstance(ix, torch.Tensor):\n",
        "            ix = ix.cpu().numpy()\n",
        "\n",
        "        # Remove PAD and END tokens\n",
        "        ix = ix[(ix != self.PAD_TOKEN) & (ix != self.END_TOKEN)]\n",
        "\n",
        "        # Reshape the flattened array back to Nx3\n",
        "        ix = ix[:(len(ix)//3)*3]\n",
        "        ix = ix.reshape(-1, 3)\n",
        "\n",
        "        dx = self.dx_bins[(ix[:, 0] - self.cumulative_sizes[0]).clip(0, len(self.dx_bins)-1)]\n",
        "        dy = self.dy_bins[(ix[:, 1] - self.cumulative_sizes[1]).clip(0, len(self.dy_bins)-1)]\n",
        "\n",
        "        mag_idx = ix[:, 2] - self.cumulative_sizes[2]\n",
        "        pen = (mag_idx < len(self.mag_bins) // 2).astype(int)\n",
        "        mag_idx[pen == 0] -= len(self.mag_bins) // 2\n",
        "        mag = self.mag_bins[:len(self.mag_bins)//2][mag_idx.clip(0, len(self.mag_bins)//2 - 1)]\n",
        "\n",
        "        return np.column_stack([dx, dy, mag, pen])\n",
        "\n",
        "    def encode_text(self, text):\n",
        "        return torch.tensor([self.stoi.get(ch, self.char_PAD_TOKEN) for ch in text], dtype=torch.long)\n",
        "\n",
        "    def decode_text(self, ix):\n",
        "        if isinstance(ix, torch.Tensor):\n",
        "            ix = ix.cpu().numpy()\n",
        "        return ''.join([self.itos.get(i, '') for i in ix if i != self.char_PAD_TOKEN])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        stroke = self.strokes[idx]\n",
        "        text = self.texts[idx]\n",
        "\n",
        "        if self.augment:\n",
        "          stroke = self.augment_stroke(stroke.copy())\n",
        "\n",
        "        # Encode stroke\n",
        "        stroke_offsets = strokes_to_offsets(stroke)\n",
        "        encoded_stroke = self.encode_stroke(stroke_offsets)\n",
        "        x = torch.full((self.max_seq_length,), self.PAD_TOKEN, dtype=torch.long)\n",
        "        y = torch.full((self.max_seq_length,), self.PAD_TOKEN, dtype=torch.long)\n",
        "\n",
        "        seq_len = min(len(encoded_stroke), self.max_seq_length - 1)  # -1 to leave room for END token\n",
        "        x[:seq_len] = torch.tensor(encoded_stroke[:seq_len], dtype=torch.long)\n",
        "        x[seq_len] = self.END_TOKEN\n",
        "\n",
        "        y[:seq_len] = x[1:seq_len+1]\n",
        "        y[seq_len] = self.END_TOKEN\n",
        "\n",
        "        # Encode text (context)\n",
        "        encoded_text = self.encode_text(text)\n",
        "        c = torch.full((self.max_text_length,), self.char_PAD_TOKEN, dtype=torch.long)\n",
        "        text_len = min(len(encoded_text), self.max_text_length)\n",
        "        c[:text_len] = encoded_text[:text_len]\n",
        "\n",
        "        return x, c, y\n",
        "\n",
        "\n",
        "def create_datasets(augment=True, max_seq_length=1100, num_words=3):\n",
        "  raw_json = load_and_parse_data()\n",
        "\n",
        "  # partition the input data into a training and the test set\n",
        "  test_set_size = min(1000, int(len(raw_json) * 0.20)) # 10% of the training set, or up to 1000 examples\n",
        "  rp = torch.randperm(len(raw_json)).tolist()\n",
        "  train_examples = [raw_json[i] for i in rp[:-test_set_size]]\n",
        "  test_examples = [raw_json[i] for i in rp[-test_set_size:]]\n",
        "\n",
        "  train_examples = generate_word_combos(train_examples, desired_num_combos=9000, num_words=num_words)\n",
        "  test_examples = generate_word_combos(test_examples, desired_num_combos=1000, num_words=num_words)\n",
        "\n",
        "  train_strokes = [copy.deepcopy(v['points']) for v in train_examples]\n",
        "  train_texts = [copy.deepcopy(v['metadata']['asciiSequence']) for v in train_examples]\n",
        "\n",
        "  test_strokes = [copy.deepcopy(v['points']) for v in test_examples]\n",
        "  test_texts = [copy.deepcopy(v['metadata']['asciiSequence']) for v in test_examples]\n",
        "\n",
        "  chars = \"abcdefghijklmnopqrstuvwxyz \"\n",
        "  print(f\"Number of examples in the train dataset: {len(train_examples)}\")\n",
        "  print(f\"Number of examples in the test dataset: {len(test_examples)}\")\n",
        "  print(f\"Max token sequence length: {max_seq_length}\")\n",
        "  print(f\"Number of unique characters in the ascii vocabulary: {len(chars)}\")\n",
        "  print(\"Ascii vocabulary:\")\n",
        "  print(f'\\t\"{chars}\"')\n",
        "\n",
        "  print(f\"Split up the dataset into {len(train_examples)} training examples and {len(test_examples)} test examples\")\n",
        "\n",
        "  # wrap in dataset objects\n",
        "  train_dataset = StrokeDataset(train_strokes, train_texts, chars, max_seq_length, name='train', augment=augment)\n",
        "  test_dataset = StrokeDataset(test_strokes, test_texts, chars, max_seq_length, name='test', augment=augment)\n",
        "  return train_dataset, test_dataset\n",
        "\n",
        "\n",
        "class InfiniteDataLoader:\n",
        "    \"\"\"\n",
        "    this is really hacky and I'm not proud of it, but there doesn't seem to be\n",
        "    a better way in PyTorch to just create an infinite dataloader?\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, dataset, **kwargs):\n",
        "        train_sampler = torch.utils.data.RandomSampler(dataset, replacement=True, num_samples=int(1e10))\n",
        "        self.train_loader = DataLoader(dataset, sampler=train_sampler, **kwargs)\n",
        "        self.data_iter = iter(self.train_loader)\n",
        "\n",
        "    def next(self):\n",
        "        try:\n",
        "            batch = next(self.data_iter)\n",
        "        except StopIteration: # this will technically only happen after 1e10 samples... (i.e. basically never)\n",
        "            self.data_iter = iter(self.train_loader)\n",
        "            batch = next(self.data_iter)\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset, _ = create_datasets(augment=True, max_seq_length=1100, num_words=3)"
      ],
      "metadata": {
        "id": "pRH6-roo_bZQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "outputId": "116b4359-3e11-48b9-cdc1-3b37a2ff2780"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-7a090a69-e2ba-4e0d-95d8-2572cfa32e0e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-7a090a69-e2ba-4e0d-95d8-2572cfa32e0e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 0100-bigbank.json to 0100-bigbank (14).json\n",
            "For a dataset of 148 examples we can generate 529396 combinations of 3 examples.\n",
            "Generating 9000 random (and thus possibly overlapping) combos...\n",
            "For a dataset of 37 examples we can generate 7770 combinations of 3 examples.\n",
            "Generating 1000 random (and thus possibly overlapping) combos...\n",
            "Number of examples in the train dataset: 9000\n",
            "Number of examples in the test dataset: 1000\n",
            "Max token sequence length: 1100\n",
            "Number of unique characters in the ascii vocabulary: 27\n",
            "Ascii vocabulary:\n",
            "\t\"abcdefghijklmnopqrstuvwxyz \"\n",
            "Split up the dataset into 9000 training examples and 1000 test examples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "example_ix = 14\n",
        "x1, c1, y1 = dataset[example_ix]  # Get tokenized version of the second example\n",
        "x2, c2, y2 = dataset[example_ix]\n",
        "\n",
        "o1 = dataset.decode_stroke(x1)\n",
        "r1 = offsets_to_strokes(o1)\n",
        "fig, ax = plot_strokes(r1, title='Reconstructed text (data augmentation seed 1)')\n",
        "\n",
        "o2 = dataset.decode_stroke(x2)\n",
        "print(o2.shape[0]*3)\n",
        "r2 = offsets_to_strokes(o2)\n",
        "fig, ax = plot_strokes(r2, title='Reconstructed from tokens (data augmentation seed 2)')"
      ],
      "metadata": {
        "id": "OwL8_iYoEmSP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "6c3237a8-9cf8-418f-96a8-dfdf88f1f126"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "945\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_stroke = o2#dataset.decode_stroke(x)\n",
        "decoded_text = c1 #dataset.decode_text(c)\n",
        "\n",
        "print(\"Original stroke shape:\", (1082,3))\n",
        "print(\"Encoded stroke shape:\", x1.shape)\n",
        "print(\"Encoded text shape:\", c1.shape)\n",
        "print(\"Decoded stroke shape:\", decoded_stroke.shape)\n",
        "\n",
        "print(\"\\nEncoded strokes (first 15 tokens, aka 5 pen strokes):\")\n",
        "print([v.item() for v in x1[:15]])\n",
        "print(\"\\n\\nEncoded text (first 10 tokens, aka ascii chars):\")\n",
        "print(c1[:10])\n",
        "print(\"\\nDecoded stroke (first 5 rows, aka 5 pen steps):\")\n",
        "print(decoded_stroke[:5])\n",
        "print(\"\\nInferred number of tokens required to represent:\")\n",
        "print(decoded_stroke.shape[0]*3)\n",
        "print(\"\\nDecoded text:\")\n",
        "print(dataset.decode_text(c1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMqTTPtzs6ot",
        "outputId": "afc28280-4b35-46d0-dd07-e30fc1555447"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original stroke shape: (1082, 3)\n",
            "Encoded stroke shape: torch.Size([1100])\n",
            "Encoded text shape: torch.Size([30])\n",
            "Decoded stroke shape: (315, 4)\n",
            "\n",
            "Encoded strokes (first 15 tokens, aka 5 pen strokes):\n",
            "[50, 176, 252, 85, 122, 276, 80, 116, 283, 84, 122, 274, 74, 110, 284]\n",
            "\n",
            "\n",
            "Encoded text (first 10 tokens, aka ascii chars):\n",
            "tensor([25,  5, 23, 27,  4,  5, 19,  9,  7, 14])\n",
            "\n",
            "Decoded stroke (first 5 rows, aka 5 pen steps):\n",
            "[[ 0.          0.          0.          1.        ]\n",
            " [ 0.8        -0.58666667  0.01769231  1.        ]\n",
            " [ 0.62       -0.78666667  0.03846154  1.        ]\n",
            " [ 0.74       -0.65333333  0.04192308  1.        ]\n",
            " [ 0.8        -0.6         0.03384615  1.        ]]\n",
            "\n",
            "Inferred number of tokens required to represent:\n",
            "945\n",
            "\n",
            "Decoded text:\n",
            "yew design october\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "LXAlpngErwVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_ctx_head == 0\n",
        "        # query projections for all heads\n",
        "        self.c_attn_q = nn.Linear(config.n_embd, config.n_embd)\n",
        "        # key, value projections for all heads\n",
        "        self.c_attn_kv = nn.Linear(config.n_embd, 2 * config.n_embd)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        self.n_ctx_head = config.n_ctx_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "        _, T_ctx, _ = context.size()\n",
        "\n",
        "        # calculate query for all heads in batch and move head forward to be the batch dim\n",
        "        q = self.c_attn_q(x).view(B, T, self.n_ctx_head, C // self.n_ctx_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # calculate key, values for all heads in batch and move head forward to be the batch dim\n",
        "        k, v = self.c_attn_kv(context).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T_ctx, self.n_ctx_head, C // self.n_ctx_head).transpose(1, 2) # (B, nh, T_ctx, hs)\n",
        "        v = v.view(B, T_ctx, self.n_ctx_head, C // self.n_ctx_head).transpose(1, 2) # (B, nh, T_ctx, hs)\n",
        "\n",
        "        # cross-attention; (B, nh, T, hs) x (B, nh, hs, T_ctx) -> (B, nh, T, T_ctx)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        y = att @ v # (B, nh, T, T_ctx) x (B, nh, T_ctx, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.c_proj(y)\n",
        "        return y"
      ],
      "metadata": {
        "id": "Azf2fXB3MeRL"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------------------------------------------------------\n",
        "# Transformer Language Model (*exactly* as used in GPT-2)\n",
        "\n",
        "class NewGELU(nn.Module):\n",
        "    \"\"\"\n",
        "    Implementation of the GELU activation function currently in Google BERT repo (identical to OpenAI GPT).\n",
        "    Reference: Gaussian Error Linear Units (GELU) paper: https://arxiv.org/abs/1606.08415\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (x + 0.044715 * torch.pow(x, 3.0))))\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    A vanilla multi-head masked self-attention layer with a projection at the end.\n",
        "    It is possible to use torch.nn.MultiheadAttention here but I am including an\n",
        "    explicit implementation here to show that there is nothing too scary here.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_head == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd)\n",
        "        # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "        self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                     .view(1, 1, config.block_size, config.block_size))\n",
        "        self.n_head = config.n_head\n",
        "        self.n_embd = config.n_embd\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        q, k ,v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "        att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "        att = F.softmax(att, dim=-1)\n",
        "        y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.c_proj(y)\n",
        "        return y\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\" an unassuming Transformer block \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.ln_1 = nn.LayerNorm(config.n_embd)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.ln_2 = nn.LayerNorm(config.n_embd)\n",
        "        self.cross_attn = CrossAttention(config) # NEW\n",
        "        self.ln_3 = nn.LayerNorm(config.n_embd) # NEW\n",
        "        self.mlp = nn.ModuleDict(dict(\n",
        "            c_fc    = nn.Linear(config.n_embd, 4 * config.n_embd),\n",
        "            c_proj  = nn.Linear(4 * config.n_embd, config.n_embd),\n",
        "            act     = NewGELU(),\n",
        "        ))\n",
        "        m = self.mlp\n",
        "        self.mlpf = lambda x: m.c_proj(m.act(m.c_fc(x))) # MLP forward\n",
        "\n",
        "    def forward(self, x, context):\n",
        "        x = x + self.attn(self.ln_1(x))\n",
        "        #x = x + self.mlpf(self.ln_2(x))\n",
        "        x = x + self.cross_attn(self.ln_2(x), context)\n",
        "        x = x + self.mlpf(self.ln_3(x))\n",
        "        return x\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \"\"\" Transformer Language Model, exactly as seen in GPT-2 \"\"\"\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.block_size = config.block_size\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            wpe = nn.Embedding(config.block_size, config.n_embd),\n",
        "            wce = nn.Embedding(config.context_vocab_size, config.n_embd), # NEW\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),\n",
        "            ln_f = nn.LayerNorm(config.n_embd),\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "\n",
        "        # report number of parameters (note we don't count the decoder parameters in lm_head)\n",
        "        n_params = sum(p.numel() for p in self.transformer.parameters())\n",
        "        print(\"Number of Transformer parameters: {:.0f}\".format(n_params,))\n",
        "\n",
        "    def get_block_size(self):\n",
        "        return self.block_size\n",
        "\n",
        "    def forward(self, idx, context, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device).unsqueeze(0) # shape (1, t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        pos_emb = self.transformer.wpe(pos) # position embeddings of shape (1, t, n_embd)\n",
        "        x = tok_emb + pos_emb\n",
        "\n",
        "        context_emb = self.transformer.wce(context) # context embeddings of shape (b, t_ctx, n_embd)\n",
        "\n",
        "        if self.config.ablate_cross_attention:\n",
        "          context_emb = torch.zeros_like(context_emb)\n",
        "\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x, context_emb)\n",
        "        x = self.transformer.ln_f(x)\n",
        "        logits = self.lm_head(x)\n",
        "\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "@dataclass\n",
        "class ModelConfig:\n",
        "    block_size: int = None # length of the input sequences of integers\n",
        "    vocab_size: int = None # the input integers are in range [0 .. vocab_size -1]\n",
        "    context_vocab_size: int = None # size of the context vocabulary (ASCII characters)\n",
        "    context_length: int = None # maximum length of the context sequence\n",
        "    # parameters below control the sizes of each model slightly differently\n",
        "    n_layer: int = 4\n",
        "    n_embd: int = 64\n",
        "    n_embd2: int = 64\n",
        "    n_head: int = 4\n",
        "    n_ctx_head: int = 4 # number of heads for cross-attention\n",
        "    ablate_cross_attention: bool = False"
      ],
      "metadata": {
        "id": "-x74SZP_qymr"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "PoVuOu7ZB3HI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_string(fmt='%m%d_%H%M'):\n",
        "    return datetime.now().strftime(fmt)\n",
        "\n",
        "run_tag = \"ct_10ksamples_permute\"\n",
        "\n",
        "@dataclass\n",
        "class AppConfig:\n",
        "    # system/input/output\n",
        "    input_file: str = 'names.txt'\n",
        "    work_dir: str = 'out'\n",
        "    resume: bool = False\n",
        "    sample_only: bool = False\n",
        "    num_workers: int = 1 # 4\n",
        "    max_steps: int = 30000\n",
        "    device: str = 'cuda'\n",
        "    seed: int = 3407\n",
        "\n",
        "    # sampling\n",
        "    top_k: int = -1\n",
        "\n",
        "    # model configuration\n",
        "    n_layer: int = 4\n",
        "    n_embd: int = 64\n",
        "    n_embd2: int = 64\n",
        "    n_head: int = 4\n",
        "    ablate_cross_attention: bool = False  # New flag to ablate cross-attention\n",
        "    augment: bool = True\n",
        "    max_seq_length: int = 1100\n",
        "\n",
        "    # optimization\n",
        "    batch_size: int = 32\n",
        "    learning_rate: float = 3e-4\n",
        "    weight_decay: float = 1e-4\n",
        "\n",
        "    # wandb parameters\n",
        "    wandb_project: str = run_tag\n",
        "    wandb_entity: str = 'sam-greydanus'  # Set this to your wandb username or team name\n",
        "    wandb_run_name: str = f\"{get_time_string()}_{run_tag}\"\n",
        "\n",
        "args = AppConfig()\n",
        "\n",
        "# system inits\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed_all(args.seed)\n",
        "os.makedirs(args.work_dir, exist_ok=True)\n",
        "writer = SummaryWriter(log_dir=args.work_dir)\n",
        "\n",
        "# init datasets\n",
        "train_dataset, test_dataset = create_datasets(augment=args.augment, max_seq_length=args.max_seq_length)\n",
        "vocab_size = train_dataset.get_vocab_size()\n",
        "block_size = train_dataset.get_output_length()\n",
        "context_vocab_size = train_dataset.get_char_vocab_size()\n",
        "print(f\"Dataset determined that: {vocab_size=}, {block_size=}\")\n",
        "\n",
        "# init model\n",
        "config = ModelConfig(vocab_size=vocab_size,\n",
        "                     block_size=block_size,\n",
        "                     context_vocab_size=context_vocab_size,\n",
        "                     n_layer=args.n_layer, n_head=args.n_head,\n",
        "                     n_embd=args.n_embd, n_embd2=args.n_embd2,\n",
        "                     ablate_cross_attention=args.ablate_cross_attention,\n",
        "                     n_ctx_head=args.n_head,)\n",
        "model = Transformer(config)\n",
        "model.to(args.device)\n",
        "print(f\"Model #params: {sum(p.numel() for p in model.parameters())}\")\n",
        "if args.resume or args.sample_only: # note: if we sample-only then we also assume we are resuming\n",
        "    print(\"resuming from existing model in the workdir\")\n",
        "    model.load_state_dict(torch.load(os.path.join(args.work_dir, 'model.pt')))\n",
        "if args.sample_only:\n",
        "    # save_samples(num=50)\n",
        "    print('This functionality is temporarily commented out')\n",
        "    sys.exit()\n",
        "\n",
        "# init optimizer and batch loader\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate, weight_decay=args.weight_decay, betas=(0.9, 0.99), eps=1e-8)\n",
        "batch_loader = InfiniteDataLoader(train_dataset, batch_size=args.batch_size, pin_memory=True, num_workers=args.num_workers)"
      ],
      "metadata": {
        "id": "exe5-vbitBJL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "e0cc9b27-f2dc-4fe4-9663-b96d6c55e866"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3b73365c-83d4-43e8-b802-2f3fc9fdc34d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3b73365c-83d4-43e8-b802-2f3fc9fdc34d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 0100-bigbank.json to 0100-bigbank (15).json\n",
            "For a dataset of 148 examples we can generate 529396 combinations of 3 examples.\n",
            "Generating 9000 random (and thus possibly overlapping) combos...\n",
            "For a dataset of 37 examples we can generate 7770 combinations of 3 examples.\n",
            "Generating 1000 random (and thus possibly overlapping) combos...\n",
            "Number of examples in the train dataset: 9000\n",
            "Number of examples in the test dataset: 1000\n",
            "Max token sequence length: 1100\n",
            "Number of unique characters in the ascii vocabulary: 27\n",
            "Ascii vocabulary:\n",
            "\t\"abcdefghijklmnopqrstuvwxyz \"\n",
            "Split up the dataset into 9000 training examples and 1000 test examples\n",
            "Dataset determined that: vocab_size=456, block_size=1100\n",
            "Number of Transformer parameters: 368512\n",
            "Model #params: 397696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    project=args.wandb_project,\n",
        "    entity=args.wandb_entity,\n",
        "    name=args.wandb_run_name,\n",
        "    config=args\n",
        ")\n",
        "\n",
        "wandb.config.update({\n",
        "    \"n_layer\": config.n_layer,\n",
        "    \"n_head\": config.n_head,\n",
        "    \"n_embd\": config.n_embd,\n",
        "    \"learning_rate\": args.learning_rate,\n",
        "    \"weight_decay\": args.weight_decay,\n",
        "    \"batch_size\": args.batch_size,\n",
        "    \"ablate_cross_attention\": args.ablate_cross_attention,\n",
        "})"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MvHVOusgH_z8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "9f115ae3-79f8-41e1-8bae-31296514f04f"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.4"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240707_034343-5cwh9ym6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/sam-greydanus/ct_10ksamples_permute/runs/5cwh9ym6' target=\"_blank\">0707_0343_ct_10ksamples_permute</a></strong> to <a href='https://wandb.ai/sam-greydanus/ct_10ksamples_permute' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/sam-greydanus/ct_10ksamples_permute' target=\"_blank\">https://wandb.ai/sam-greydanus/ct_10ksamples_permute</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/sam-greydanus/ct_10ksamples_permute/runs/5cwh9ym6' target=\"_blank\">https://wandb.ai/sam-greydanus/ct_10ksamples_permute/runs/5cwh9ym6</a>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample from the untrained model"
      ],
      "metadata": {
        "id": "Z_EKkV_W1tZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.inference_mode()\n",
        "def evaluate(model, dataset, batch_size=50, max_batches=None):\n",
        "    model.eval()\n",
        "    loader = DataLoader(dataset, shuffle=True, batch_size=batch_size, num_workers=0)\n",
        "    losses = []\n",
        "    for i, batch in enumerate(loader):\n",
        "        batch = [t.to(args.device) for t in batch]\n",
        "        X, C, Y = batch\n",
        "        logits, loss = model(X, C, Y)\n",
        "        losses.append(loss.item())\n",
        "        if max_batches is not None and i >= max_batches:\n",
        "            break\n",
        "    mean_loss = torch.tensor(losses).mean().item()\n",
        "    model.train() # reset model back to training mode\n",
        "    return mean_loss\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate(model, idx, context, max_new_tokens, temperature=1.0, do_sample=False, top_k=None):\n",
        "    \"\"\"\n",
        "    Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
        "    the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
        "    Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
        "    \"\"\"\n",
        "    block_size = model.get_block_size()\n",
        "    steps = max(0, max_new_tokens-idx.size(1))\n",
        "    for i in range(steps):\n",
        "        # if the sequence context is growing too long we must crop it at block_size\n",
        "        idx_cond = idx if idx.size(1) <= block_size else idx[:, -block_size:]\n",
        "        # forward the model to get the logits for the index in the sequence\n",
        "        logits, _ = model(idx_cond, context)\n",
        "        # pluck the logits at the final step and scale by desired temperature\n",
        "        logits = logits[:, -1, :] / temperature\n",
        "        # optionally crop the logits to only the top k options\n",
        "        if top_k is not None:\n",
        "            v, _ = torch.topk(logits, top_k)\n",
        "            logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "        # apply softmax to convert logits to (normalized) probabilities\n",
        "        probs = F.softmax(logits, dim=-1)\n",
        "        # either sample from the distribution or take the most likely element\n",
        "        if do_sample:\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "        else:\n",
        "            _, idx_next = torch.topk(probs, k=1, dim=-1)\n",
        "        # append sampled index to the running sequence and continue\n",
        "        idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "    return idx\n",
        "\n",
        "def save_samples(model, dataset, num=2, model_device='cpu', warmup_steps=100, do_sample=False):\n",
        "    \"\"\" samples from the model and plots the decoded strokes \"\"\"\n",
        "    model_device = list(model.parameters())[0].device # hacky\n",
        "\n",
        "    stroke_seq, context = [], []\n",
        "    for i in range(num):\n",
        "      x, c, y = dataset[i]\n",
        "      stroke_seq.append(x) ; context.append(c)\n",
        "\n",
        "    X_init = torch.stack(stroke_seq).to(model_device)[:,:warmup_steps]\n",
        "    context = torch.stack(context).long().to(model_device)\n",
        "    top_k = None\n",
        "    steps = dataset.get_output_length() - 1  # -1 because we already start with the first token\n",
        "\n",
        "    X_samp = generate(model, X_init, context, steps, top_k=top_k, do_sample=do_sample).to('cpu')\n",
        "\n",
        "    for i in range(X_samp.size(0)):\n",
        "        # get the i'th row of sampled integers, as python list\n",
        "        row = X_samp[i].detach().cpu().numpy()\n",
        "        offset_samp = dataset.decode_stroke(row)\n",
        "        point_samp = offsets_to_strokes(offset_samp)\n",
        "        decoded_ascii = dataset.decode_text(context[i])\n",
        "\n",
        "        # Plot the stroke\n",
        "        fig, ax = plot_strokes(point_samp, f'Sample {i+1}: \"{decoded_ascii}\"') #plt.axis('off')\n",
        "        tag = 'sample' if do_sample else 'topk'\n",
        "        fig.savefig(f\"{dataset.name}_{tag}_{i+1}.png\")\n",
        "        wandb.log({f\"{dataset.name}_{tag}_{i+1}\": wandb.Image(f\"{dataset.name}_{tag}_{i+1}.png\")})\n",
        "        plt.close(fig)\n",
        "        print(f\"Saved {dataset.name}_{tag}_{i+1}.png\")\n",
        "\n",
        "    print('-'*80)"
      ],
      "metadata": {
        "id": "RplUgs12B8xB"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train the model"
      ],
      "metadata": {
        "id": "nV1ntAoG1vqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "best_loss = None\n",
        "step = 0\n",
        "while True:\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # get the next batch, ship to device, and unpack it to input and target\n",
        "    batch = batch_loader.next()\n",
        "    batch = [t.to(args.device) for t in batch]\n",
        "    X, C, Y = batch\n",
        "\n",
        "    # feed into the model\n",
        "    logits, loss = model(X, C, Y)\n",
        "\n",
        "    # calculate the gradient, update the weights\n",
        "    model.zero_grad(set_to_none=True) ; loss.backward()\n",
        "    optimizer.step()\n",
        "    wandb.log({\"train_loss_step\": loss.item(), \"step\": step})\n",
        "\n",
        "    # wait for all CUDA work on the GPU to finish then calculate iteration time taken\n",
        "    if args.device.startswith('cuda'):\n",
        "        torch.cuda.synchronize()\n",
        "    t1 = time.time()\n",
        "\n",
        "    # logging\n",
        "    if step % 25 == 0:\n",
        "        print(f\"step {step} | loss {loss.item():.4f} | step time {(t1-t0)*1000:.2f}ms\")\n",
        "\n",
        "    # evaluate the model\n",
        "    if step > 0 and step % 200 == 0:\n",
        "        train_loss = evaluate(model, train_dataset, batch_size=100, max_batches=10)\n",
        "        test_loss  = evaluate(model, test_dataset,  batch_size=100, max_batches=10)\n",
        "        wandb.log({\"train_loss\": train_loss, \"test_loss\": test_loss, \"step\": step })\n",
        "        print(f\"step {step} train loss: {train_loss:.4f} test loss: {test_loss:.4f}\")\n",
        "        # save the model to disk if it has improved\n",
        "        if best_loss is None or test_loss < best_loss:\n",
        "            out_path = os.path.join(args.work_dir, \"model.pt\")\n",
        "            print(f\"Test loss {test_loss:.4f} is the best so far, saving model to {out_path}\")\n",
        "            torch.save(model.state_dict(), out_path)\n",
        "            #wandb.save(out_path)\n",
        "            best_loss = test_loss\n",
        "\n",
        "    # sample from the model\n",
        "    if step > 0 and step % 200 == 0:\n",
        "        save_samples(model, test_dataset, num=3, do_sample=True)\n",
        "        save_samples(model, test_dataset, num=3, do_sample=False)\n",
        "        save_samples(model, train_dataset, num=3, do_sample=True)\n",
        "        save_samples(model, train_dataset, num=3, do_sample=False)\n",
        "\n",
        "    step += 1\n",
        "    # termination conditions\n",
        "    if args.max_steps >= 0 and step >= args.max_steps:\n",
        "        break"
      ],
      "metadata": {
        "id": "7otFYXQhr9lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "820ee545-6437-4811-d2a4-87896707c263"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0 | loss 6.2894 | step time 131.12ms\n",
            "step 25 | loss 5.5434 | step time 107.06ms\n",
            "step 50 | loss 5.0877 | step time 107.56ms\n",
            "step 75 | loss 4.9738 | step time 106.57ms\n",
            "step 100 | loss 4.7185 | step time 106.40ms\n",
            "step 125 | loss 4.4960 | step time 106.12ms\n",
            "step 150 | loss 4.1369 | step time 106.37ms\n",
            "step 175 | loss 3.8813 | step time 106.34ms\n",
            "step 200 | loss 3.6553 | step time 106.15ms\n",
            "step 200 train loss: 3.6562 test loss: 3.7083\n",
            "Test loss 3.7083 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 225 | loss 3.4355 | step time 105.87ms\n",
            "step 250 | loss 3.3546 | step time 105.98ms\n",
            "step 275 | loss 3.2621 | step time 105.87ms\n",
            "step 300 | loss 3.1258 | step time 106.20ms\n",
            "step 325 | loss 3.0475 | step time 106.09ms\n",
            "step 350 | loss 2.9665 | step time 106.22ms\n",
            "step 375 | loss 2.9374 | step time 106.20ms\n",
            "step 400 | loss 2.9302 | step time 106.22ms\n",
            "step 400 train loss: 2.9233 test loss: 2.9776\n",
            "Test loss 2.9776 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 425 | loss 2.9232 | step time 105.99ms\n",
            "step 450 | loss 2.9225 | step time 106.03ms\n",
            "step 475 | loss 2.8056 | step time 106.15ms\n",
            "step 500 | loss 2.9758 | step time 106.13ms\n",
            "step 525 | loss 2.7756 | step time 106.19ms\n",
            "step 550 | loss 2.7938 | step time 106.13ms\n",
            "step 575 | loss 2.9540 | step time 106.57ms\n",
            "step 600 | loss 2.8777 | step time 105.91ms\n",
            "step 600 train loss: 2.8573 test loss: 2.8890\n",
            "Test loss 2.8890 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 625 | loss 2.8856 | step time 106.36ms\n",
            "step 650 | loss 2.7915 | step time 106.21ms\n",
            "step 675 | loss 2.7917 | step time 106.78ms\n",
            "step 700 | loss 2.8676 | step time 106.06ms\n",
            "step 725 | loss 2.7917 | step time 106.42ms\n",
            "step 750 | loss 2.8121 | step time 106.04ms\n",
            "step 775 | loss 2.8806 | step time 106.20ms\n",
            "step 800 | loss 2.8513 | step time 106.47ms\n",
            "step 800 train loss: 2.8164 test loss: 2.8491\n",
            "Test loss 2.8491 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 825 | loss 2.8742 | step time 106.84ms\n",
            "step 850 | loss 2.7647 | step time 106.79ms\n",
            "step 875 | loss 2.8338 | step time 106.85ms\n",
            "step 900 | loss 2.7579 | step time 106.59ms\n",
            "step 925 | loss 2.7983 | step time 106.46ms\n",
            "step 950 | loss 2.8568 | step time 106.23ms\n",
            "step 975 | loss 2.7796 | step time 105.96ms\n",
            "step 1000 | loss 2.8116 | step time 106.27ms\n",
            "step 1000 train loss: 2.7905 test loss: 2.8289\n",
            "Test loss 2.8289 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 1025 | loss 2.8435 | step time 106.24ms\n",
            "step 1050 | loss 2.8197 | step time 106.48ms\n",
            "step 1075 | loss 2.8236 | step time 106.08ms\n",
            "step 1100 | loss 2.7673 | step time 105.97ms\n",
            "step 1125 | loss 2.8489 | step time 106.12ms\n",
            "step 1150 | loss 2.7418 | step time 106.28ms\n",
            "step 1175 | loss 2.7795 | step time 106.18ms\n",
            "step 1200 | loss 2.8175 | step time 105.92ms\n",
            "step 1200 train loss: 2.7570 test loss: 2.8132\n",
            "Test loss 2.8132 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 1225 | loss 2.8179 | step time 106.68ms\n",
            "step 1250 | loss 2.7968 | step time 106.15ms\n",
            "step 1275 | loss 2.7932 | step time 106.55ms\n",
            "step 1300 | loss 2.8259 | step time 106.44ms\n",
            "step 1325 | loss 2.7688 | step time 106.27ms\n",
            "step 1350 | loss 2.7116 | step time 106.36ms\n",
            "step 1375 | loss 2.7793 | step time 106.22ms\n",
            "step 1400 | loss 2.8211 | step time 106.14ms\n",
            "step 1400 train loss: 2.7626 test loss: 2.8040\n",
            "Test loss 2.8040 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 1425 | loss 2.7438 | step time 105.90ms\n",
            "step 1450 | loss 2.7745 | step time 106.27ms\n",
            "step 1475 | loss 2.7145 | step time 106.70ms\n",
            "step 1500 | loss 2.6921 | step time 106.13ms\n",
            "step 1525 | loss 2.7767 | step time 105.96ms\n",
            "step 1550 | loss 2.8626 | step time 106.15ms\n",
            "step 1575 | loss 2.6839 | step time 106.51ms\n",
            "step 1600 | loss 2.6420 | step time 106.16ms\n",
            "step 1600 train loss: 2.7384 test loss: 2.7985\n",
            "Test loss 2.7985 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 1625 | loss 2.7330 | step time 105.94ms\n",
            "step 1650 | loss 2.7534 | step time 106.83ms\n",
            "step 1675 | loss 2.8463 | step time 106.18ms\n",
            "step 1700 | loss 2.7293 | step time 106.04ms\n",
            "step 1725 | loss 2.7474 | step time 106.02ms\n",
            "step 1750 | loss 2.7975 | step time 106.05ms\n",
            "step 1775 | loss 2.7737 | step time 106.40ms\n",
            "step 1800 | loss 2.7497 | step time 105.96ms\n",
            "step 1800 train loss: 2.7498 test loss: 2.7922\n",
            "Test loss 2.7922 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 1825 | loss 2.6897 | step time 106.14ms\n",
            "step 1850 | loss 2.7913 | step time 106.15ms\n",
            "step 1875 | loss 2.7405 | step time 106.30ms\n",
            "step 1900 | loss 2.7994 | step time 105.89ms\n",
            "step 1925 | loss 2.6640 | step time 106.32ms\n",
            "step 1950 | loss 2.7480 | step time 105.98ms\n",
            "step 1975 | loss 2.7653 | step time 105.99ms\n",
            "step 2000 | loss 2.6684 | step time 106.43ms\n",
            "step 2000 train loss: 2.7537 test loss: 2.7868\n",
            "Test loss 2.7868 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 2025 | loss 2.6897 | step time 106.05ms\n",
            "step 2050 | loss 2.7235 | step time 106.24ms\n",
            "step 2075 | loss 2.7399 | step time 106.26ms\n",
            "step 2100 | loss 2.6380 | step time 106.07ms\n",
            "step 2125 | loss 2.7518 | step time 105.83ms\n",
            "step 2150 | loss 2.8996 | step time 105.89ms\n",
            "step 2175 | loss 2.7938 | step time 106.56ms\n",
            "step 2200 | loss 2.7284 | step time 106.56ms\n",
            "step 2200 train loss: 2.7305 test loss: 2.7839\n",
            "Test loss 2.7839 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 2225 | loss 2.7061 | step time 106.14ms\n",
            "step 2250 | loss 2.8019 | step time 106.13ms\n",
            "step 2275 | loss 2.7262 | step time 106.50ms\n",
            "step 2300 | loss 2.7823 | step time 106.20ms\n",
            "step 2325 | loss 2.7885 | step time 105.90ms\n",
            "step 2350 | loss 2.7267 | step time 105.89ms\n",
            "step 2375 | loss 2.7471 | step time 105.94ms\n",
            "step 2400 | loss 2.7808 | step time 106.38ms\n",
            "step 2400 train loss: 2.7400 test loss: 2.7794\n",
            "Test loss 2.7794 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 2425 | loss 2.7618 | step time 105.95ms\n",
            "step 2450 | loss 2.7011 | step time 106.48ms\n",
            "step 2475 | loss 2.8135 | step time 106.62ms\n",
            "step 2500 | loss 2.7463 | step time 106.36ms\n",
            "step 2525 | loss 2.7084 | step time 106.29ms\n",
            "step 2550 | loss 2.7454 | step time 106.33ms\n",
            "step 2575 | loss 2.7871 | step time 106.41ms\n",
            "step 2600 | loss 2.6330 | step time 106.68ms\n",
            "step 2600 train loss: 2.7274 test loss: 2.7763\n",
            "Test loss 2.7763 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 2625 | loss 2.7510 | step time 106.72ms\n",
            "step 2650 | loss 2.6823 | step time 106.00ms\n",
            "step 2675 | loss 2.6992 | step time 106.70ms\n",
            "step 2700 | loss 2.7808 | step time 106.68ms\n",
            "step 2725 | loss 2.7419 | step time 106.72ms\n",
            "step 2750 | loss 2.6880 | step time 106.65ms\n",
            "step 2775 | loss 2.7254 | step time 106.20ms\n",
            "step 2800 | loss 2.7518 | step time 106.53ms\n",
            "step 2800 train loss: 2.7289 test loss: 2.7718\n",
            "Test loss 2.7718 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 2825 | loss 2.6603 | step time 106.01ms\n",
            "step 2850 | loss 2.6613 | step time 106.19ms\n",
            "step 2875 | loss 2.6548 | step time 106.05ms\n",
            "step 2900 | loss 2.7785 | step time 106.34ms\n",
            "step 2925 | loss 2.7498 | step time 105.99ms\n",
            "step 2950 | loss 2.7483 | step time 105.89ms\n",
            "step 2975 | loss 2.6066 | step time 106.34ms\n",
            "step 3000 | loss 2.7275 | step time 106.73ms\n",
            "step 3000 train loss: 2.7333 test loss: 2.7681\n",
            "Test loss 2.7681 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 3025 | loss 2.7735 | step time 105.87ms\n",
            "step 3050 | loss 2.7075 | step time 106.36ms\n",
            "step 3075 | loss 2.7510 | step time 106.45ms\n",
            "step 3100 | loss 2.6699 | step time 106.36ms\n",
            "step 3125 | loss 2.6981 | step time 106.83ms\n",
            "step 3150 | loss 2.7457 | step time 106.22ms\n",
            "step 3175 | loss 2.8046 | step time 106.03ms\n",
            "step 3200 | loss 2.7087 | step time 106.29ms\n",
            "step 3200 train loss: 2.7201 test loss: 2.7659\n",
            "Test loss 2.7659 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 3225 | loss 2.7394 | step time 105.85ms\n",
            "step 3250 | loss 2.7537 | step time 106.64ms\n",
            "step 3275 | loss 2.7012 | step time 106.58ms\n",
            "step 3300 | loss 2.7191 | step time 106.64ms\n",
            "step 3325 | loss 2.7500 | step time 106.41ms\n",
            "step 3350 | loss 2.7592 | step time 106.56ms\n",
            "step 3375 | loss 2.7409 | step time 106.81ms\n",
            "step 3400 | loss 2.7147 | step time 106.73ms\n",
            "step 3400 train loss: 2.7190 test loss: 2.7611\n",
            "Test loss 2.7611 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 3425 | loss 2.7579 | step time 106.38ms\n",
            "step 3450 | loss 2.5807 | step time 106.52ms\n",
            "step 3475 | loss 2.6603 | step time 106.80ms\n",
            "step 3500 | loss 2.6450 | step time 106.00ms\n",
            "step 3525 | loss 2.6803 | step time 106.53ms\n",
            "step 3550 | loss 2.7682 | step time 106.43ms\n",
            "step 3575 | loss 2.7087 | step time 106.06ms\n",
            "step 3600 | loss 2.7424 | step time 106.67ms\n",
            "step 3600 train loss: 2.7011 test loss: 2.7566\n",
            "Test loss 2.7566 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 3625 | loss 2.7889 | step time 105.95ms\n",
            "step 3650 | loss 2.7854 | step time 106.37ms\n",
            "step 3675 | loss 2.6571 | step time 106.11ms\n",
            "step 3700 | loss 2.7164 | step time 106.02ms\n",
            "step 3725 | loss 2.6839 | step time 106.09ms\n",
            "step 3750 | loss 2.6731 | step time 106.21ms\n",
            "step 3775 | loss 2.7066 | step time 106.26ms\n",
            "step 3800 | loss 2.7185 | step time 106.10ms\n",
            "step 3800 train loss: 2.6968 test loss: 2.7479\n",
            "Test loss 2.7479 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 3825 | loss 2.6955 | step time 106.62ms\n",
            "step 3850 | loss 2.6981 | step time 106.14ms\n",
            "step 3875 | loss 2.6860 | step time 106.34ms\n",
            "step 3900 | loss 2.7519 | step time 106.52ms\n",
            "step 3925 | loss 2.7432 | step time 106.71ms\n",
            "step 3950 | loss 2.7286 | step time 106.20ms\n",
            "step 3975 | loss 2.5974 | step time 106.68ms\n",
            "step 4000 | loss 2.6616 | step time 106.61ms\n",
            "step 4000 train loss: 2.6858 test loss: 2.7428\n",
            "Test loss 2.7428 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 4025 | loss 2.7601 | step time 106.02ms\n",
            "step 4050 | loss 2.7213 | step time 106.11ms\n",
            "step 4075 | loss 2.8199 | step time 106.38ms\n",
            "step 4100 | loss 2.6694 | step time 106.64ms\n",
            "step 4125 | loss 2.7566 | step time 105.90ms\n",
            "step 4150 | loss 2.6912 | step time 106.18ms\n",
            "step 4175 | loss 2.7550 | step time 106.10ms\n",
            "step 4200 | loss 2.7406 | step time 106.29ms\n",
            "step 4200 train loss: 2.6818 test loss: 2.7347\n",
            "Test loss 2.7347 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 4225 | loss 2.6797 | step time 106.25ms\n",
            "step 4250 | loss 2.6590 | step time 106.11ms\n",
            "step 4275 | loss 2.5959 | step time 106.09ms\n",
            "step 4300 | loss 2.6688 | step time 106.24ms\n",
            "step 4325 | loss 2.6359 | step time 106.01ms\n",
            "step 4350 | loss 2.6801 | step time 106.28ms\n",
            "step 4375 | loss 2.7093 | step time 105.83ms\n",
            "step 4400 | loss 2.5838 | step time 106.16ms\n",
            "step 4400 train loss: 2.6718 test loss: 2.7110\n",
            "Test loss 2.7110 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 4425 | loss 2.7114 | step time 106.74ms\n",
            "step 4450 | loss 2.6825 | step time 106.80ms\n",
            "step 4475 | loss 2.6646 | step time 106.43ms\n",
            "step 4500 | loss 2.6585 | step time 106.62ms\n",
            "step 4525 | loss 2.6391 | step time 106.32ms\n",
            "step 4550 | loss 2.6428 | step time 106.48ms\n",
            "step 4575 | loss 2.6211 | step time 106.14ms\n",
            "step 4600 | loss 2.6883 | step time 106.96ms\n",
            "step 4600 train loss: 2.6431 test loss: 2.6853\n",
            "Test loss 2.6853 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 4625 | loss 2.6259 | step time 106.07ms\n",
            "step 4650 | loss 2.6808 | step time 106.47ms\n",
            "step 4675 | loss 2.6505 | step time 105.82ms\n",
            "step 4700 | loss 2.6328 | step time 105.93ms\n",
            "step 4725 | loss 2.6698 | step time 105.82ms\n",
            "step 4750 | loss 2.4946 | step time 106.14ms\n",
            "step 4775 | loss 2.5192 | step time 106.08ms\n",
            "step 4800 | loss 2.6449 | step time 106.24ms\n",
            "step 4800 train loss: 2.5875 test loss: 2.6388\n",
            "Test loss 2.6388 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 4825 | loss 2.5264 | step time 106.28ms\n",
            "step 4850 | loss 2.6018 | step time 106.27ms\n",
            "step 4875 | loss 2.5904 | step time 106.65ms\n",
            "step 4900 | loss 2.5019 | step time 106.24ms\n",
            "step 4925 | loss 2.4654 | step time 106.02ms\n",
            "step 4950 | loss 2.5094 | step time 106.22ms\n",
            "step 4975 | loss 2.5707 | step time 106.36ms\n",
            "step 5000 | loss 2.4797 | step time 106.10ms\n",
            "step 5000 train loss: 2.5375 test loss: 2.5912\n",
            "Test loss 2.5912 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 5025 | loss 2.5251 | step time 105.93ms\n",
            "step 5050 | loss 2.5351 | step time 106.35ms\n",
            "step 5075 | loss 2.5386 | step time 106.61ms\n",
            "step 5100 | loss 2.4492 | step time 106.83ms\n",
            "step 5125 | loss 2.5074 | step time 105.87ms\n",
            "step 5150 | loss 2.5047 | step time 106.01ms\n",
            "step 5175 | loss 2.4908 | step time 106.17ms\n",
            "step 5200 | loss 2.4413 | step time 106.30ms\n",
            "step 5200 train loss: 2.4980 test loss: 2.5489\n",
            "Test loss 2.5489 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 5225 | loss 2.4631 | step time 106.61ms\n",
            "step 5250 | loss 2.3848 | step time 105.88ms\n",
            "step 5275 | loss 2.3970 | step time 106.36ms\n",
            "step 5300 | loss 2.5012 | step time 106.16ms\n",
            "step 5325 | loss 2.4045 | step time 106.65ms\n",
            "step 5350 | loss 2.4304 | step time 106.07ms\n",
            "step 5375 | loss 2.4307 | step time 106.42ms\n",
            "step 5400 | loss 2.4126 | step time 106.68ms\n",
            "step 5400 train loss: 2.4635 test loss: 2.5192\n",
            "Test loss 2.5192 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 5425 | loss 2.3944 | step time 106.33ms\n",
            "step 5450 | loss 2.4947 | step time 106.12ms\n",
            "step 5475 | loss 2.4187 | step time 106.64ms\n",
            "step 5500 | loss 2.4292 | step time 106.28ms\n",
            "step 5525 | loss 2.4239 | step time 106.53ms\n",
            "step 5550 | loss 2.4731 | step time 106.10ms\n",
            "step 5575 | loss 2.4118 | step time 106.04ms\n",
            "step 5600 | loss 2.3556 | step time 106.74ms\n",
            "step 5600 train loss: 2.4389 test loss: 2.4939\n",
            "Test loss 2.4939 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 5625 | loss 2.3749 | step time 106.47ms\n",
            "step 5650 | loss 2.4878 | step time 106.32ms\n",
            "step 5675 | loss 2.4594 | step time 105.84ms\n",
            "step 5700 | loss 2.4401 | step time 106.53ms\n",
            "step 5725 | loss 2.4373 | step time 105.85ms\n",
            "step 5750 | loss 2.4089 | step time 106.01ms\n",
            "step 5775 | loss 2.3808 | step time 106.29ms\n",
            "step 5800 | loss 2.3804 | step time 106.55ms\n",
            "step 5800 train loss: 2.4258 test loss: 2.4761\n",
            "Test loss 2.4761 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 5825 | loss 2.4414 | step time 106.31ms\n",
            "step 5850 | loss 2.4237 | step time 106.44ms\n",
            "step 5875 | loss 2.4642 | step time 106.22ms\n",
            "step 5900 | loss 2.4505 | step time 106.54ms\n",
            "step 5925 | loss 2.4961 | step time 106.59ms\n",
            "step 5950 | loss 2.4307 | step time 106.46ms\n",
            "step 5975 | loss 2.2351 | step time 106.36ms\n",
            "step 6000 | loss 2.4424 | step time 106.30ms\n",
            "step 6000 train loss: 2.4122 test loss: 2.4594\n",
            "Test loss 2.4594 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 6025 | loss 2.3756 | step time 106.18ms\n",
            "step 6050 | loss 2.3730 | step time 106.55ms\n",
            "step 6075 | loss 2.3870 | step time 106.66ms\n",
            "step 6100 | loss 2.3933 | step time 106.78ms\n",
            "step 6125 | loss 2.3953 | step time 107.51ms\n",
            "step 6150 | loss 2.3590 | step time 106.20ms\n",
            "step 6175 | loss 2.4295 | step time 106.28ms\n",
            "step 6200 | loss 2.4011 | step time 106.55ms\n",
            "step 6200 train loss: 2.3997 test loss: 2.4447\n",
            "Test loss 2.4447 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 6225 | loss 2.3857 | step time 106.73ms\n",
            "step 6250 | loss 2.3483 | step time 106.25ms\n",
            "step 6275 | loss 2.2687 | step time 106.49ms\n",
            "step 6300 | loss 2.3624 | step time 106.62ms\n",
            "step 6325 | loss 2.4337 | step time 106.56ms\n",
            "step 6350 | loss 2.3461 | step time 106.69ms\n",
            "step 6375 | loss 2.4008 | step time 106.57ms\n",
            "step 6400 | loss 2.3852 | step time 106.49ms\n",
            "step 6400 train loss: 2.3811 test loss: 2.4363\n",
            "Test loss 2.4363 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 6425 | loss 2.3496 | step time 106.08ms\n",
            "step 6450 | loss 2.3732 | step time 106.03ms\n",
            "step 6475 | loss 2.3438 | step time 106.65ms\n",
            "step 6500 | loss 2.3935 | step time 106.00ms\n",
            "step 6525 | loss 2.3322 | step time 106.52ms\n",
            "step 6550 | loss 2.4122 | step time 106.12ms\n",
            "step 6575 | loss 2.3454 | step time 105.91ms\n",
            "step 6600 | loss 2.3891 | step time 106.05ms\n",
            "step 6600 train loss: 2.3665 test loss: 2.4264\n",
            "Test loss 2.4264 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 6625 | loss 2.3101 | step time 106.53ms\n",
            "step 6650 | loss 2.2486 | step time 106.60ms\n",
            "step 6675 | loss 2.3412 | step time 106.56ms\n",
            "step 6700 | loss 2.3960 | step time 106.78ms\n",
            "step 6725 | loss 2.3541 | step time 106.54ms\n",
            "step 6750 | loss 2.3738 | step time 106.93ms\n",
            "step 6775 | loss 2.4305 | step time 106.68ms\n",
            "step 6800 | loss 2.3144 | step time 106.62ms\n",
            "step 6800 train loss: 2.3595 test loss: 2.4126\n",
            "Test loss 2.4126 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 6825 | loss 2.3306 | step time 106.74ms\n",
            "step 6850 | loss 2.3378 | step time 106.39ms\n",
            "step 6875 | loss 2.3188 | step time 106.78ms\n",
            "step 6900 | loss 2.4035 | step time 106.59ms\n",
            "step 6925 | loss 2.3829 | step time 106.65ms\n",
            "step 6950 | loss 2.3605 | step time 106.07ms\n",
            "step 6975 | loss 2.3758 | step time 106.35ms\n",
            "step 7000 | loss 2.3439 | step time 105.99ms\n",
            "step 7000 train loss: 2.3448 test loss: 2.4077\n",
            "Test loss 2.4077 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 7025 | loss 2.4219 | step time 106.22ms\n",
            "step 7050 | loss 2.3717 | step time 105.85ms\n",
            "step 7075 | loss 2.3180 | step time 105.92ms\n",
            "step 7100 | loss 2.3436 | step time 106.28ms\n",
            "step 7125 | loss 2.2841 | step time 105.74ms\n",
            "step 7150 | loss 2.2606 | step time 106.00ms\n",
            "step 7175 | loss 2.3328 | step time 105.80ms\n",
            "step 7200 | loss 2.3597 | step time 106.09ms\n",
            "step 7200 train loss: 2.3447 test loss: 2.4000\n",
            "Test loss 2.4000 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 7225 | loss 2.2796 | step time 105.95ms\n",
            "step 7250 | loss 2.2452 | step time 106.39ms\n",
            "step 7275 | loss 2.3037 | step time 105.82ms\n",
            "step 7300 | loss 2.3321 | step time 105.84ms\n",
            "step 7325 | loss 2.2441 | step time 106.32ms\n",
            "step 7350 | loss 2.4342 | step time 106.38ms\n",
            "step 7375 | loss 2.3849 | step time 105.85ms\n",
            "step 7400 | loss 2.2966 | step time 105.96ms\n",
            "step 7400 train loss: 2.3235 test loss: 2.3966\n",
            "Test loss 2.3966 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 7425 | loss 2.3039 | step time 106.12ms\n",
            "step 7450 | loss 2.3168 | step time 106.11ms\n",
            "step 7475 | loss 2.3476 | step time 106.05ms\n",
            "step 7500 | loss 2.3251 | step time 106.00ms\n",
            "step 7525 | loss 2.3269 | step time 106.63ms\n",
            "step 7550 | loss 2.3195 | step time 106.28ms\n",
            "step 7575 | loss 2.2636 | step time 106.12ms\n",
            "step 7600 | loss 2.3554 | step time 105.96ms\n",
            "step 7600 train loss: 2.3324 test loss: 2.3918\n",
            "Test loss 2.3918 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 7625 | loss 2.2536 | step time 106.18ms\n",
            "step 7650 | loss 2.3058 | step time 106.37ms\n",
            "step 7675 | loss 2.3482 | step time 106.50ms\n",
            "step 7700 | loss 2.3622 | step time 106.15ms\n",
            "step 7725 | loss 2.3281 | step time 107.03ms\n",
            "step 7750 | loss 2.3493 | step time 106.60ms\n",
            "step 7775 | loss 2.2946 | step time 105.80ms\n",
            "step 7800 | loss 2.2617 | step time 105.98ms\n",
            "step 7800 train loss: 2.3227 test loss: 2.3876\n",
            "Test loss 2.3876 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 7825 | loss 2.3371 | step time 105.78ms\n",
            "step 7850 | loss 2.2899 | step time 106.65ms\n",
            "step 7875 | loss 2.3112 | step time 106.55ms\n",
            "step 7900 | loss 2.3459 | step time 106.49ms\n",
            "step 7925 | loss 2.3366 | step time 105.92ms\n",
            "step 7950 | loss 2.2411 | step time 105.83ms\n",
            "step 7975 | loss 2.3167 | step time 106.72ms\n",
            "step 8000 | loss 2.2619 | step time 105.95ms\n",
            "step 8000 train loss: 2.3323 test loss: 2.3831\n",
            "Test loss 2.3831 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 8025 | loss 2.4279 | step time 105.91ms\n",
            "step 8050 | loss 2.2688 | step time 106.05ms\n",
            "step 8075 | loss 2.3092 | step time 105.92ms\n",
            "step 8100 | loss 2.3129 | step time 106.46ms\n",
            "step 8125 | loss 2.2764 | step time 106.40ms\n",
            "step 8150 | loss 2.3115 | step time 106.30ms\n",
            "step 8175 | loss 2.3548 | step time 106.31ms\n",
            "step 8200 | loss 2.3067 | step time 106.10ms\n",
            "step 8200 train loss: 2.3007 test loss: 2.3826\n",
            "Test loss 2.3826 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 8225 | loss 2.2457 | step time 106.68ms\n",
            "step 8250 | loss 2.3014 | step time 106.65ms\n",
            "step 8275 | loss 2.4354 | step time 106.51ms\n",
            "step 8300 | loss 2.3130 | step time 106.42ms\n",
            "step 8325 | loss 2.3060 | step time 106.46ms\n",
            "step 8350 | loss 2.3293 | step time 106.47ms\n",
            "step 8375 | loss 2.3937 | step time 106.22ms\n",
            "step 8400 | loss 2.3585 | step time 106.20ms\n",
            "step 8400 train loss: 2.3202 test loss: 2.3722\n",
            "Test loss 2.3722 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 8425 | loss 2.3130 | step time 106.60ms\n",
            "step 8450 | loss 2.3036 | step time 106.26ms\n",
            "step 8475 | loss 2.2654 | step time 106.42ms\n",
            "step 8500 | loss 2.2390 | step time 106.99ms\n",
            "step 8525 | loss 2.3388 | step time 106.35ms\n",
            "step 8550 | loss 2.2819 | step time 106.08ms\n",
            "step 8575 | loss 2.2505 | step time 106.39ms\n",
            "step 8600 | loss 2.3039 | step time 106.06ms\n",
            "step 8600 train loss: 2.3039 test loss: 2.3676\n",
            "Test loss 2.3676 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 8625 | loss 2.3025 | step time 106.24ms\n",
            "step 8650 | loss 2.2014 | step time 106.52ms\n",
            "step 8675 | loss 2.3327 | step time 106.08ms\n",
            "step 8700 | loss 2.2927 | step time 106.42ms\n",
            "step 8725 | loss 2.3475 | step time 106.15ms\n",
            "step 8750 | loss 2.2162 | step time 106.57ms\n",
            "step 8775 | loss 2.3378 | step time 106.30ms\n",
            "step 8800 | loss 2.2691 | step time 105.82ms\n",
            "step 8800 train loss: 2.2890 test loss: 2.3661\n",
            "Test loss 2.3661 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 8825 | loss 2.3079 | step time 106.09ms\n",
            "step 8850 | loss 2.3267 | step time 105.97ms\n",
            "step 8875 | loss 2.2448 | step time 106.18ms\n",
            "step 8900 | loss 2.2843 | step time 106.02ms\n",
            "step 8925 | loss 2.2253 | step time 106.58ms\n",
            "step 8950 | loss 2.2832 | step time 106.08ms\n",
            "step 8975 | loss 2.2371 | step time 106.10ms\n",
            "step 9000 | loss 2.3248 | step time 105.88ms\n",
            "step 9000 train loss: 2.3071 test loss: 2.3614\n",
            "Test loss 2.3614 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 9025 | loss 2.2718 | step time 106.40ms\n",
            "step 9050 | loss 2.2341 | step time 105.95ms\n",
            "step 9075 | loss 2.2100 | step time 106.35ms\n",
            "step 9100 | loss 2.3040 | step time 106.27ms\n",
            "step 9125 | loss 2.2838 | step time 105.91ms\n",
            "step 9150 | loss 2.3268 | step time 105.97ms\n",
            "step 9175 | loss 2.3354 | step time 106.03ms\n",
            "step 9200 | loss 2.3051 | step time 106.67ms\n",
            "step 9200 train loss: 2.3002 test loss: 2.3590\n",
            "Test loss 2.3590 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 9225 | loss 2.2537 | step time 106.04ms\n",
            "step 9250 | loss 2.3034 | step time 106.06ms\n",
            "step 9275 | loss 2.2933 | step time 106.10ms\n",
            "step 9300 | loss 2.2811 | step time 106.54ms\n",
            "step 9325 | loss 2.3116 | step time 106.13ms\n",
            "step 9350 | loss 2.3506 | step time 106.49ms\n",
            "step 9375 | loss 2.3291 | step time 106.38ms\n",
            "step 9400 | loss 2.2872 | step time 106.02ms\n",
            "step 9400 train loss: 2.2829 test loss: 2.3566\n",
            "Test loss 2.3566 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 9425 | loss 2.2541 | step time 106.08ms\n",
            "step 9450 | loss 2.2469 | step time 106.33ms\n",
            "step 9475 | loss 2.2422 | step time 106.54ms\n",
            "step 9500 | loss 2.4125 | step time 106.13ms\n",
            "step 9525 | loss 2.2470 | step time 106.56ms\n",
            "step 9550 | loss 2.2346 | step time 106.03ms\n",
            "step 9575 | loss 2.2014 | step time 106.13ms\n",
            "step 9600 | loss 2.3022 | step time 106.28ms\n",
            "step 9600 train loss: 2.2875 test loss: 2.3496\n",
            "Test loss 2.3496 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 9625 | loss 2.2984 | step time 106.22ms\n",
            "step 9650 | loss 2.2600 | step time 105.85ms\n",
            "step 9675 | loss 2.2244 | step time 106.65ms\n",
            "step 9700 | loss 2.3073 | step time 105.98ms\n",
            "step 9725 | loss 2.2498 | step time 106.59ms\n",
            "step 9750 | loss 2.1945 | step time 106.51ms\n",
            "step 9775 | loss 2.3343 | step time 106.37ms\n",
            "step 9800 | loss 2.3167 | step time 105.89ms\n",
            "step 9800 train loss: 2.2826 test loss: 2.3524\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 9825 | loss 2.2973 | step time 106.59ms\n",
            "step 9850 | loss 2.2672 | step time 106.28ms\n",
            "step 9875 | loss 2.2308 | step time 106.08ms\n",
            "step 9900 | loss 2.2132 | step time 106.53ms\n",
            "step 9925 | loss 2.3238 | step time 105.91ms\n",
            "step 9950 | loss 2.2762 | step time 106.54ms\n",
            "step 9975 | loss 2.3660 | step time 107.20ms\n",
            "step 10000 | loss 2.2599 | step time 106.02ms\n",
            "step 10000 train loss: 2.2736 test loss: 2.3479\n",
            "Test loss 2.3479 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 10025 | loss 2.2413 | step time 105.99ms\n",
            "step 10050 | loss 2.3280 | step time 105.85ms\n",
            "step 10075 | loss 2.2516 | step time 106.23ms\n",
            "step 10100 | loss 2.2413 | step time 105.87ms\n",
            "step 10125 | loss 2.2772 | step time 106.01ms\n",
            "step 10150 | loss 2.3336 | step time 105.98ms\n",
            "step 10175 | loss 2.3069 | step time 105.79ms\n",
            "step 10200 | loss 2.2430 | step time 106.34ms\n",
            "step 10200 train loss: 2.2738 test loss: 2.3464\n",
            "Test loss 2.3464 is the best so far, saving model to out/model.pt\n",
            "Saved test_sample_1.png\n",
            "Saved test_sample_2.png\n",
            "Saved test_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved test_topk_1.png\n",
            "Saved test_topk_2.png\n",
            "Saved test_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_sample_1.png\n",
            "Saved train_sample_2.png\n",
            "Saved train_sample_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "Saved train_topk_1.png\n",
            "Saved train_topk_2.png\n",
            "Saved train_topk_3.png\n",
            "--------------------------------------------------------------------------------\n",
            "step 10225 | loss 2.2709 | step time 106.17ms\n",
            "step 10250 | loss 2.2370 | step time 105.86ms\n",
            "step 10275 | loss 2.2607 | step time 106.31ms\n",
            "step 10300 | loss 2.2741 | step time 105.92ms\n",
            "step 10325 | loss 2.3031 | step time 105.78ms\n",
            "step 10350 | loss 2.2648 | step time 105.86ms\n",
            "step 10375 | loss 2.2370 | step time 106.36ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "q83i143gIwwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(dpi=200)\n",
        "img = mpimg.imread('test_sample_1.png')\n",
        "plt.imshow(img) ; plt.axis('off') ; plt.show()"
      ],
      "metadata": {
        "id": "CtO814TOsWU_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
