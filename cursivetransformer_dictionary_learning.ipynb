{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyNa3QXf6zV2iSJ04v7on9ZP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55b06a6cfffa4f208c7de76c8fc96553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0937ac49cd88433bad658cc6ce264219",
              "IPY_MODEL_fbc5d20e911847edbd64ff4bb2fed314",
              "IPY_MODEL_f891da403eab41d8b36e00c9a80bda05"
            ],
            "layout": "IPY_MODEL_6032e5f7f1c44c0cbb7c196f71d8aaad"
          }
        },
        "0937ac49cd88433bad658cc6ce264219": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b5824ff1f246dcb1ca39299aca113b",
            "placeholder": "​",
            "style": "IPY_MODEL_5c202b00910140c78de69988ce617fee",
            "value": "100%"
          }
        },
        "fbc5d20e911847edbd64ff4bb2fed314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e246f87fefed4dd697df9d8638f71c6c",
            "max": 5000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f713c028dbef4a358d65cdf5e3be017e",
            "value": 5000
          }
        },
        "f891da403eab41d8b36e00c9a80bda05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e37097922e714c83a33adb70e3c873ee",
            "placeholder": "​",
            "style": "IPY_MODEL_97a1b0742e10463eaae06d0731f09713",
            "value": " 5000/5000 [20:19&lt;00:00,  4.14it/s]"
          }
        },
        "6032e5f7f1c44c0cbb7c196f71d8aaad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6b5824ff1f246dcb1ca39299aca113b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c202b00910140c78de69988ce617fee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e246f87fefed4dd697df9d8638f71c6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f713c028dbef4a358d65cdf5e3be017e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e37097922e714c83a33adb70e3c873ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97a1b0742e10463eaae06d0731f09713": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08deed2411804061ad99dd900fcfc094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8012ed55e30442eb99a8e7c216879844",
              "IPY_MODEL_a4bab5cfe52049da9d095c26b11cec9d",
              "IPY_MODEL_1f6f2826adfe4abbb647b7f1b90bca47"
            ],
            "layout": "IPY_MODEL_f4321f2b8a5f40caa7f313402d74a126"
          }
        },
        "8012ed55e30442eb99a8e7c216879844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_575ed395f6d94ff1a8e8fdfb37a3ed95",
            "placeholder": "​",
            "style": "IPY_MODEL_be5991d0e8cb4e49a8dc4f10b739736b",
            "value": "100%"
          }
        },
        "a4bab5cfe52049da9d095c26b11cec9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_263ebd3f22de4b65a243f06f5e384b53",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4893e3821884f009c60ce0f0a71067a",
            "value": 25
          }
        },
        "1f6f2826adfe4abbb647b7f1b90bca47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43c95502b9a74c3186496d69acfc45f4",
            "placeholder": "​",
            "style": "IPY_MODEL_2482751a70eb40c6a77f17881ee621ff",
            "value": " 25/25 [00:01&lt;00:00, 16.53it/s]"
          }
        },
        "f4321f2b8a5f40caa7f313402d74a126": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "575ed395f6d94ff1a8e8fdfb37a3ed95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be5991d0e8cb4e49a8dc4f10b739736b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "263ebd3f22de4b65a243f06f5e384b53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4893e3821884f009c60ce0f0a71067a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43c95502b9a74c3186496d69acfc45f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2482751a70eb40c6a77f17881ee621ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zwimpee/cursivetransformer/blob/main/cursivetransformer_dictionary_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cursive Transformer Mechanistic Interpretability\n",
        "---\n",
        "## Introduction\n",
        "The purpose of this notebook is to apply the techniques of mechanistic interpretability, in particular dictionary learning, to our cursive transformer. The goal of this exercise is two-fold:\n",
        "1. Attempt to gain insight into the structure and orientation of the features being learned by the model, in particular in the cross-attention and feed-forward layers\n",
        "2. More generally become familiar with the latest ME techniques, as they can easily transfer to be applied beyond the scope of this project to essentially ANY transformer-based model\n",
        "\n",
        "To this end, we will reference the following resources throughout this document:\n",
        "- https://transformer-circuits.pub/2023/monosemantic-features\n",
        "- https://www.alignmentforum.org/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s\n",
        "- https://colab.research.google.com/drive/1u8larhpxy8w4mMsJiSBddNOzFGj7_RTn?usp=sharing\n",
        "- https://github.com/TransformerLensOrg/TransformerLens\n",
        "- https://arena3-chapter1-transformer-interp.streamlit.app/"
      ],
      "metadata": {
        "id": "GdwBlsu_am35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "JuHwKIaP3Oyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -V"
      ],
      "metadata": {
        "id": "12UmRQ9N3Rav",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab523ba9-0658-4d74-8dc1-8b81c62a0041"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "5BpggN2t3Qr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformer_lens\n",
        "!pip install gradio\n",
        "!pip install wandb\n",
        "!pip install einops\n",
        "!pip install matplotlib\n",
        "!pip install datasets\n",
        "\n",
        "# Clone the cursivetransformer repository and install its requirements\n",
        "!rm -rf cursivetransformer && git clone https://github.com/zwimpee/cursivetransformer.git\n",
        "!pip install -r cursivetransformer/requirements.txt\n",
        "\n",
        "# Login to Weights & Biases (replace 'your_api_key' with your actual API key)\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "VY-xjph_3QkR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d73a3f0-a7fe-4fe9-876f-7f117894891a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformer_lens in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.34.2)\n",
            "Requirement already satisfied: beartype<0.15.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.14.1)\n",
            "Requirement already satisfied: better-abc<0.0.4,>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: datasets>=2.7.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (3.0.1)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.8.0)\n",
            "Requirement already satisfied: fancy-einsum>=0.0.3 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.0.3)\n",
            "Requirement already satisfied: jaxtyping>=0.2.11 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.34)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.1.4)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.8.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.4.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.5)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.44.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.18.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.10.5)\n",
            "Requirement already satisfied: typeguard==2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping>=0.2.11->transformer_lens) (2.13.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (2.14.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.44.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.115.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.24.7)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (10.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.11)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.6.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.3)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.31.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (12.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi<1.0->gradio) (0.38.6)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.2)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.14.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.8.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Cloning into 'cursivetransformer'...\n",
            "remote: Enumerating objects: 2384, done.\u001b[K\n",
            "remote: Counting objects: 100% (519/519), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 2384 (delta 435), reused 449 (delta 385), pack-reused 1865 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2384/2384), 32.08 MiB | 17.46 MiB/s, done.\n",
            "Resolving deltas: 100% (1349/1349), done.\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r cursivetransformer/requirements.txt (line 1)) (2.4.1+cu121)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from -r cursivetransformer/requirements.txt (line 2)) (0.18.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r cursivetransformer/requirements.txt (line 3)) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r cursivetransformer/requirements.txt (line 4)) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r cursivetransformer/requirements.txt (line 5)) (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->-r cursivetransformer/requirements.txt (line 1)) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r cursivetransformer/requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->-r cursivetransformer/requirements.txt (line 1)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r cursivetransformer/requirements.txt (line 1)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->-r cursivetransformer/requirements.txt (line 1)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r cursivetransformer/requirements.txt (line 1)) (2024.6.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (2.14.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb->-r cursivetransformer/requirements.txt (line 2)) (71.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r cursivetransformer/requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r cursivetransformer/requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->-r cursivetransformer/requirements.txt (line 2)) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r cursivetransformer/requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r cursivetransformer/requirements.txt (line 2)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r cursivetransformer/requirements.txt (line 2)) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r cursivetransformer/requirements.txt (line 2)) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->-r cursivetransformer/requirements.txt (line 1)) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->-r cursivetransformer/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r cursivetransformer/requirements.txt (line 2)) (5.0.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzwimpee\u001b[0m (\u001b[33mllm-lab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "cWhbLc-33V2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/cursivetransformer')  # Adjust the path if necessary\n",
        "\n",
        "# Import cursivetransformer modules\n",
        "from cursivetransformer.model import get_all_args, get_checkpoint\n",
        "from cursivetransformer.data import create_datasets, offsets_to_strokes\n",
        "from cursivetransformer.sample import generate_n_words, plot_strokes\n",
        "\n",
        "# Import other necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import pprint\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "from IPython.display import HTML, display\n",
        "from functools import partial\n",
        "import tqdm.notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "xit1BQED3ZK_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Autoencoder"
      ],
      "metadata": {
        "id": "NkFwM1If3bbO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1p4_vsXeZigM"
      },
      "outputs": [],
      "source": [
        "# Configuration for the autoencoder\n",
        "cfg = {\n",
        "    \"seed\": 49,\n",
        "    \"batch_size\": 4096,\n",
        "    \"buffer_mult\": 384,\n",
        "    \"lr\": 1e-4,\n",
        "    \"num_tokens\": int(2e9),\n",
        "    \"l1_coeff\": 3e-4,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.99,\n",
        "    \"dict_mult\": 8,\n",
        "    \"seq_len\": 256,\n",
        "    \"d_mlp\": None,  # To be set after loading the model\n",
        "    \"enc_dtype\": \"fp32\",\n",
        "    \"remove_rare_dir\": False,\n",
        "}\n",
        "\n",
        "cfg[\"model_batch_size\"] = 64\n",
        "cfg[\"buffer_size\"] = cfg[\"batch_size\"] * cfg[\"buffer_mult\"]\n",
        "cfg[\"buffer_batches\"] = cfg[\"buffer_size\"] // cfg[\"seq_len\"]\n",
        "\n",
        "DTYPES = {\"fp32\": torch.float32, \"fp16\": torch.float16, \"bf16\": torch.bfloat16}\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        d_hidden = cfg[\"d_mlp\"] * cfg[\"dict_mult\"]\n",
        "        d_mlp = cfg[\"d_mlp\"]\n",
        "        l1_coeff = cfg[\"l1_coeff\"]\n",
        "        dtype = DTYPES[cfg[\"enc_dtype\"]]\n",
        "        torch.manual_seed(cfg[\"seed\"])\n",
        "        self.W_enc = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_mlp, d_hidden, dtype=dtype)))\n",
        "        self.W_dec = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, d_mlp, dtype=dtype)))\n",
        "        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n",
        "        self.b_dec = nn.Parameter(torch.zeros(d_mlp, dtype=dtype))\n",
        "\n",
        "        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        self.d_hidden = d_hidden\n",
        "        self.l1_coeff = l1_coeff\n",
        "\n",
        "        self.to(\"cuda\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cent = x - self.b_dec\n",
        "        acts = F.relu(x_cent @ self.W_enc + self.b_enc)\n",
        "        x_reconstruct = acts @ self.W_dec + self.b_dec\n",
        "        l2_loss = (x_reconstruct.float() - x.float()).pow(2).sum(-1).mean(0)\n",
        "        l1_loss = self.l1_coeff * (acts.float().abs().sum())\n",
        "        loss = l2_loss + l1_loss\n",
        "        return loss, x_reconstruct, acts, l2_loss, l1_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def remove_parallel_component_of_grads(self):\n",
        "        W_dec_normed = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "        W_dec_grad_proj = (self.W_dec.grad * W_dec_normed).sum(-1, keepdim=True) * W_dec_normed\n",
        "        self.W_dec.grad -= W_dec_grad_proj"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils\n",
        "\n"
      ],
      "metadata": {
        "id": "TDksX_ZQ3lcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Reconstruction Loss"
      ],
      "metadata": {
        "id": "iDiByoQV3kvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recons_loss(num_batches=5, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    loss_list = []\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for i in range(num_batches):\n",
        "        idx = torch.randperm(len(all_tokens))[:cfg[\"model_batch_size\"]]\n",
        "        tokens = all_tokens[idx].to(model_device)\n",
        "        context = all_contexts[idx].to(model_device)\n",
        "        targets = all_targets[idx].to(model_device)\n",
        "\n",
        "        # Capture MLP activations\n",
        "        mlp_activations = []\n",
        "\n",
        "        def capture_mlp_activations(module, input, output):\n",
        "            mlp_activations.append(output.detach())\n",
        "\n",
        "        # Register the hook on the MLP output layer\n",
        "        mlp_layer = model.transformer.h[0].mlp.c_proj  # Adjust layer index as needed\n",
        "        hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "        # Forward pass without hooks\n",
        "        logits, loss = model(tokens, context, targets=targets)\n",
        "        loss = loss.item()\n",
        "\n",
        "        # Remove the hook\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Get the activations\n",
        "        mlp_acts = mlp_activations[0]  # Shape: [batch_size, seq_len, d_mlp]\n",
        "\n",
        "        # Flatten activations\n",
        "        mlp_acts_flattened = mlp_acts.reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "        # Reconstruct activations using encoder\n",
        "        loss_enc, x_reconstruct, hidden_acts, l2_loss, l1_loss = local_encoder(mlp_acts_flattened)\n",
        "\n",
        "        # Reconstructed activations reshaped back to original shape\n",
        "        reconstructed_acts = x_reconstruct.view_as(mlp_acts)\n",
        "\n",
        "        # Define the hook to replace activations\n",
        "        def reconstruction_hook(module, input, output):\n",
        "            return reconstructed_acts\n",
        "\n",
        "        # Register the reconstruction hook\n",
        "        hook_handle = mlp_layer.register_forward_hook(reconstruction_hook)\n",
        "        # Forward pass with reconstructed activations\n",
        "        logits_recons, loss_recons = model(tokens, context, targets=targets)\n",
        "        recons_loss = loss_recons.item()\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Zero ablation\n",
        "        def zero_ablation_hook(module, input, output):\n",
        "            return torch.zeros_like(output)\n",
        "\n",
        "        hook_handle = mlp_layer.register_forward_hook(zero_ablation_hook)\n",
        "        logits_zero_abl, loss_zero_abl = model(tokens, context, targets=targets)\n",
        "        zero_abl_loss = loss_zero_abl.item()\n",
        "        hook_handle.remove()\n",
        "\n",
        "        loss_list.append((loss, recons_loss, zero_abl_loss))\n",
        "    losses = torch.tensor(loss_list)\n",
        "    loss, recons_loss, zero_abl_loss = losses.mean(0).tolist()\n",
        "\n",
        "    print(f\"loss: {loss:.4f}, recons_loss: {recons_loss:.4f}, zero_abl_loss: {zero_abl_loss:.4f}\")\n",
        "    score = ((zero_abl_loss - recons_loss) / (zero_abl_loss - loss))\n",
        "    print(f\"Reconstruction Score: {score:.2%}\")\n",
        "    return score, loss, recons_loss, zero_abl_loss"
      ],
      "metadata": {
        "id": "pxQjA1Xh3pgP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Frequencies"
      ],
      "metadata": {
        "id": "j1dKdlV13rTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_freqs(num_batches=25, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    act_freq_scores = torch.zeros(local_encoder.d_hidden, dtype=torch.float32).cuda()\n",
        "    total = 0\n",
        "    for i in tqdm.trange(num_batches):\n",
        "        idx = torch.randperm(len(all_tokens))[:cfg[\"model_batch_size\"]]\n",
        "        tokens = all_tokens[idx].to(model_device)\n",
        "        context = all_contexts[idx].to(model_device)\n",
        "\n",
        "        mlp_activations = []\n",
        "\n",
        "        def capture_mlp_activations(module, input, output):\n",
        "            mlp_activations.append(output.detach())\n",
        "\n",
        "        # Register the hook on the MLP output layer\n",
        "        mlp_layer = model.transformer.h[0].mlp.c_proj  # Adjust layer index as needed\n",
        "        hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "        # Forward pass\n",
        "        logits, _ = model(tokens, context)\n",
        "        # Remove the hook\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Get the activations\n",
        "        mlp_acts = mlp_activations[0]  # Shape: [batch_size, seq_len, d_mlp]\n",
        "        mlp_acts_flattened = mlp_acts.reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "        # Pass through encoder\n",
        "        hidden = local_encoder(mlp_acts_flattened)[2]  # Get the activations\n",
        "\n",
        "        act_freq_scores += (hidden > 0).sum(0)\n",
        "        total += hidden.shape[0]\n",
        "    act_freq_scores /= total\n",
        "    num_dead = (act_freq_scores == 0).float().mean()\n",
        "    print(\"Num dead\", num_dead.item())\n",
        "    return act_freq_scores"
      ],
      "metadata": {
        "id": "kbDgvhpS3vnU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualise Feature Utils"
      ],
      "metadata": {
        "id": "kk1mA6FK3y0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from html import escape\n",
        "import colorsys\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "SPACE = \"·\"\n",
        "NEWLINE = \"↩\"\n",
        "TAB = \"→\"\n",
        "\n",
        "def create_html(strings, values, max_value=None, saturation=0.5, allow_different_length=False, return_string=False):\n",
        "    # Escape strings to deal with tabs, newlines, etc.\n",
        "    escaped_strings = [escape(s, quote=True) for s in strings]\n",
        "    processed_strings = [\n",
        "        s.replace(\"\\n\", f\"{NEWLINE}<br/>\").replace(\"\\t\", f\"{TAB}&emsp;\").replace(\" \", \"&nbsp;\")\n",
        "        for s in escaped_strings\n",
        "    ]\n",
        "\n",
        "    if isinstance(values, torch.Tensor) and len(values.shape) > 1:\n",
        "        values = values.flatten().tolist()\n",
        "\n",
        "    if not allow_different_length:\n",
        "        assert len(processed_strings) == len(values)\n",
        "\n",
        "    # Scale values\n",
        "    if max_value is None:\n",
        "        max_value = max(max(values), -min(values)) + 1e-3\n",
        "    scaled_values = [v / max_value * saturation for v in values]\n",
        "\n",
        "    # Create HTML\n",
        "    html = \"\"\n",
        "    for i, s in enumerate(processed_strings):\n",
        "        if i < len(scaled_values):\n",
        "            v = scaled_values[i]\n",
        "        else:\n",
        "            v = 0\n",
        "        if v < 0:\n",
        "            hue = 0  # Red in HSV\n",
        "        else:\n",
        "            hue = 0.66  # Blue in HSV\n",
        "        rgb_color = colorsys.hsv_to_rgb(\n",
        "            hue, v, 1\n",
        "        )\n",
        "        hex_color = \"#%02x%02x%02x\" % (\n",
        "            int(rgb_color[0] * 255),\n",
        "            int(rgb_color[1] * 255),\n",
        "            int(rgb_color[2] * 255),\n",
        "        )\n",
        "        html += f'<span style=\"background-color: {hex_color}; border: 1px solid lightgray; font-size: 16px; border-radius: 3px;\">{s}</span>'\n",
        "    if return_string:\n",
        "        return html\n",
        "    else:\n",
        "        display(HTML(html))\n",
        "\n",
        "# - [ ] TODO: <-DEBUG THIS!!!\n",
        "def stroke_to_svg(stroke_sequence):\n",
        "    # This function generates an SVG path for the stroke sequence\n",
        "    svg_output = \"\"\n",
        "    pen_down = False\n",
        "    for point in stroke_sequence:\n",
        "        x, y, pen = point\n",
        "        if pen == 1:\n",
        "            if not pen_down:\n",
        "                svg_output += f'M {x},{y} '\n",
        "                pen_down = True\n",
        "            else:\n",
        "                svg_output += f'L {x},{y} '\n",
        "        else:\n",
        "            pen_down = False\n",
        "    svg_element = f'<path d=\"{svg_output}\" style=\"stroke:black;fill:none;\" />'\n",
        "    return svg_element\n",
        "\n",
        "# def stroke_to_svg(stroke_sequence):\n",
        "#     # This function generates an SVG path for each stroke in the sequence\n",
        "#     svg_output = \"\"\n",
        "#     for stroke in stroke_sequence:\n",
        "#         if stroke[2] == 0:\n",
        "#           continue\n",
        "#         svg_output += f'<path d=\"M{stroke[0]},{stroke[1]}'\n",
        "#         # for point in stroke[1:]:\n",
        "#         #     svg_output += f' L{point[0]},{point[1]}'\n",
        "#     svg_output += '\" style=\"stroke:black;fill:none;\" />'\n",
        "#     return svg_output\n",
        "\n",
        "def basic_feature_vis(text, feature_index, max_val=0):\n",
        "    feature_in = encoder.W_enc[:, feature_index]\n",
        "    feature_bias = encoder.b_enc[feature_index]\n",
        "\n",
        "    # Encode the context text\n",
        "    c = test_dataset.encode_text(text).unsqueeze(0).to(model_device)  # Context tokens\n",
        "\n",
        "    # Initialize tokens with a START token or zeros\n",
        "    # Assuming START_TOKEN is defined in your dataset\n",
        "    START_TOKEN = test_dataset.END_TOKEN  # Using END_TOKEN as a placeholder\n",
        "    x = torch.full((1, 1), START_TOKEN, dtype=torch.long).to(model_device)  # Initial token\n",
        "\n",
        "    # Generate stroke tokens conditioned on the context text\n",
        "    max_new_tokens = args.max_seq_length - 1  # Adjust based on your sequence length\n",
        "    tokens = generate(model, x, c, max_new_tokens, temperature=1.0, do_sample=False).to(model_device)\n",
        "\n",
        "    # Capture MLP activations\n",
        "    mlp_activations = []\n",
        "\n",
        "    def capture_mlp_activations(module, input, output):\n",
        "        mlp_activations.append(output.detach())\n",
        "\n",
        "    # Register the hook\n",
        "    mlp_layer = model.transformer.h[0].mlp.c_proj\n",
        "    hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "    # Forward pass with the generated tokens and context\n",
        "    logits, _ = model(tokens, c)\n",
        "    hook_handle.remove()\n",
        "\n",
        "    # Get the activations\n",
        "    mlp_acts = mlp_activations[0][0].cpu()  # Shape: [seq_len, d_mlp]\n",
        "    feature_acts = F.relu((mlp_acts - encoder.b_dec.cpu()) @ feature_in.cpu() + feature_bias.cpu())\n",
        "\n",
        "    if max_val == 0:\n",
        "        max_val = max(1e-7, feature_acts.max().item())\n",
        "\n",
        "    # Decode stroke tokens back to the original stroke format\n",
        "    stroke_sequence = [offsets_to_strokes(test_dataset.decode_stroke(t)) for t in tokens]\n",
        "\n",
        "    # Convert decoded strokes to SVG format for visualization\n",
        "    stroke_svgs = [stroke_to_svg(stroke) for stroke in stroke_sequence]\n",
        "\n",
        "    # Flatten the lists if necessary\n",
        "    stroke_svgs = [item for sublist in stroke_svgs for item in sublist]\n",
        "    feature_acts = feature_acts.flatten()\n",
        "\n",
        "    # Ensure the lengths match\n",
        "    min_length = min(len(stroke_svgs), len(feature_acts))\n",
        "    stroke_svgs = stroke_svgs[:min_length]\n",
        "    feature_acts = feature_acts[:min_length]\n",
        "\n",
        "    return basic_token_vis_make_str(stroke_svgs, feature_acts, max_val)\n",
        "\n",
        "# def basic_feature_vis(feature_index, max_val=0):\n",
        "#     feature_in = encoder.W_enc[:, feature_index]\n",
        "#     feature_bias = encoder.b_enc[feature_index]\n",
        "\n",
        "#     # Get a sample stroke sequence and context from the dataset\n",
        "#     x, c, _ = test_dataset[0]  # You can choose any index or randomize\n",
        "#     tokens = x.unsqueeze(0).to(model_device)  # Stroke tokens\n",
        "#     context = c.unsqueeze(0).to(model_device)  # Context tokens\n",
        "\n",
        "#     # Capture MLP activations\n",
        "#     mlp_activations = []\n",
        "\n",
        "#     def capture_mlp_activations(module, input, output):\n",
        "#         mlp_activations.append(output.detach())\n",
        "\n",
        "#     # Register the hook\n",
        "#     mlp_layer = model.transformer.h[0].mlp.c_proj\n",
        "#     hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "#     # Forward pass\n",
        "#     logits, _ = model(tokens, context)\n",
        "#     hook_handle.remove()\n",
        "\n",
        "#     # Get the activations\n",
        "#     mlp_acts = mlp_activations[0][0].cpu()  # Shape: [seq_len, d_mlp]\n",
        "#     feature_acts = F.relu((mlp_acts - encoder.b_dec.cpu()) @ feature_in.cpu() + feature_bias.cpu())\n",
        "#     if max_val == 0:\n",
        "#         max_val = max(1e-7, feature_acts.max().item())\n",
        "\n",
        "#     # Decode stroke tokens back to the original stroke format\n",
        "#     stroke_sequence = [offsets_to_strokes(test_dataset.decode_stroke(t)) for t in tokens]\n",
        "\n",
        "#     # Convert decoded strokes to SVG format for visualization\n",
        "#     stroke_svgs = [stroke_to_svg(stroke) for stroke in stroke_sequence]\n",
        "\n",
        "#     return basic_token_vis_make_str(stroke_svgs, feature_acts, max_val)\n",
        "\n",
        "\n",
        "def basic_token_vis_make_str(strings, values, max_val=None):\n",
        "    if not isinstance(strings, list):\n",
        "        strings = list(strings)\n",
        "    values = values.detach().numpy()\n",
        "    if max_val is None:\n",
        "        max_val = values.max()\n",
        "    header_string = f\"<h4>Max Range <b>{values.max():.4f}</b> Min Range: <b>{values.min():.4f}</b></h4>\"\n",
        "    header_string += f\"<h4>Set Max Range <b>{max_val:.4f}</b></h4>\"\n",
        "    body_string = create_html(strings, values, max_value=max_val, return_string=True, allow_different_length=True)\n",
        "    return header_string + body_string"
      ],
      "metadata": {
        "id": "I9jLMFym32Yw"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Token DataFrame"
      ],
      "metadata": {
        "id": "NZmEcWIx34gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_token_df(tokens, len_prefix=5, len_suffix=1):\n",
        "    str_tokens = [str(t.item()) for t in tokens]\n",
        "    unique_token = [f\"{s}/{i}\" for i, s in enumerate(str_tokens)]\n",
        "\n",
        "    context = []\n",
        "    batch = []\n",
        "    pos = []\n",
        "    label = []\n",
        "    for p in range(len(tokens)):\n",
        "        prefix = \"\".join(str_tokens[max(0, p - len_prefix):p])\n",
        "        if p == len(tokens) - 1:\n",
        "            suffix = \"\"\n",
        "        else:\n",
        "            suffix = \"\".join(str_tokens[p + 1:min(len(tokens) - 1, p + 1 + len_suffix)])\n",
        "        current = str_tokens[p]\n",
        "        context.append(f\"{prefix}|{current}|{suffix}\")\n",
        "        batch.append(0)  # Since we have a single batch\n",
        "        pos.append(p)\n",
        "        label.append(f\"{0}/{p}\")\n",
        "    return pd.DataFrame(dict(\n",
        "        str_tokens=str_tokens,\n",
        "        unique_token=unique_token,\n",
        "        context=context,\n",
        "        batch=batch,\n",
        "        pos=pos,\n",
        "        label=label,\n",
        "    ))"
      ],
      "metadata": {
        "id": "j3py2Keq37VI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Model"
      ],
      "metadata": {
        "id": "rpgE-1vu37QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = get_all_args(False)\n",
        "args.sample_only = True\n",
        "args.load_from_run_id = '6le6tujz'  # Replace with your actual run ID\n",
        "args.wandb_entity = 'sam-greydanus'\n",
        "args.dataset_name = 'bigbank'  # Replace with your dataset name\n",
        "args.wandb_run_name = 'cursivetransformer_dictionary_learning'\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "train_dataset, test_dataset = create_datasets(args)\n",
        "\n",
        "args.block_size = train_dataset.get_stroke_seq_length()\n",
        "args.context_block_size = train_dataset.get_text_seq_length()\n",
        "args.vocab_size = train_dataset.get_vocab_size()\n",
        "args.context_vocab_size = train_dataset.get_char_vocab_size()\n",
        "\n",
        "model, optimizer, scheduler, step, best_loss = get_checkpoint(args)\n",
        "\n",
        "\n",
        "cfg[\"d_mlp\"] = args.n_embd  # Assuming n_embd is the MLP dimension\n",
        "args"
      ],
      "metadata": {
        "id": "Fb6qP_3i72fU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e4e00a0-74da-43ed-fedd-9df5b2e8af78"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "For a dataset of 1805 examples we can generate 440811596555 combinations of 4 examples.\n",
            "Generating 497000 4-word examples.\n",
            "For a dataset of 95 examples we can generate 3183545 combinations of 4 examples.\n",
            "Generating 3000 4-word examples.\n",
            "Number of examples in the train dataset: 497000\n",
            "Number of examples in the test dataset: 3000\n",
            "Max token sequence length: 1000\n",
            "Number of unique characters in the ascii vocabulary: 71\n",
            "Ascii vocabulary:\n",
            "\t\" enaitoshrdx.vpukbgfcymzw1lqj804I92637OTAS5N)EHR\"'(BCQLMWYU,ZF!DXV?KPGJ\"\n",
            "Split up the dataset into 497000 training examples and 3000 test examples\n",
            "Number of Transformer parameters: 368064\n",
            "Model #params: 397184\n",
            "Loaded model from local path: best_checkpoint.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(max_steps=110000,\n",
              "          print_every=100,\n",
              "          log_every=2500,\n",
              "          lr_decay=0.333,\n",
              "          step_lr_every=33000,\n",
              "          device='cuda',\n",
              "          seed=42,\n",
              "          n_layer=4,\n",
              "          n_embd=64,\n",
              "          n_embd2=64,\n",
              "          n_ctx_head=4,\n",
              "          learning_rate=0.01,\n",
              "          weight_decay=0.0001,\n",
              "          batch_size=32,\n",
              "          train_size=497000,\n",
              "          test_size=3000,\n",
              "          num_words=4,\n",
              "          max_seq_length=1000,\n",
              "          augment=True,\n",
              "          ablate_cross_attention=False,\n",
              "          downsample_mean=0.65,\n",
              "          downsample_width=0.1,\n",
              "          add_digits=True,\n",
              "          alphabet=' enaitoshrdx.vpukbgfcymzw1lqj804I92637OTAS5N)EHR\"\\'(BCQLMWYU,ZF!DXV?KPGJ',\n",
              "          dataset_name='bigbank',\n",
              "          wandb_project='bigbank_experiments',\n",
              "          wandb_entity='sam-greydanus',\n",
              "          wandb_run_name='cursivetransformer_dictionary_learning',\n",
              "          wandb_api_key=None,\n",
              "          load_from_run_id='6le6tujz',\n",
              "          sample_only=True,\n",
              "          local_checkpoint_path='best_checkpoint.pt',\n",
              "          block_size=1000,\n",
              "          context_block_size=50,\n",
              "          vocab_size=455,\n",
              "          context_vocab_size=72)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_device = 'cuda'\n",
        "model = model.to(model_device)\n",
        "model = model.eval()  # Set model to evaluation mode"
      ],
      "metadata": {
        "id": "f650Kjl_O-P4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate N words"
      ],
      "metadata": {
        "id": "SwtqsUG93UO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "point_samp = generate_n_words(model, test_dataset, \"Sample text for visualization\", model_device='cuda', n_words = 4)\n",
        "_ = plot_strokes(point_samp, \"Example output for `generate_n_words`\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "ZHApTdJk3TbF",
        "outputId": "0c72c24f-3117-49e9-9b2d-f784d44a4bd6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "hTPC8yxS4DNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = cfg[\"model_batch_size\"] # - [ ] TODO: Determine if this is needed?\n",
        "num_samples = len(test_dataset)\n",
        "stroke_seqs = []\n",
        "contexts = []\n",
        "targets = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "    x, c, y = test_dataset[i]\n",
        "    stroke_seqs.append(x)\n",
        "    contexts.append(c)\n",
        "    targets.append(y)\n",
        "\n",
        "all_tokens = torch.stack(stroke_seqs)\n",
        "all_contexts = torch.stack(contexts)\n",
        "all_targets = torch.stack(targets)"
      ],
      "metadata": {
        "id": "nAEcf7h_4DFN"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "q7_RwgFV4Mln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Autoencoder"
      ],
      "metadata": {
        "id": "JwmkLrrc4Cv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = AutoEncoder(cfg)"
      ],
      "metadata": {
        "id": "Yiea6x6o4Q69"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Autoencoder"
      ],
      "metadata": {
        "id": "u4f-J5kyOa9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sae(model, encoder, num_batches=5000, batch_size=256):\n",
        "    optimizer = torch.optim.Adam(encoder.parameters(), lr=cfg['lr'], betas=(cfg['beta1'], cfg['beta2']))\n",
        "\n",
        "    for batch in tqdm.tqdm(range(num_batches)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Sample data\n",
        "        idx = torch.randperm(len(all_tokens))[:batch_size]\n",
        "        tokens = all_tokens[idx].to(model_device)\n",
        "        contexts = all_contexts[idx].to(model_device)\n",
        "\n",
        "        # Capture MLP activations\n",
        "        mlp_activations = []\n",
        "        def capture_mlp_activations(module, input, output):\n",
        "            mlp_activations.append(output.detach())\n",
        "\n",
        "        # Register the hook\n",
        "        mlp_layer = model.transformer.h[0].mlp.c_proj\n",
        "        hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            _ = model(tokens, contexts)\n",
        "\n",
        "        # Remove the hook\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Get the activations\n",
        "        mlp_acts = mlp_activations[0].reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "        # Pass through encoder\n",
        "        loss, _, _, l2_loss, l1_loss = encoder(mlp_acts)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            print(f\"Batch {batch}, Loss: {loss.item():.4f}, L2 Loss: {l2_loss.item():.4f}, L1 Loss: {l1_loss.item():.4f}\")\n",
        "\n",
        "    print(\"SAE training completed.\")\n",
        "\n",
        "# Train the SAE\n",
        "train_sae(model, encoder)\n",
        "# Save the encoder weights\n",
        "# torch.save(encoder.state_dict(), 'encoder_weights.pth')"
      ],
      "metadata": {
        "id": "FAgTAimjOajl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "55b06a6cfffa4f208c7de76c8fc96553",
            "0937ac49cd88433bad658cc6ce264219",
            "fbc5d20e911847edbd64ff4bb2fed314",
            "f891da403eab41d8b36e00c9a80bda05",
            "6032e5f7f1c44c0cbb7c196f71d8aaad",
            "d6b5824ff1f246dcb1ca39299aca113b",
            "5c202b00910140c78de69988ce617fee",
            "e246f87fefed4dd697df9d8638f71c6c",
            "f713c028dbef4a358d65cdf5e3be017e",
            "e37097922e714c83a33adb70e3c873ee",
            "97a1b0742e10463eaae06d0731f09713"
          ]
        },
        "outputId": "845fa51d-8e05-4c97-b7d9-2acb34101a1a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55b06a6cfffa4f208c7de76c8fc96553"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0, Loss: 241332.0938, L2 Loss: 75172.5859, L1 Loss: 166159.5000\n",
            "Batch 10, Loss: 214066.2812, L2 Loss: 56957.3203, L1 Loss: 157108.9688\n",
            "Batch 20, Loss: 199604.7500, L2 Loss: 46454.2109, L1 Loss: 153150.5469\n",
            "Batch 30, Loss: 181658.2812, L2 Loss: 37208.3477, L1 Loss: 144449.9375\n",
            "Batch 40, Loss: 155653.8594, L2 Loss: 28417.0527, L1 Loss: 127236.8125\n",
            "Batch 50, Loss: 148265.1719, L2 Loss: 25845.4805, L1 Loss: 122419.6953\n",
            "Batch 60, Loss: 139325.7031, L2 Loss: 23541.7852, L1 Loss: 115783.9219\n",
            "Batch 70, Loss: 129620.6562, L2 Loss: 21665.4883, L1 Loss: 107955.1719\n",
            "Batch 80, Loss: 122666.4688, L2 Loss: 20573.6719, L1 Loss: 102092.7969\n",
            "Batch 90, Loss: 114763.4141, L2 Loss: 19429.5312, L1 Loss: 95333.8828\n",
            "Batch 100, Loss: 105333.3516, L2 Loss: 18193.7402, L1 Loss: 87139.6094\n",
            "Batch 110, Loss: 101712.8750, L2 Loss: 18118.3906, L1 Loss: 83594.4844\n",
            "Batch 120, Loss: 94465.1953, L2 Loss: 17316.6172, L1 Loss: 77148.5781\n",
            "Batch 130, Loss: 89969.6406, L2 Loss: 17097.2930, L1 Loss: 72872.3516\n",
            "Batch 140, Loss: 86069.7188, L2 Loss: 16942.2559, L1 Loss: 69127.4609\n",
            "Batch 150, Loss: 80839.1094, L2 Loss: 16384.8477, L1 Loss: 64454.2656\n",
            "Batch 160, Loss: 75551.2109, L2 Loss: 15653.0127, L1 Loss: 59898.1953\n",
            "Batch 170, Loss: 72814.1250, L2 Loss: 15551.1367, L1 Loss: 57262.9844\n",
            "Batch 180, Loss: 68683.5938, L2 Loss: 15070.3984, L1 Loss: 53613.1992\n",
            "Batch 190, Loss: 66559.0547, L2 Loss: 14999.9482, L1 Loss: 51559.1055\n",
            "Batch 200, Loss: 64067.0859, L2 Loss: 14862.6504, L1 Loss: 49204.4336\n",
            "Batch 210, Loss: 60956.1953, L2 Loss: 14515.5020, L1 Loss: 46440.6953\n",
            "Batch 220, Loss: 58507.7734, L2 Loss: 14263.4707, L1 Loss: 44244.3047\n",
            "Batch 230, Loss: 56312.1797, L2 Loss: 14007.5986, L1 Loss: 42304.5820\n",
            "Batch 240, Loss: 53820.8984, L2 Loss: 13630.8232, L1 Loss: 40190.0742\n",
            "Batch 250, Loss: 53507.6836, L2 Loss: 13912.9570, L1 Loss: 39594.7266\n",
            "Batch 260, Loss: 49935.6719, L2 Loss: 13262.7432, L1 Loss: 36672.9297\n",
            "Batch 270, Loss: 48823.1484, L2 Loss: 13209.5645, L1 Loss: 35613.5859\n",
            "Batch 280, Loss: 47711.4688, L2 Loss: 13185.2402, L1 Loss: 34526.2305\n",
            "Batch 290, Loss: 45123.8828, L2 Loss: 12763.4648, L1 Loss: 32360.4199\n",
            "Batch 300, Loss: 44920.4648, L2 Loss: 12851.8125, L1 Loss: 32068.6523\n",
            "Batch 310, Loss: 44084.5898, L2 Loss: 12760.1309, L1 Loss: 31324.4590\n",
            "Batch 320, Loss: 42204.5703, L2 Loss: 12530.6660, L1 Loss: 29673.9062\n",
            "Batch 330, Loss: 41808.5000, L2 Loss: 12526.6309, L1 Loss: 29281.8691\n",
            "Batch 340, Loss: 39408.5352, L2 Loss: 12207.8047, L1 Loss: 27200.7305\n",
            "Batch 350, Loss: 38755.3711, L2 Loss: 12178.4736, L1 Loss: 26576.8984\n",
            "Batch 360, Loss: 38425.8672, L2 Loss: 12191.8203, L1 Loss: 26234.0469\n",
            "Batch 370, Loss: 38156.6875, L2 Loss: 12197.3682, L1 Loss: 25959.3184\n",
            "Batch 380, Loss: 36103.2031, L2 Loss: 11907.2822, L1 Loss: 24195.9219\n",
            "Batch 390, Loss: 35840.3281, L2 Loss: 11967.2070, L1 Loss: 23873.1230\n",
            "Batch 400, Loss: 35238.7539, L2 Loss: 11846.6611, L1 Loss: 23392.0938\n",
            "Batch 410, Loss: 33553.7500, L2 Loss: 11675.7676, L1 Loss: 21877.9844\n",
            "Batch 420, Loss: 33686.4023, L2 Loss: 11681.9639, L1 Loss: 22004.4375\n",
            "Batch 430, Loss: 32597.1895, L2 Loss: 11581.3945, L1 Loss: 21015.7949\n",
            "Batch 440, Loss: 32670.4453, L2 Loss: 11597.1943, L1 Loss: 21073.2520\n",
            "Batch 450, Loss: 31466.6484, L2 Loss: 11448.0303, L1 Loss: 20018.6191\n",
            "Batch 460, Loss: 31057.2734, L2 Loss: 11438.5186, L1 Loss: 19618.7559\n",
            "Batch 470, Loss: 31126.0391, L2 Loss: 11421.7920, L1 Loss: 19704.2480\n",
            "Batch 480, Loss: 30400.3672, L2 Loss: 11363.8105, L1 Loss: 19036.5566\n",
            "Batch 490, Loss: 29980.9023, L2 Loss: 11337.6787, L1 Loss: 18643.2227\n",
            "Batch 500, Loss: 28852.0820, L2 Loss: 11216.4326, L1 Loss: 17635.6504\n",
            "Batch 510, Loss: 29628.3984, L2 Loss: 11246.5859, L1 Loss: 18381.8125\n",
            "Batch 520, Loss: 28176.0430, L2 Loss: 11135.9668, L1 Loss: 17040.0762\n",
            "Batch 530, Loss: 28120.8008, L2 Loss: 11132.2764, L1 Loss: 16988.5234\n",
            "Batch 540, Loss: 28153.9023, L2 Loss: 11160.4795, L1 Loss: 16993.4219\n",
            "Batch 550, Loss: 27298.3379, L2 Loss: 11073.4141, L1 Loss: 16224.9238\n",
            "Batch 560, Loss: 27120.8828, L2 Loss: 11090.4180, L1 Loss: 16030.4648\n",
            "Batch 570, Loss: 26460.5938, L2 Loss: 10995.4746, L1 Loss: 15465.1182\n",
            "Batch 580, Loss: 26092.7969, L2 Loss: 11001.2686, L1 Loss: 15091.5293\n",
            "Batch 590, Loss: 25659.2656, L2 Loss: 10936.9707, L1 Loss: 14722.2939\n",
            "Batch 600, Loss: 24072.4863, L2 Loss: 10848.8340, L1 Loss: 13223.6523\n",
            "Batch 610, Loss: 25045.1406, L2 Loss: 10956.2842, L1 Loss: 14088.8555\n",
            "Batch 620, Loss: 26124.1680, L2 Loss: 10979.6670, L1 Loss: 15144.5000\n",
            "Batch 630, Loss: 25093.4824, L2 Loss: 10948.8223, L1 Loss: 14144.6602\n",
            "Batch 640, Loss: 24328.0273, L2 Loss: 10920.6748, L1 Loss: 13407.3525\n",
            "Batch 650, Loss: 24910.3164, L2 Loss: 10887.7324, L1 Loss: 14022.5830\n",
            "Batch 660, Loss: 24788.9102, L2 Loss: 10829.4980, L1 Loss: 13959.4111\n",
            "Batch 670, Loss: 24257.1445, L2 Loss: 10795.8115, L1 Loss: 13461.3330\n",
            "Batch 680, Loss: 24277.2500, L2 Loss: 10846.0156, L1 Loss: 13431.2334\n",
            "Batch 690, Loss: 24541.6680, L2 Loss: 10820.2715, L1 Loss: 13721.3955\n",
            "Batch 700, Loss: 23577.7031, L2 Loss: 10744.9346, L1 Loss: 12832.7695\n",
            "Batch 710, Loss: 23454.3203, L2 Loss: 10764.4229, L1 Loss: 12689.8965\n",
            "Batch 720, Loss: 22937.5215, L2 Loss: 10717.2988, L1 Loss: 12220.2227\n",
            "Batch 730, Loss: 22588.1836, L2 Loss: 10631.3594, L1 Loss: 11956.8242\n",
            "Batch 740, Loss: 23362.3281, L2 Loss: 10616.7129, L1 Loss: 12745.6162\n",
            "Batch 750, Loss: 22111.1816, L2 Loss: 10574.3398, L1 Loss: 11536.8418\n",
            "Batch 760, Loss: 22793.7754, L2 Loss: 10572.2285, L1 Loss: 12221.5469\n",
            "Batch 770, Loss: 22652.6211, L2 Loss: 10497.8184, L1 Loss: 12154.8037\n",
            "Batch 780, Loss: 22154.8320, L2 Loss: 10459.6768, L1 Loss: 11695.1562\n",
            "Batch 790, Loss: 22708.2148, L2 Loss: 10427.2266, L1 Loss: 12280.9873\n",
            "Batch 800, Loss: 22430.0234, L2 Loss: 10336.8203, L1 Loss: 12093.2021\n",
            "Batch 810, Loss: 22013.9961, L2 Loss: 10316.3047, L1 Loss: 11697.6914\n",
            "Batch 820, Loss: 21979.7812, L2 Loss: 10304.5088, L1 Loss: 11675.2725\n",
            "Batch 830, Loss: 21409.4961, L2 Loss: 10259.7021, L1 Loss: 11149.7930\n",
            "Batch 840, Loss: 20435.0352, L2 Loss: 10152.4023, L1 Loss: 10282.6338\n",
            "Batch 850, Loss: 21154.4629, L2 Loss: 10095.2021, L1 Loss: 11059.2607\n",
            "Batch 860, Loss: 20486.3340, L2 Loss: 10078.8379, L1 Loss: 10407.4961\n",
            "Batch 870, Loss: 21436.0508, L2 Loss: 10027.8623, L1 Loss: 11408.1895\n",
            "Batch 880, Loss: 21002.5078, L2 Loss: 9956.2061, L1 Loss: 11046.3018\n",
            "Batch 890, Loss: 21014.9648, L2 Loss: 9958.5205, L1 Loss: 11056.4434\n",
            "Batch 900, Loss: 21131.9238, L2 Loss: 9892.0801, L1 Loss: 11239.8438\n",
            "Batch 910, Loss: 20573.2422, L2 Loss: 9804.9268, L1 Loss: 10768.3145\n",
            "Batch 920, Loss: 20962.7305, L2 Loss: 9775.9062, L1 Loss: 11186.8232\n",
            "Batch 930, Loss: 20011.3828, L2 Loss: 9714.4873, L1 Loss: 10296.8955\n",
            "Batch 940, Loss: 20822.2656, L2 Loss: 9687.9629, L1 Loss: 11134.3037\n",
            "Batch 950, Loss: 20070.8477, L2 Loss: 9620.3438, L1 Loss: 10450.5039\n",
            "Batch 960, Loss: 20623.1406, L2 Loss: 9553.6533, L1 Loss: 11069.4873\n",
            "Batch 970, Loss: 20168.1133, L2 Loss: 9505.3955, L1 Loss: 10662.7178\n",
            "Batch 980, Loss: 20176.5195, L2 Loss: 9449.0664, L1 Loss: 10727.4521\n",
            "Batch 990, Loss: 20456.0312, L2 Loss: 9332.9658, L1 Loss: 11123.0645\n",
            "Batch 1000, Loss: 19352.3711, L2 Loss: 9361.6641, L1 Loss: 9990.7061\n",
            "Batch 1010, Loss: 19961.8867, L2 Loss: 9332.1240, L1 Loss: 10629.7637\n",
            "Batch 1020, Loss: 19654.5664, L2 Loss: 9284.6133, L1 Loss: 10369.9521\n",
            "Batch 1030, Loss: 19502.2500, L2 Loss: 9245.4121, L1 Loss: 10256.8369\n",
            "Batch 1040, Loss: 18936.8242, L2 Loss: 9164.6484, L1 Loss: 9772.1748\n",
            "Batch 1050, Loss: 19579.8359, L2 Loss: 9087.0127, L1 Loss: 10492.8232\n",
            "Batch 1060, Loss: 19224.4883, L2 Loss: 9104.7344, L1 Loss: 10119.7549\n",
            "Batch 1070, Loss: 19137.8672, L2 Loss: 9004.1846, L1 Loss: 10133.6826\n",
            "Batch 1080, Loss: 18951.9414, L2 Loss: 8919.6465, L1 Loss: 10032.2939\n",
            "Batch 1090, Loss: 19131.7559, L2 Loss: 8887.5020, L1 Loss: 10244.2539\n",
            "Batch 1100, Loss: 19625.0977, L2 Loss: 8827.3848, L1 Loss: 10797.7119\n",
            "Batch 1110, Loss: 19449.7344, L2 Loss: 8748.8770, L1 Loss: 10700.8574\n",
            "Batch 1120, Loss: 18710.9883, L2 Loss: 8704.8447, L1 Loss: 10006.1445\n",
            "Batch 1130, Loss: 19389.0820, L2 Loss: 8668.9727, L1 Loss: 10720.1084\n",
            "Batch 1140, Loss: 19054.0234, L2 Loss: 8608.0645, L1 Loss: 10445.9590\n",
            "Batch 1150, Loss: 18963.6719, L2 Loss: 8585.9951, L1 Loss: 10377.6758\n",
            "Batch 1160, Loss: 18481.7227, L2 Loss: 8513.4014, L1 Loss: 9968.3213\n",
            "Batch 1170, Loss: 18691.7832, L2 Loss: 8454.5469, L1 Loss: 10237.2363\n",
            "Batch 1180, Loss: 18529.5820, L2 Loss: 8469.0986, L1 Loss: 10060.4834\n",
            "Batch 1190, Loss: 18559.9297, L2 Loss: 8345.7002, L1 Loss: 10214.2305\n",
            "Batch 1200, Loss: 18591.2266, L2 Loss: 8262.2393, L1 Loss: 10328.9863\n",
            "Batch 1210, Loss: 18831.4453, L2 Loss: 8230.5068, L1 Loss: 10600.9375\n",
            "Batch 1220, Loss: 18954.2383, L2 Loss: 8180.4946, L1 Loss: 10773.7441\n",
            "Batch 1230, Loss: 18041.0312, L2 Loss: 8210.0703, L1 Loss: 9830.9609\n",
            "Batch 1240, Loss: 18484.6934, L2 Loss: 8108.5298, L1 Loss: 10376.1641\n",
            "Batch 1250, Loss: 18011.1328, L2 Loss: 8051.0947, L1 Loss: 9960.0391\n",
            "Batch 1260, Loss: 17971.7168, L2 Loss: 8019.2354, L1 Loss: 9952.4814\n",
            "Batch 1270, Loss: 18578.0586, L2 Loss: 7912.3584, L1 Loss: 10665.7012\n",
            "Batch 1280, Loss: 18126.4648, L2 Loss: 7874.2090, L1 Loss: 10252.2559\n",
            "Batch 1290, Loss: 17986.2207, L2 Loss: 7867.5269, L1 Loss: 10118.6934\n",
            "Batch 1300, Loss: 17505.9727, L2 Loss: 7844.6372, L1 Loss: 9661.3359\n",
            "Batch 1310, Loss: 17945.5840, L2 Loss: 7752.4375, L1 Loss: 10193.1465\n",
            "Batch 1320, Loss: 17902.4766, L2 Loss: 7740.6987, L1 Loss: 10161.7783\n",
            "Batch 1330, Loss: 18259.1113, L2 Loss: 7612.2231, L1 Loss: 10646.8877\n",
            "Batch 1340, Loss: 17996.9590, L2 Loss: 7581.0723, L1 Loss: 10415.8867\n",
            "Batch 1350, Loss: 17582.7734, L2 Loss: 7576.7603, L1 Loss: 10006.0137\n",
            "Batch 1360, Loss: 17659.4609, L2 Loss: 7535.2285, L1 Loss: 10124.2314\n",
            "Batch 1370, Loss: 17597.8672, L2 Loss: 7478.2295, L1 Loss: 10119.6387\n",
            "Batch 1380, Loss: 17468.7559, L2 Loss: 7386.3730, L1 Loss: 10082.3828\n",
            "Batch 1390, Loss: 17582.4609, L2 Loss: 7369.7124, L1 Loss: 10212.7490\n",
            "Batch 1400, Loss: 17615.0664, L2 Loss: 7298.0127, L1 Loss: 10317.0537\n",
            "Batch 1410, Loss: 17676.5840, L2 Loss: 7282.0732, L1 Loss: 10394.5107\n",
            "Batch 1420, Loss: 17412.7441, L2 Loss: 7233.6748, L1 Loss: 10179.0693\n",
            "Batch 1430, Loss: 16707.6211, L2 Loss: 7243.1333, L1 Loss: 9464.4883\n",
            "Batch 1440, Loss: 17209.7578, L2 Loss: 7181.0713, L1 Loss: 10028.6875\n",
            "Batch 1450, Loss: 16846.9902, L2 Loss: 7104.2612, L1 Loss: 9742.7285\n",
            "Batch 1460, Loss: 17033.1680, L2 Loss: 7070.1211, L1 Loss: 9963.0469\n",
            "Batch 1470, Loss: 17067.1934, L2 Loss: 7036.1255, L1 Loss: 10031.0684\n",
            "Batch 1480, Loss: 17329.3867, L2 Loss: 6971.4834, L1 Loss: 10357.9033\n",
            "Batch 1490, Loss: 16542.8184, L2 Loss: 6952.1523, L1 Loss: 9590.6660\n",
            "Batch 1500, Loss: 17207.3398, L2 Loss: 6933.0215, L1 Loss: 10274.3193\n",
            "Batch 1510, Loss: 16847.2578, L2 Loss: 6856.9287, L1 Loss: 9990.3291\n",
            "Batch 1520, Loss: 16496.1719, L2 Loss: 6856.9121, L1 Loss: 9639.2588\n",
            "Batch 1530, Loss: 16486.4297, L2 Loss: 6803.7246, L1 Loss: 9682.7061\n",
            "Batch 1540, Loss: 17029.8633, L2 Loss: 6765.7676, L1 Loss: 10264.0957\n",
            "Batch 1550, Loss: 16529.5820, L2 Loss: 6719.1699, L1 Loss: 9810.4131\n",
            "Batch 1560, Loss: 17047.0039, L2 Loss: 6696.5352, L1 Loss: 10350.4688\n",
            "Batch 1570, Loss: 15799.4697, L2 Loss: 6685.0977, L1 Loss: 9114.3721\n",
            "Batch 1580, Loss: 16335.4824, L2 Loss: 6607.5942, L1 Loss: 9727.8887\n",
            "Batch 1590, Loss: 16481.0332, L2 Loss: 6605.1553, L1 Loss: 9875.8779\n",
            "Batch 1600, Loss: 16258.6162, L2 Loss: 6561.5869, L1 Loss: 9697.0293\n",
            "Batch 1610, Loss: 15759.5371, L2 Loss: 6503.3188, L1 Loss: 9256.2188\n",
            "Batch 1620, Loss: 16151.4199, L2 Loss: 6473.8193, L1 Loss: 9677.6006\n",
            "Batch 1630, Loss: 16601.3203, L2 Loss: 6452.7383, L1 Loss: 10148.5830\n",
            "Batch 1640, Loss: 15714.6270, L2 Loss: 6406.4541, L1 Loss: 9308.1729\n",
            "Batch 1650, Loss: 16159.9863, L2 Loss: 6393.1714, L1 Loss: 9766.8154\n",
            "Batch 1660, Loss: 16524.4316, L2 Loss: 6357.7031, L1 Loss: 10166.7285\n",
            "Batch 1670, Loss: 15618.9980, L2 Loss: 6284.5415, L1 Loss: 9334.4570\n",
            "Batch 1680, Loss: 15732.6338, L2 Loss: 6250.1074, L1 Loss: 9482.5264\n",
            "Batch 1690, Loss: 15739.4707, L2 Loss: 6252.8525, L1 Loss: 9486.6182\n",
            "Batch 1700, Loss: 15503.7227, L2 Loss: 6218.8174, L1 Loss: 9284.9053\n",
            "Batch 1710, Loss: 15372.4316, L2 Loss: 6159.2271, L1 Loss: 9213.2041\n",
            "Batch 1720, Loss: 15870.6445, L2 Loss: 6126.3374, L1 Loss: 9744.3076\n",
            "Batch 1730, Loss: 15608.9199, L2 Loss: 6113.6333, L1 Loss: 9495.2871\n",
            "Batch 1740, Loss: 15990.1094, L2 Loss: 6114.0601, L1 Loss: 9876.0498\n",
            "Batch 1750, Loss: 15518.4395, L2 Loss: 6088.4194, L1 Loss: 9430.0195\n",
            "Batch 1760, Loss: 15214.4004, L2 Loss: 6037.4312, L1 Loss: 9176.9688\n",
            "Batch 1770, Loss: 15535.9023, L2 Loss: 6029.8892, L1 Loss: 9506.0137\n",
            "Batch 1780, Loss: 15295.1465, L2 Loss: 5965.9604, L1 Loss: 9329.1865\n",
            "Batch 1790, Loss: 15577.2490, L2 Loss: 5968.5693, L1 Loss: 9608.6797\n",
            "Batch 1800, Loss: 15561.4492, L2 Loss: 5938.0347, L1 Loss: 9623.4141\n",
            "Batch 1810, Loss: 15166.3994, L2 Loss: 5894.6904, L1 Loss: 9271.7090\n",
            "Batch 1820, Loss: 15285.1670, L2 Loss: 5870.4355, L1 Loss: 9414.7314\n",
            "Batch 1830, Loss: 14783.0645, L2 Loss: 5845.7026, L1 Loss: 8937.3613\n",
            "Batch 1840, Loss: 15263.7295, L2 Loss: 5818.7012, L1 Loss: 9445.0283\n",
            "Batch 1850, Loss: 15118.4775, L2 Loss: 5785.9941, L1 Loss: 9332.4834\n",
            "Batch 1860, Loss: 15531.1592, L2 Loss: 5794.0381, L1 Loss: 9737.1211\n",
            "Batch 1870, Loss: 15203.9668, L2 Loss: 5732.2197, L1 Loss: 9471.7471\n",
            "Batch 1880, Loss: 15106.1816, L2 Loss: 5713.3423, L1 Loss: 9392.8398\n",
            "Batch 1890, Loss: 15202.4375, L2 Loss: 5696.8228, L1 Loss: 9505.6152\n",
            "Batch 1900, Loss: 14683.0459, L2 Loss: 5665.0811, L1 Loss: 9017.9648\n",
            "Batch 1910, Loss: 15082.2090, L2 Loss: 5648.4497, L1 Loss: 9433.7598\n",
            "Batch 1920, Loss: 15079.5156, L2 Loss: 5637.9058, L1 Loss: 9441.6104\n",
            "Batch 1930, Loss: 15175.6426, L2 Loss: 5594.8892, L1 Loss: 9580.7529\n",
            "Batch 1940, Loss: 14539.9160, L2 Loss: 5574.0225, L1 Loss: 8965.8936\n",
            "Batch 1950, Loss: 14816.1895, L2 Loss: 5538.8765, L1 Loss: 9277.3135\n",
            "Batch 1960, Loss: 15198.8262, L2 Loss: 5501.6211, L1 Loss: 9697.2051\n",
            "Batch 1970, Loss: 14878.4258, L2 Loss: 5478.5464, L1 Loss: 9399.8799\n",
            "Batch 1980, Loss: 15059.2256, L2 Loss: 5466.4463, L1 Loss: 9592.7793\n",
            "Batch 1990, Loss: 14871.9043, L2 Loss: 5432.0386, L1 Loss: 9439.8662\n",
            "Batch 2000, Loss: 14217.4785, L2 Loss: 5400.2363, L1 Loss: 8817.2422\n",
            "Batch 2010, Loss: 14480.8320, L2 Loss: 5382.9561, L1 Loss: 9097.8760\n",
            "Batch 2020, Loss: 14955.3271, L2 Loss: 5367.4609, L1 Loss: 9587.8662\n",
            "Batch 2030, Loss: 14315.6494, L2 Loss: 5328.9082, L1 Loss: 8986.7412\n",
            "Batch 2040, Loss: 14552.7109, L2 Loss: 5328.4116, L1 Loss: 9224.2998\n",
            "Batch 2050, Loss: 14642.4551, L2 Loss: 5303.2280, L1 Loss: 9339.2275\n",
            "Batch 2060, Loss: 14788.3682, L2 Loss: 5312.8164, L1 Loss: 9475.5518\n",
            "Batch 2070, Loss: 14591.4990, L2 Loss: 5272.7393, L1 Loss: 9318.7598\n",
            "Batch 2080, Loss: 14115.3027, L2 Loss: 5246.0264, L1 Loss: 8869.2764\n",
            "Batch 2090, Loss: 14536.9629, L2 Loss: 5233.7646, L1 Loss: 9303.1982\n",
            "Batch 2100, Loss: 14507.7754, L2 Loss: 5206.1055, L1 Loss: 9301.6699\n",
            "Batch 2110, Loss: 14190.8857, L2 Loss: 5184.9014, L1 Loss: 9005.9844\n",
            "Batch 2120, Loss: 14559.4902, L2 Loss: 5150.7632, L1 Loss: 9408.7266\n",
            "Batch 2130, Loss: 13966.4492, L2 Loss: 5134.6860, L1 Loss: 8831.7627\n",
            "Batch 2140, Loss: 14220.9033, L2 Loss: 5119.5547, L1 Loss: 9101.3486\n",
            "Batch 2150, Loss: 14013.4307, L2 Loss: 5077.8633, L1 Loss: 8935.5674\n",
            "Batch 2160, Loss: 13905.4043, L2 Loss: 5063.4048, L1 Loss: 8841.9990\n",
            "Batch 2170, Loss: 14087.4414, L2 Loss: 5073.3325, L1 Loss: 9014.1084\n",
            "Batch 2180, Loss: 14500.9746, L2 Loss: 5081.4976, L1 Loss: 9419.4766\n",
            "Batch 2190, Loss: 14206.3838, L2 Loss: 5023.6904, L1 Loss: 9182.6934\n",
            "Batch 2200, Loss: 14400.7305, L2 Loss: 4984.5610, L1 Loss: 9416.1689\n",
            "Batch 2210, Loss: 13943.6484, L2 Loss: 4977.8364, L1 Loss: 8965.8125\n",
            "Batch 2220, Loss: 13781.7578, L2 Loss: 4961.7144, L1 Loss: 8820.0439\n",
            "Batch 2230, Loss: 14051.9531, L2 Loss: 4961.2290, L1 Loss: 9090.7236\n",
            "Batch 2240, Loss: 13728.3311, L2 Loss: 4949.3164, L1 Loss: 8779.0146\n",
            "Batch 2250, Loss: 13750.5625, L2 Loss: 4922.4990, L1 Loss: 8828.0635\n",
            "Batch 2260, Loss: 13875.5273, L2 Loss: 4903.3062, L1 Loss: 8972.2207\n",
            "Batch 2270, Loss: 13547.3232, L2 Loss: 4852.3057, L1 Loss: 8695.0176\n",
            "Batch 2280, Loss: 13531.5684, L2 Loss: 4870.9580, L1 Loss: 8660.6104\n",
            "Batch 2290, Loss: 13885.5693, L2 Loss: 4870.6357, L1 Loss: 9014.9336\n",
            "Batch 2300, Loss: 13955.7012, L2 Loss: 4851.4917, L1 Loss: 9104.2100\n",
            "Batch 2310, Loss: 13359.3066, L2 Loss: 4813.4717, L1 Loss: 8545.8350\n",
            "Batch 2320, Loss: 13694.5605, L2 Loss: 4795.8921, L1 Loss: 8898.6689\n",
            "Batch 2330, Loss: 13368.2705, L2 Loss: 4781.5322, L1 Loss: 8586.7383\n",
            "Batch 2340, Loss: 13533.4570, L2 Loss: 4761.5942, L1 Loss: 8771.8633\n",
            "Batch 2350, Loss: 13626.4551, L2 Loss: 4773.9980, L1 Loss: 8852.4570\n",
            "Batch 2360, Loss: 13020.6152, L2 Loss: 4716.1865, L1 Loss: 8304.4287\n",
            "Batch 2370, Loss: 13737.9082, L2 Loss: 4723.7822, L1 Loss: 9014.1260\n",
            "Batch 2380, Loss: 13207.8965, L2 Loss: 4715.2920, L1 Loss: 8492.6045\n",
            "Batch 2390, Loss: 13286.0176, L2 Loss: 4666.3403, L1 Loss: 8619.6768\n",
            "Batch 2400, Loss: 13550.5117, L2 Loss: 4695.3940, L1 Loss: 8855.1172\n",
            "Batch 2410, Loss: 13287.6328, L2 Loss: 4653.8950, L1 Loss: 8633.7373\n",
            "Batch 2420, Loss: 13393.7324, L2 Loss: 4649.4663, L1 Loss: 8744.2656\n",
            "Batch 2430, Loss: 13502.2217, L2 Loss: 4634.2568, L1 Loss: 8867.9648\n",
            "Batch 2440, Loss: 13356.6045, L2 Loss: 4627.9062, L1 Loss: 8728.6982\n",
            "Batch 2450, Loss: 13170.9805, L2 Loss: 4596.8872, L1 Loss: 8574.0938\n",
            "Batch 2460, Loss: 13225.8857, L2 Loss: 4574.5273, L1 Loss: 8651.3584\n",
            "Batch 2470, Loss: 12984.3574, L2 Loss: 4560.9624, L1 Loss: 8423.3945\n",
            "Batch 2480, Loss: 13096.6426, L2 Loss: 4543.2114, L1 Loss: 8553.4316\n",
            "Batch 2490, Loss: 13212.8242, L2 Loss: 4568.1494, L1 Loss: 8644.6748\n",
            "Batch 2500, Loss: 12990.6221, L2 Loss: 4549.0752, L1 Loss: 8441.5469\n",
            "Batch 2510, Loss: 12675.1855, L2 Loss: 4501.6113, L1 Loss: 8173.5737\n",
            "Batch 2520, Loss: 13185.6445, L2 Loss: 4500.7261, L1 Loss: 8684.9180\n",
            "Batch 2530, Loss: 12724.2637, L2 Loss: 4472.6592, L1 Loss: 8251.6045\n",
            "Batch 2540, Loss: 12970.6758, L2 Loss: 4492.6992, L1 Loss: 8477.9766\n",
            "Batch 2550, Loss: 13157.5859, L2 Loss: 4487.3843, L1 Loss: 8670.2021\n",
            "Batch 2560, Loss: 13349.6875, L2 Loss: 4472.7417, L1 Loss: 8876.9453\n",
            "Batch 2570, Loss: 13200.6602, L2 Loss: 4447.3311, L1 Loss: 8753.3291\n",
            "Batch 2580, Loss: 12866.4521, L2 Loss: 4443.6328, L1 Loss: 8422.8193\n",
            "Batch 2590, Loss: 12645.0049, L2 Loss: 4425.8604, L1 Loss: 8219.1445\n",
            "Batch 2600, Loss: 12644.3633, L2 Loss: 4381.9253, L1 Loss: 8262.4385\n",
            "Batch 2610, Loss: 13123.6641, L2 Loss: 4411.5801, L1 Loss: 8712.0840\n",
            "Batch 2620, Loss: 12791.5508, L2 Loss: 4377.9194, L1 Loss: 8413.6309\n",
            "Batch 2630, Loss: 12941.3848, L2 Loss: 4378.3706, L1 Loss: 8563.0146\n",
            "Batch 2640, Loss: 12411.2852, L2 Loss: 4383.3633, L1 Loss: 8027.9214\n",
            "Batch 2650, Loss: 12409.9551, L2 Loss: 4314.4487, L1 Loss: 8095.5063\n",
            "Batch 2660, Loss: 12792.9111, L2 Loss: 4343.4229, L1 Loss: 8449.4883\n",
            "Batch 2670, Loss: 12401.5059, L2 Loss: 4322.2290, L1 Loss: 8079.2764\n",
            "Batch 2680, Loss: 12668.8896, L2 Loss: 4310.4004, L1 Loss: 8358.4893\n",
            "Batch 2690, Loss: 12429.5645, L2 Loss: 4314.4980, L1 Loss: 8115.0659\n",
            "Batch 2700, Loss: 12564.7471, L2 Loss: 4280.4033, L1 Loss: 8284.3438\n",
            "Batch 2710, Loss: 13152.5420, L2 Loss: 4287.8164, L1 Loss: 8864.7256\n",
            "Batch 2720, Loss: 12593.6006, L2 Loss: 4263.0283, L1 Loss: 8330.5723\n",
            "Batch 2730, Loss: 12655.0420, L2 Loss: 4250.9795, L1 Loss: 8404.0625\n",
            "Batch 2740, Loss: 12737.7891, L2 Loss: 4251.0483, L1 Loss: 8486.7412\n",
            "Batch 2750, Loss: 12893.5410, L2 Loss: 4253.8740, L1 Loss: 8639.6670\n",
            "Batch 2760, Loss: 12495.8701, L2 Loss: 4233.7109, L1 Loss: 8262.1592\n",
            "Batch 2770, Loss: 12325.9570, L2 Loss: 4202.9683, L1 Loss: 8122.9888\n",
            "Batch 2780, Loss: 12857.1484, L2 Loss: 4240.4883, L1 Loss: 8616.6602\n",
            "Batch 2790, Loss: 12544.4629, L2 Loss: 4206.0527, L1 Loss: 8338.4102\n",
            "Batch 2800, Loss: 12236.3535, L2 Loss: 4151.0801, L1 Loss: 8085.2729\n",
            "Batch 2810, Loss: 12462.7002, L2 Loss: 4198.5371, L1 Loss: 8264.1631\n",
            "Batch 2820, Loss: 12278.5156, L2 Loss: 4187.9536, L1 Loss: 8090.5625\n",
            "Batch 2830, Loss: 12307.3184, L2 Loss: 4165.7778, L1 Loss: 8141.5410\n",
            "Batch 2840, Loss: 12323.1494, L2 Loss: 4152.6226, L1 Loss: 8170.5269\n",
            "Batch 2850, Loss: 12368.0957, L2 Loss: 4138.7788, L1 Loss: 8229.3164\n",
            "Batch 2860, Loss: 12448.9297, L2 Loss: 4128.6709, L1 Loss: 8320.2588\n",
            "Batch 2870, Loss: 12082.6445, L2 Loss: 4099.0742, L1 Loss: 7983.5703\n",
            "Batch 2880, Loss: 12402.6104, L2 Loss: 4117.7783, L1 Loss: 8284.8320\n",
            "Batch 2890, Loss: 12138.3857, L2 Loss: 4104.9805, L1 Loss: 8033.4053\n",
            "Batch 2900, Loss: 11845.6992, L2 Loss: 4075.2625, L1 Loss: 7770.4370\n",
            "Batch 2910, Loss: 12313.6240, L2 Loss: 4117.6270, L1 Loss: 8195.9971\n",
            "Batch 2920, Loss: 12412.6250, L2 Loss: 4070.5652, L1 Loss: 8342.0596\n",
            "Batch 2930, Loss: 12239.0029, L2 Loss: 4071.9768, L1 Loss: 8167.0264\n",
            "Batch 2940, Loss: 12018.8359, L2 Loss: 4045.4426, L1 Loss: 7973.3936\n",
            "Batch 2950, Loss: 12255.8818, L2 Loss: 4065.0728, L1 Loss: 8190.8091\n",
            "Batch 2960, Loss: 12322.2158, L2 Loss: 4032.7432, L1 Loss: 8289.4727\n",
            "Batch 2970, Loss: 12022.8564, L2 Loss: 4035.0608, L1 Loss: 7987.7954\n",
            "Batch 2980, Loss: 12470.7578, L2 Loss: 4036.0969, L1 Loss: 8434.6611\n",
            "Batch 2990, Loss: 12065.6562, L2 Loss: 3986.9932, L1 Loss: 8078.6631\n",
            "Batch 3000, Loss: 12396.0762, L2 Loss: 4025.9897, L1 Loss: 8370.0869\n",
            "Batch 3010, Loss: 12240.1494, L2 Loss: 4003.1956, L1 Loss: 8236.9541\n",
            "Batch 3020, Loss: 12104.7314, L2 Loss: 3962.6421, L1 Loss: 8142.0894\n",
            "Batch 3030, Loss: 11940.3125, L2 Loss: 3973.5347, L1 Loss: 7966.7783\n",
            "Batch 3040, Loss: 11654.8701, L2 Loss: 3979.2522, L1 Loss: 7675.6182\n",
            "Batch 3050, Loss: 12090.1113, L2 Loss: 3958.9116, L1 Loss: 8131.1997\n",
            "Batch 3060, Loss: 11587.9756, L2 Loss: 3956.1553, L1 Loss: 7631.8203\n",
            "Batch 3070, Loss: 12129.3955, L2 Loss: 3971.7141, L1 Loss: 8157.6812\n",
            "Batch 3080, Loss: 11966.3340, L2 Loss: 3953.4736, L1 Loss: 8012.8599\n",
            "Batch 3090, Loss: 11483.8164, L2 Loss: 3917.2612, L1 Loss: 7566.5547\n",
            "Batch 3100, Loss: 11854.2393, L2 Loss: 3924.7097, L1 Loss: 7929.5298\n",
            "Batch 3110, Loss: 11940.9775, L2 Loss: 3909.4080, L1 Loss: 8031.5693\n",
            "Batch 3120, Loss: 11884.5459, L2 Loss: 3898.9338, L1 Loss: 7985.6118\n",
            "Batch 3130, Loss: 11530.3691, L2 Loss: 3884.5427, L1 Loss: 7645.8267\n",
            "Batch 3140, Loss: 11854.5205, L2 Loss: 3891.3552, L1 Loss: 7963.1655\n",
            "Batch 3150, Loss: 11601.4199, L2 Loss: 3859.7300, L1 Loss: 7741.6895\n",
            "Batch 3160, Loss: 11588.7812, L2 Loss: 3873.6855, L1 Loss: 7715.0957\n",
            "Batch 3170, Loss: 11592.8477, L2 Loss: 3845.9998, L1 Loss: 7746.8481\n",
            "Batch 3180, Loss: 11696.5732, L2 Loss: 3869.1587, L1 Loss: 7827.4146\n",
            "Batch 3190, Loss: 11793.6230, L2 Loss: 3833.7583, L1 Loss: 7959.8643\n",
            "Batch 3200, Loss: 11459.3799, L2 Loss: 3830.0437, L1 Loss: 7629.3364\n",
            "Batch 3210, Loss: 11403.3770, L2 Loss: 3846.0015, L1 Loss: 7557.3755\n",
            "Batch 3220, Loss: 11790.8535, L2 Loss: 3879.7119, L1 Loss: 7911.1421\n",
            "Batch 3230, Loss: 11526.8555, L2 Loss: 3807.6924, L1 Loss: 7719.1626\n",
            "Batch 3240, Loss: 11693.6895, L2 Loss: 3818.7488, L1 Loss: 7874.9404\n",
            "Batch 3250, Loss: 11833.9238, L2 Loss: 3827.6826, L1 Loss: 8006.2407\n",
            "Batch 3260, Loss: 11498.5186, L2 Loss: 3810.5432, L1 Loss: 7687.9756\n",
            "Batch 3270, Loss: 11603.8164, L2 Loss: 3784.7847, L1 Loss: 7819.0312\n",
            "Batch 3280, Loss: 11503.5488, L2 Loss: 3801.4277, L1 Loss: 7702.1206\n",
            "Batch 3290, Loss: 11359.1572, L2 Loss: 3760.1277, L1 Loss: 7599.0293\n",
            "Batch 3300, Loss: 11190.9111, L2 Loss: 3776.4368, L1 Loss: 7414.4746\n",
            "Batch 3310, Loss: 11502.1953, L2 Loss: 3787.6682, L1 Loss: 7714.5269\n",
            "Batch 3320, Loss: 11664.6328, L2 Loss: 3761.6851, L1 Loss: 7902.9482\n",
            "Batch 3330, Loss: 11041.2998, L2 Loss: 3758.8860, L1 Loss: 7282.4141\n",
            "Batch 3340, Loss: 11252.8877, L2 Loss: 3736.7092, L1 Loss: 7516.1787\n",
            "Batch 3350, Loss: 11360.6172, L2 Loss: 3739.4050, L1 Loss: 7621.2119\n",
            "Batch 3360, Loss: 11271.9346, L2 Loss: 3736.4695, L1 Loss: 7535.4653\n",
            "Batch 3370, Loss: 11269.4883, L2 Loss: 3710.6267, L1 Loss: 7558.8613\n",
            "Batch 3380, Loss: 11637.2930, L2 Loss: 3715.1614, L1 Loss: 7922.1313\n",
            "Batch 3390, Loss: 11245.8564, L2 Loss: 3696.3901, L1 Loss: 7549.4663\n",
            "Batch 3400, Loss: 11476.8242, L2 Loss: 3706.5229, L1 Loss: 7770.3018\n",
            "Batch 3410, Loss: 11353.8945, L2 Loss: 3724.0093, L1 Loss: 7629.8848\n",
            "Batch 3420, Loss: 11340.2539, L2 Loss: 3718.1812, L1 Loss: 7622.0732\n",
            "Batch 3430, Loss: 11345.0303, L2 Loss: 3697.8132, L1 Loss: 7647.2168\n",
            "Batch 3440, Loss: 11150.6387, L2 Loss: 3678.0127, L1 Loss: 7472.6260\n",
            "Batch 3450, Loss: 10974.1211, L2 Loss: 3658.7820, L1 Loss: 7315.3394\n",
            "Batch 3460, Loss: 11140.0977, L2 Loss: 3678.3062, L1 Loss: 7461.7910\n",
            "Batch 3470, Loss: 11251.4160, L2 Loss: 3673.7605, L1 Loss: 7577.6558\n",
            "Batch 3480, Loss: 11268.3984, L2 Loss: 3653.6375, L1 Loss: 7614.7607\n",
            "Batch 3490, Loss: 10905.7852, L2 Loss: 3637.2317, L1 Loss: 7268.5537\n",
            "Batch 3500, Loss: 11203.3516, L2 Loss: 3673.7407, L1 Loss: 7529.6113\n",
            "Batch 3510, Loss: 11163.0303, L2 Loss: 3651.4773, L1 Loss: 7511.5532\n",
            "Batch 3520, Loss: 11121.8105, L2 Loss: 3620.9678, L1 Loss: 7500.8428\n",
            "Batch 3530, Loss: 11110.1250, L2 Loss: 3630.1067, L1 Loss: 7480.0186\n",
            "Batch 3540, Loss: 10927.2256, L2 Loss: 3623.0686, L1 Loss: 7304.1567\n",
            "Batch 3550, Loss: 10841.0576, L2 Loss: 3603.2737, L1 Loss: 7237.7837\n",
            "Batch 3560, Loss: 10872.9990, L2 Loss: 3578.6821, L1 Loss: 7294.3169\n",
            "Batch 3570, Loss: 10873.2832, L2 Loss: 3580.3213, L1 Loss: 7292.9619\n",
            "Batch 3580, Loss: 11220.0420, L2 Loss: 3595.6702, L1 Loss: 7624.3721\n",
            "Batch 3590, Loss: 10716.4033, L2 Loss: 3574.7397, L1 Loss: 7141.6636\n",
            "Batch 3600, Loss: 10451.1299, L2 Loss: 3553.9827, L1 Loss: 6897.1475\n",
            "Batch 3610, Loss: 10822.6768, L2 Loss: 3587.2207, L1 Loss: 7235.4561\n",
            "Batch 3620, Loss: 10870.2754, L2 Loss: 3583.5864, L1 Loss: 7286.6885\n",
            "Batch 3630, Loss: 10579.5879, L2 Loss: 3552.5410, L1 Loss: 7027.0474\n",
            "Batch 3640, Loss: 10573.9053, L2 Loss: 3543.2681, L1 Loss: 7030.6372\n",
            "Batch 3650, Loss: 10534.0146, L2 Loss: 3556.5767, L1 Loss: 6977.4380\n",
            "Batch 3660, Loss: 11125.6357, L2 Loss: 3557.6990, L1 Loss: 7567.9365\n",
            "Batch 3670, Loss: 10474.0771, L2 Loss: 3519.9182, L1 Loss: 6954.1587\n",
            "Batch 3680, Loss: 10960.0312, L2 Loss: 3548.8223, L1 Loss: 7411.2090\n",
            "Batch 3690, Loss: 10748.7070, L2 Loss: 3519.4399, L1 Loss: 7229.2676\n",
            "Batch 3700, Loss: 10775.3320, L2 Loss: 3514.2808, L1 Loss: 7261.0518\n",
            "Batch 3710, Loss: 10816.8555, L2 Loss: 3496.6157, L1 Loss: 7320.2393\n",
            "Batch 3720, Loss: 10895.6924, L2 Loss: 3526.5220, L1 Loss: 7369.1704\n",
            "Batch 3730, Loss: 10715.8477, L2 Loss: 3505.6309, L1 Loss: 7210.2173\n",
            "Batch 3740, Loss: 10745.5391, L2 Loss: 3473.4417, L1 Loss: 7272.0972\n",
            "Batch 3750, Loss: 10714.6230, L2 Loss: 3483.8606, L1 Loss: 7230.7622\n",
            "Batch 3760, Loss: 10980.5830, L2 Loss: 3495.0654, L1 Loss: 7485.5176\n",
            "Batch 3770, Loss: 10421.8770, L2 Loss: 3472.2805, L1 Loss: 6949.5962\n",
            "Batch 3780, Loss: 10719.0801, L2 Loss: 3486.1892, L1 Loss: 7232.8911\n",
            "Batch 3790, Loss: 10634.4199, L2 Loss: 3458.2197, L1 Loss: 7176.2002\n",
            "Batch 3800, Loss: 10765.3799, L2 Loss: 3475.5696, L1 Loss: 7289.8105\n",
            "Batch 3810, Loss: 10921.1367, L2 Loss: 3466.6646, L1 Loss: 7454.4722\n",
            "Batch 3820, Loss: 10386.6484, L2 Loss: 3456.8044, L1 Loss: 6929.8442\n",
            "Batch 3830, Loss: 10728.6367, L2 Loss: 3462.9902, L1 Loss: 7265.6465\n",
            "Batch 3840, Loss: 10762.2676, L2 Loss: 3465.1721, L1 Loss: 7297.0957\n",
            "Batch 3850, Loss: 10440.3594, L2 Loss: 3428.2517, L1 Loss: 7012.1074\n",
            "Batch 3860, Loss: 10387.9443, L2 Loss: 3400.9976, L1 Loss: 6986.9468\n",
            "Batch 3870, Loss: 10438.8359, L2 Loss: 3393.6028, L1 Loss: 7045.2329\n",
            "Batch 3880, Loss: 10580.4785, L2 Loss: 3417.8562, L1 Loss: 7162.6226\n",
            "Batch 3890, Loss: 10467.1582, L2 Loss: 3390.0127, L1 Loss: 7077.1455\n",
            "Batch 3900, Loss: 10322.3076, L2 Loss: 3388.6472, L1 Loss: 6933.6602\n",
            "Batch 3910, Loss: 10801.9805, L2 Loss: 3394.8591, L1 Loss: 7407.1216\n",
            "Batch 3920, Loss: 10692.6953, L2 Loss: 3416.3801, L1 Loss: 7276.3154\n",
            "Batch 3930, Loss: 10176.3398, L2 Loss: 3370.8132, L1 Loss: 6805.5269\n",
            "Batch 3940, Loss: 10098.8242, L2 Loss: 3359.6230, L1 Loss: 6739.2017\n",
            "Batch 3950, Loss: 10307.4180, L2 Loss: 3354.2202, L1 Loss: 6953.1978\n",
            "Batch 3960, Loss: 10719.3164, L2 Loss: 3348.2720, L1 Loss: 7371.0439\n",
            "Batch 3970, Loss: 10737.5332, L2 Loss: 3364.5386, L1 Loss: 7372.9941\n",
            "Batch 3980, Loss: 10504.9619, L2 Loss: 3358.3816, L1 Loss: 7146.5801\n",
            "Batch 3990, Loss: 10310.6816, L2 Loss: 3366.5056, L1 Loss: 6944.1758\n",
            "Batch 4000, Loss: 10436.0596, L2 Loss: 3341.7449, L1 Loss: 7094.3149\n",
            "Batch 4010, Loss: 10210.0186, L2 Loss: 3344.5750, L1 Loss: 6865.4434\n",
            "Batch 4020, Loss: 9981.2021, L2 Loss: 3312.5864, L1 Loss: 6668.6157\n",
            "Batch 4030, Loss: 10490.1270, L2 Loss: 3316.3730, L1 Loss: 7173.7539\n",
            "Batch 4040, Loss: 10208.3613, L2 Loss: 3314.9248, L1 Loss: 6893.4365\n",
            "Batch 4050, Loss: 10556.3203, L2 Loss: 3337.5781, L1 Loss: 7218.7427\n",
            "Batch 4060, Loss: 10107.8291, L2 Loss: 3283.1902, L1 Loss: 6824.6392\n",
            "Batch 4070, Loss: 10181.8027, L2 Loss: 3324.0371, L1 Loss: 6857.7651\n",
            "Batch 4080, Loss: 10212.5908, L2 Loss: 3294.1946, L1 Loss: 6918.3965\n",
            "Batch 4090, Loss: 10275.1426, L2 Loss: 3301.4941, L1 Loss: 6973.6479\n",
            "Batch 4100, Loss: 9955.2090, L2 Loss: 3278.2371, L1 Loss: 6676.9717\n",
            "Batch 4110, Loss: 10236.7871, L2 Loss: 3262.0137, L1 Loss: 6974.7734\n",
            "Batch 4120, Loss: 10144.3809, L2 Loss: 3271.0352, L1 Loss: 6873.3452\n",
            "Batch 4130, Loss: 10323.2891, L2 Loss: 3307.5583, L1 Loss: 7015.7310\n",
            "Batch 4140, Loss: 10201.9053, L2 Loss: 3277.3650, L1 Loss: 6924.5405\n",
            "Batch 4150, Loss: 9972.6641, L2 Loss: 3238.8142, L1 Loss: 6733.8496\n",
            "Batch 4160, Loss: 10122.7891, L2 Loss: 3251.0896, L1 Loss: 6871.6997\n",
            "Batch 4170, Loss: 9995.2227, L2 Loss: 3253.2148, L1 Loss: 6742.0083\n",
            "Batch 4180, Loss: 10502.9424, L2 Loss: 3272.3142, L1 Loss: 7230.6279\n",
            "Batch 4190, Loss: 10095.8037, L2 Loss: 3263.2961, L1 Loss: 6832.5073\n",
            "Batch 4200, Loss: 9943.9678, L2 Loss: 3217.4431, L1 Loss: 6726.5249\n",
            "Batch 4210, Loss: 9811.1328, L2 Loss: 3228.9485, L1 Loss: 6582.1846\n",
            "Batch 4220, Loss: 10319.6484, L2 Loss: 3219.2192, L1 Loss: 7100.4292\n",
            "Batch 4230, Loss: 9976.2266, L2 Loss: 3183.7878, L1 Loss: 6792.4385\n",
            "Batch 4240, Loss: 10203.7383, L2 Loss: 3195.7415, L1 Loss: 7007.9966\n",
            "Batch 4250, Loss: 10132.8760, L2 Loss: 3224.4158, L1 Loss: 6908.4600\n",
            "Batch 4260, Loss: 9773.8770, L2 Loss: 3186.1050, L1 Loss: 6587.7725\n",
            "Batch 4270, Loss: 10333.0859, L2 Loss: 3215.2622, L1 Loss: 7117.8242\n",
            "Batch 4280, Loss: 9948.2998, L2 Loss: 3192.9036, L1 Loss: 6755.3965\n",
            "Batch 4290, Loss: 9488.2881, L2 Loss: 3158.7229, L1 Loss: 6329.5649\n",
            "Batch 4300, Loss: 10030.2021, L2 Loss: 3177.6101, L1 Loss: 6852.5918\n",
            "Batch 4310, Loss: 10192.9668, L2 Loss: 3188.0557, L1 Loss: 7004.9111\n",
            "Batch 4320, Loss: 9902.7422, L2 Loss: 3156.4023, L1 Loss: 6746.3398\n",
            "Batch 4330, Loss: 9975.8496, L2 Loss: 3156.9048, L1 Loss: 6818.9453\n",
            "Batch 4340, Loss: 9963.2109, L2 Loss: 3145.3889, L1 Loss: 6817.8218\n",
            "Batch 4350, Loss: 9762.4990, L2 Loss: 3133.3723, L1 Loss: 6629.1270\n",
            "Batch 4360, Loss: 9805.4365, L2 Loss: 3137.4536, L1 Loss: 6667.9829\n",
            "Batch 4370, Loss: 9894.9668, L2 Loss: 3160.6687, L1 Loss: 6734.2983\n",
            "Batch 4380, Loss: 9832.6172, L2 Loss: 3125.4631, L1 Loss: 6707.1543\n",
            "Batch 4390, Loss: 9875.5049, L2 Loss: 3132.6868, L1 Loss: 6742.8184\n",
            "Batch 4400, Loss: 9876.2354, L2 Loss: 3113.2991, L1 Loss: 6762.9365\n",
            "Batch 4410, Loss: 10092.1670, L2 Loss: 3109.7156, L1 Loss: 6982.4517\n",
            "Batch 4420, Loss: 9766.8477, L2 Loss: 3122.4128, L1 Loss: 6644.4346\n",
            "Batch 4430, Loss: 9558.0615, L2 Loss: 3103.1013, L1 Loss: 6454.9600\n",
            "Batch 4440, Loss: 9758.7441, L2 Loss: 3114.0312, L1 Loss: 6644.7134\n",
            "Batch 4450, Loss: 9887.8779, L2 Loss: 3118.9265, L1 Loss: 6768.9512\n",
            "Batch 4460, Loss: 9741.3457, L2 Loss: 3094.8640, L1 Loss: 6646.4819\n",
            "Batch 4470, Loss: 9717.2168, L2 Loss: 3067.5791, L1 Loss: 6649.6377\n",
            "Batch 4480, Loss: 9677.8955, L2 Loss: 3082.7000, L1 Loss: 6595.1953\n",
            "Batch 4490, Loss: 9955.3877, L2 Loss: 3074.0361, L1 Loss: 6881.3516\n",
            "Batch 4500, Loss: 9329.4805, L2 Loss: 3065.7500, L1 Loss: 6263.7305\n",
            "Batch 4510, Loss: 9779.7471, L2 Loss: 3055.8535, L1 Loss: 6723.8936\n",
            "Batch 4520, Loss: 9477.3330, L2 Loss: 3065.3386, L1 Loss: 6411.9941\n",
            "Batch 4530, Loss: 9205.6426, L2 Loss: 3032.4302, L1 Loss: 6173.2124\n",
            "Batch 4540, Loss: 9760.9551, L2 Loss: 3043.6396, L1 Loss: 6717.3149\n",
            "Batch 4550, Loss: 9661.3613, L2 Loss: 3034.2522, L1 Loss: 6627.1089\n",
            "Batch 4560, Loss: 9587.1426, L2 Loss: 3037.7000, L1 Loss: 6549.4429\n",
            "Batch 4570, Loss: 9615.2051, L2 Loss: 2992.9634, L1 Loss: 6622.2422\n",
            "Batch 4580, Loss: 9339.8389, L2 Loss: 2995.5142, L1 Loss: 6344.3247\n",
            "Batch 4590, Loss: 9839.9473, L2 Loss: 3034.3210, L1 Loss: 6805.6265\n",
            "Batch 4600, Loss: 9619.5732, L2 Loss: 2998.5437, L1 Loss: 6621.0293\n",
            "Batch 4610, Loss: 9679.8984, L2 Loss: 3002.4456, L1 Loss: 6677.4531\n",
            "Batch 4620, Loss: 9802.9766, L2 Loss: 3021.5752, L1 Loss: 6781.4009\n",
            "Batch 4630, Loss: 9634.8379, L2 Loss: 2977.5173, L1 Loss: 6657.3208\n",
            "Batch 4640, Loss: 9479.2402, L2 Loss: 2998.6406, L1 Loss: 6480.5991\n",
            "Batch 4650, Loss: 9787.5986, L2 Loss: 2989.9597, L1 Loss: 6797.6387\n",
            "Batch 4660, Loss: 9794.2910, L2 Loss: 2970.0381, L1 Loss: 6824.2529\n",
            "Batch 4670, Loss: 9616.9404, L2 Loss: 2970.8215, L1 Loss: 6646.1187\n",
            "Batch 4680, Loss: 9537.6602, L2 Loss: 2965.8198, L1 Loss: 6571.8398\n",
            "Batch 4690, Loss: 9154.9355, L2 Loss: 2964.7026, L1 Loss: 6190.2329\n",
            "Batch 4700, Loss: 9682.0117, L2 Loss: 2984.6042, L1 Loss: 6697.4077\n",
            "Batch 4710, Loss: 9485.0156, L2 Loss: 2955.3672, L1 Loss: 6529.6479\n",
            "Batch 4720, Loss: 9401.0000, L2 Loss: 2970.4551, L1 Loss: 6430.5449\n",
            "Batch 4730, Loss: 9464.5273, L2 Loss: 2949.1179, L1 Loss: 6515.4092\n",
            "Batch 4740, Loss: 9560.4258, L2 Loss: 2947.7397, L1 Loss: 6612.6865\n",
            "Batch 4750, Loss: 9071.4824, L2 Loss: 2905.8938, L1 Loss: 6165.5884\n",
            "Batch 4760, Loss: 9621.7607, L2 Loss: 2928.8765, L1 Loss: 6692.8843\n",
            "Batch 4770, Loss: 9245.3604, L2 Loss: 2925.0237, L1 Loss: 6320.3369\n",
            "Batch 4780, Loss: 9497.4531, L2 Loss: 2954.3333, L1 Loss: 6543.1201\n",
            "Batch 4790, Loss: 9423.2246, L2 Loss: 2916.4226, L1 Loss: 6506.8022\n",
            "Batch 4800, Loss: 9508.3828, L2 Loss: 2932.7617, L1 Loss: 6575.6206\n",
            "Batch 4810, Loss: 9495.8711, L2 Loss: 2925.3516, L1 Loss: 6570.5200\n",
            "Batch 4820, Loss: 9271.6504, L2 Loss: 2918.0752, L1 Loss: 6353.5757\n",
            "Batch 4830, Loss: 9342.7695, L2 Loss: 2889.3677, L1 Loss: 6453.4019\n",
            "Batch 4840, Loss: 9190.5674, L2 Loss: 2906.2664, L1 Loss: 6284.3013\n",
            "Batch 4850, Loss: 9252.3447, L2 Loss: 2882.6990, L1 Loss: 6369.6460\n",
            "Batch 4860, Loss: 9445.8174, L2 Loss: 2887.1267, L1 Loss: 6558.6904\n",
            "Batch 4870, Loss: 8983.6875, L2 Loss: 2871.9512, L1 Loss: 6111.7363\n",
            "Batch 4880, Loss: 9236.4414, L2 Loss: 2853.8140, L1 Loss: 6382.6270\n",
            "Batch 4890, Loss: 9152.6709, L2 Loss: 2854.7612, L1 Loss: 6297.9097\n",
            "Batch 4900, Loss: 9608.6924, L2 Loss: 2849.2986, L1 Loss: 6759.3940\n",
            "Batch 4910, Loss: 9339.0244, L2 Loss: 2846.6726, L1 Loss: 6492.3521\n",
            "Batch 4920, Loss: 9425.6533, L2 Loss: 2864.0193, L1 Loss: 6561.6338\n",
            "Batch 4930, Loss: 9422.1270, L2 Loss: 2856.2986, L1 Loss: 6565.8281\n",
            "Batch 4940, Loss: 9295.8203, L2 Loss: 2848.9131, L1 Loss: 6446.9072\n",
            "Batch 4950, Loss: 9031.1699, L2 Loss: 2824.8931, L1 Loss: 6206.2769\n",
            "Batch 4960, Loss: 9177.0430, L2 Loss: 2841.3457, L1 Loss: 6335.6968\n",
            "Batch 4970, Loss: 9235.1416, L2 Loss: 2837.5859, L1 Loss: 6397.5557\n",
            "Batch 4980, Loss: 9069.7207, L2 Loss: 2825.4138, L1 Loss: 6244.3066\n",
            "Batch 4990, Loss: 9146.6416, L2 Loss: 2803.2615, L1 Loss: 6343.3799\n",
            "SAE training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Autoencoder"
      ],
      "metadata": {
        "id": "4G3YdRYB4RZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_ = get_recons_loss(num_batches=5, local_encoder=encoder) # - [ ] TODO: Increase number of batches?"
      ],
      "metadata": {
        "id": "2BewccqL4Uj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8121762d-3176-4795-ae36-f2b007b7f42c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.1043, recons_loss: 2.9206, zero_abl_loss: 14.7330\n",
            "Reconstruction Score: 86.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Frequencies"
      ],
      "metadata": {
        "id": "9XdD3DmT4Vgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = get_freqs(num_batches=25, local_encoder=encoder)\n",
        "\n",
        "# Add 1e-6.5 so that dead features show up as log_freq -6.5\n",
        "log_freq = (freqs + 10 ** -6.5).log10().cpu().numpy()\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(log_freq, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.title(\"Log Frequency of Features\")\n",
        "plt.xlabel(\"Log Frequency\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JmvsQC9y4a2H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613,
          "referenced_widgets": [
            "08deed2411804061ad99dd900fcfc094",
            "8012ed55e30442eb99a8e7c216879844",
            "a4bab5cfe52049da9d095c26b11cec9d",
            "1f6f2826adfe4abbb647b7f1b90bca47",
            "f4321f2b8a5f40caa7f313402d74a126",
            "575ed395f6d94ff1a8e8fdfb37a3ed95",
            "be5991d0e8cb4e49a8dc4f10b739736b",
            "263ebd3f22de4b65a243f06f5e384b53",
            "f4893e3821884f009c60ce0f0a71067a",
            "43c95502b9a74c3186496d69acfc45f4",
            "2482751a70eb40c6a77f17881ee621ff"
          ]
        },
        "outputId": "fea8d911-18e9-4517-ad52-44691f21c97f"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08deed2411804061ad99dd900fcfc094"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead 0.87890625\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpreting A Feature"
      ],
      "metadata": {
        "id": "mdR_2rtj4cWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's investigate the features"
      ],
      "metadata": {
        "id": "LfbqK50lBl-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# - [ ] TODO: Enhance and extend this logic to be more modular\n",
        "import pandas as pd\n",
        "\n",
        "feature_id = 18 # Change as needed\n",
        "batch_size = 128  # Adjust as needed\n",
        "\n",
        "print(f\"Feature freq: {freqs[feature_id].item():.4f}\")\n",
        "\n",
        "# Get activations\n",
        "idx = torch.randperm(len(all_tokens))[:batch_size]\n",
        "tokens = all_tokens[idx].to(model_device)\n",
        "contexts = all_contexts[idx].to(model_device)\n",
        "targets = all_targets[idx].to(model_device)\n",
        "\n",
        "mlp_activations = []\n",
        "\n",
        "def capture_mlp_activations(module, input, output):\n",
        "    mlp_activations.append(output.detach())\n",
        "\n",
        "# Register the hook\n",
        "mlp_layer = model.transformer.h[0].mlp.c_proj\n",
        "hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "# Forward pass\n",
        "logits, _ = model(tokens, contexts)\n",
        "# Remove the hook\n",
        "hook_handle.remove()\n",
        "\n",
        "# Get the activations\n",
        "mlp_acts = mlp_activations[0]  # Shape: [batch_size, seq_len, d_mlp]\n",
        "mlp_acts_flattened = mlp_acts.reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "# Pass through encoder\n",
        "loss_enc, x_reconstruct, hidden_acts, l2_loss, l1_loss = encoder(mlp_acts_flattened)\n",
        "print(\"hidden_acts.shape\", hidden_acts.shape)\n",
        "\n",
        "# Create token dataframe\n",
        "token_df = make_token_df(tokens.cpu().flatten())\n",
        "token_df[\"feature\"] = hidden_acts[:, feature_id].detach().cpu().numpy()\n",
        "display(token_df.sort_values(\"feature\", ascending=False).head(20))"
      ],
      "metadata": {
        "id": "UYT7m6vp4cPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "outputId": "7753317f-4681-49a7-cb31-bed933a3b1aa"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature freq: 0.0337\n",
            "hidden_acts.shape torch.Size([128000, 512])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       str_tokens unique_token               context  batch     pos     label  \\\n",
              "126028        439   439/126028  1513527645119|439|21      0  126028  0/126028   \n",
              "48826         439    439/48826   143371137610|439|21      0   48826   0/48826   \n",
              "97920         439    439/97920   244042842529|439|32      0   97920   0/97920   \n",
              "82064         433    433/82064   383701945129|433|30      0   82064   0/82064   \n",
              "46040         433    433/46040   933151945129|433|43      0   46040   0/46040   \n",
              "44888         439    439/44888   304163042221|439|30      0   44888   0/44888   \n",
              "44958         434    434/44958   313453134120|434|22      0   44958   0/44958   \n",
              "42628         439    439/42628   213383031915|439|30      0   42628   0/42628   \n",
              "67016         434    434/67016   243451045129|434|51      0   67016   0/67016   \n",
              "76032         434    434/76032   304013141631|434|31      0   76032   0/76032   \n",
              "97028         434    434/97028    15338163025|434|31      0   97028   0/97028   \n",
              "62670         433    433/62670   233443132823|433|22      0   62670   0/62670   \n",
              "71788         433    433/71788  3437715132770|433|22      0   71788   0/71788   \n",
              "48056         434    434/48056   304042841721|434|31      0   48056   0/48056   \n",
              "66864         434    434/66864  3036931377151|434|77      0   66864   0/66864   \n",
              "100842        439   439/100842   314213142221|439|30      0  100842  0/100842   \n",
              "126654        439   439/126654   843072144834|439|31      0  126654  0/126654   \n",
              "45644         439    439/45644   313992542830|439|30      0   45644   0/45644   \n",
              "13050         433    433/13050  3736251377151|433|91      0   13050   0/13050   \n",
              "41882         439    439/41882   294063241831|439|31      0   41882   0/41882   \n",
              "\n",
              "          feature  \n",
              "126028  29.820944  \n",
              "48826   28.412743  \n",
              "97920   28.192667  \n",
              "82064   27.944721  \n",
              "46040   27.735754  \n",
              "44888   27.547327  \n",
              "44958   27.329151  \n",
              "42628   27.304499  \n",
              "67016   27.290855  \n",
              "76032   27.273802  \n",
              "97028   27.255402  \n",
              "62670   27.215164  \n",
              "71788   27.197079  \n",
              "48056   27.168510  \n",
              "66864   27.150938  \n",
              "100842  27.131050  \n",
              "126654  27.085423  \n",
              "45644   27.065329  \n",
              "13050   27.022999  \n",
              "41882   27.022314  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c4f5348-5870-41f9-8e34-17eb352cc5b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>str_tokens</th>\n",
              "      <th>unique_token</th>\n",
              "      <th>context</th>\n",
              "      <th>batch</th>\n",
              "      <th>pos</th>\n",
              "      <th>label</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>126028</th>\n",
              "      <td>439</td>\n",
              "      <td>439/126028</td>\n",
              "      <td>1513527645119|439|21</td>\n",
              "      <td>0</td>\n",
              "      <td>126028</td>\n",
              "      <td>0/126028</td>\n",
              "      <td>29.820944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48826</th>\n",
              "      <td>439</td>\n",
              "      <td>439/48826</td>\n",
              "      <td>143371137610|439|21</td>\n",
              "      <td>0</td>\n",
              "      <td>48826</td>\n",
              "      <td>0/48826</td>\n",
              "      <td>28.412743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97920</th>\n",
              "      <td>439</td>\n",
              "      <td>439/97920</td>\n",
              "      <td>244042842529|439|32</td>\n",
              "      <td>0</td>\n",
              "      <td>97920</td>\n",
              "      <td>0/97920</td>\n",
              "      <td>28.192667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82064</th>\n",
              "      <td>433</td>\n",
              "      <td>433/82064</td>\n",
              "      <td>383701945129|433|30</td>\n",
              "      <td>0</td>\n",
              "      <td>82064</td>\n",
              "      <td>0/82064</td>\n",
              "      <td>27.944721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46040</th>\n",
              "      <td>433</td>\n",
              "      <td>433/46040</td>\n",
              "      <td>933151945129|433|43</td>\n",
              "      <td>0</td>\n",
              "      <td>46040</td>\n",
              "      <td>0/46040</td>\n",
              "      <td>27.735754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44888</th>\n",
              "      <td>439</td>\n",
              "      <td>439/44888</td>\n",
              "      <td>304163042221|439|30</td>\n",
              "      <td>0</td>\n",
              "      <td>44888</td>\n",
              "      <td>0/44888</td>\n",
              "      <td>27.547327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44958</th>\n",
              "      <td>434</td>\n",
              "      <td>434/44958</td>\n",
              "      <td>313453134120|434|22</td>\n",
              "      <td>0</td>\n",
              "      <td>44958</td>\n",
              "      <td>0/44958</td>\n",
              "      <td>27.329151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42628</th>\n",
              "      <td>439</td>\n",
              "      <td>439/42628</td>\n",
              "      <td>213383031915|439|30</td>\n",
              "      <td>0</td>\n",
              "      <td>42628</td>\n",
              "      <td>0/42628</td>\n",
              "      <td>27.304499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67016</th>\n",
              "      <td>434</td>\n",
              "      <td>434/67016</td>\n",
              "      <td>243451045129|434|51</td>\n",
              "      <td>0</td>\n",
              "      <td>67016</td>\n",
              "      <td>0/67016</td>\n",
              "      <td>27.290855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76032</th>\n",
              "      <td>434</td>\n",
              "      <td>434/76032</td>\n",
              "      <td>304013141631|434|31</td>\n",
              "      <td>0</td>\n",
              "      <td>76032</td>\n",
              "      <td>0/76032</td>\n",
              "      <td>27.273802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97028</th>\n",
              "      <td>434</td>\n",
              "      <td>434/97028</td>\n",
              "      <td>15338163025|434|31</td>\n",
              "      <td>0</td>\n",
              "      <td>97028</td>\n",
              "      <td>0/97028</td>\n",
              "      <td>27.255402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62670</th>\n",
              "      <td>433</td>\n",
              "      <td>433/62670</td>\n",
              "      <td>233443132823|433|22</td>\n",
              "      <td>0</td>\n",
              "      <td>62670</td>\n",
              "      <td>0/62670</td>\n",
              "      <td>27.215164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71788</th>\n",
              "      <td>433</td>\n",
              "      <td>433/71788</td>\n",
              "      <td>3437715132770|433|22</td>\n",
              "      <td>0</td>\n",
              "      <td>71788</td>\n",
              "      <td>0/71788</td>\n",
              "      <td>27.197079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48056</th>\n",
              "      <td>434</td>\n",
              "      <td>434/48056</td>\n",
              "      <td>304042841721|434|31</td>\n",
              "      <td>0</td>\n",
              "      <td>48056</td>\n",
              "      <td>0/48056</td>\n",
              "      <td>27.168510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66864</th>\n",
              "      <td>434</td>\n",
              "      <td>434/66864</td>\n",
              "      <td>3036931377151|434|77</td>\n",
              "      <td>0</td>\n",
              "      <td>66864</td>\n",
              "      <td>0/66864</td>\n",
              "      <td>27.150938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100842</th>\n",
              "      <td>439</td>\n",
              "      <td>439/100842</td>\n",
              "      <td>314213142221|439|30</td>\n",
              "      <td>0</td>\n",
              "      <td>100842</td>\n",
              "      <td>0/100842</td>\n",
              "      <td>27.131050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126654</th>\n",
              "      <td>439</td>\n",
              "      <td>439/126654</td>\n",
              "      <td>843072144834|439|31</td>\n",
              "      <td>0</td>\n",
              "      <td>126654</td>\n",
              "      <td>0/126654</td>\n",
              "      <td>27.085423</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45644</th>\n",
              "      <td>439</td>\n",
              "      <td>439/45644</td>\n",
              "      <td>313992542830|439|30</td>\n",
              "      <td>0</td>\n",
              "      <td>45644</td>\n",
              "      <td>0/45644</td>\n",
              "      <td>27.065329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13050</th>\n",
              "      <td>433</td>\n",
              "      <td>433/13050</td>\n",
              "      <td>3736251377151|433|91</td>\n",
              "      <td>0</td>\n",
              "      <td>13050</td>\n",
              "      <td>0/13050</td>\n",
              "      <td>27.022999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41882</th>\n",
              "      <td>439</td>\n",
              "      <td>439/41882</td>\n",
              "      <td>294063241831|439|31</td>\n",
              "      <td>0</td>\n",
              "      <td>41882</td>\n",
              "      <td>0/41882</td>\n",
              "      <td>27.022314</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c4f5348-5870-41f9-8e34-17eb352cc5b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c4f5348-5870-41f9-8e34-17eb352cc5b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c4f5348-5870-41f9-8e34-17eb352cc5b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4c90a7d9-fcc9-45ba-89e1-16e99a4dd9cf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4c90a7d9-fcc9-45ba-89e1-16e99a4dd9cf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4c90a7d9-fcc9-45ba-89e1-16e99a4dd9cf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(token_df\",\n  \"rows\": 20,\n  \"fields\": [\n    {\n      \"column\": \"str_tokens\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"439\",\n          \"433\",\n          \"434\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unique_token\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"439/126028\",\n          \"439/45644\",\n          \"439/100842\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"1513527645119|439|21\",\n          \"313992542830|439|30\",\n          \"314213142221|439|30\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"batch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pos\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 29986,\n        \"min\": 13050,\n        \"max\": 126654,\n        \"num_unique_values\": 20,\n        \"samples\": [\n          126028\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"0/126028\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"feature\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          29.82094383239746\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "interesting_feature_ids = [2, 5, 18]"
      ],
      "metadata": {
        "id": "ROqOC8q6tXy0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(freqs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIMduPHtn4SW",
        "outputId": "e30aa7af-bb1f-413d-e3d0-6b77f6d7c35b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO: DEBUG: Visualizing Feature Activations"
      ],
      "metadata": {
        "id": "h-yvVk0v4cFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the character-to-index and index-to-character mappings from the dataset\n",
        "char2idx = train_dataset.stoi  # Character to index mapping\n",
        "idx2char = train_dataset.itos  # Index to character mapping\n",
        "\n",
        "# Define the tokenization function using the dataset's mapping\n",
        "def tokenize_text(text):\n",
        "    # Map each character to its index, default to PAD token (0) for unknown characters\n",
        "    return [char2idx.get(ch, train_dataset.char_PAD_TOKEN) for ch in text]\n",
        "\n",
        "def make_feature_vis_gradio(feature_id, starting_text=None):\n",
        "    if starting_text is None:\n",
        "        starting_text = \"Sample text for visualization\"\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.HTML(value=f\"<h3>Interactive Feature Visualization for cursivetransformer</h3>\")\n",
        "        # The input elements\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                text = gr.Textbox(label=\"Context Text\", value=starting_text)\n",
        "                feature_index = gr.Number(\n",
        "                    label=\"Feature Index\", value=feature_id, precision=0\n",
        "                )\n",
        "                max_val = gr.Number(label=\"Max Value\", value=0)\n",
        "                inputs = [text, feature_index, max_val]\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                # The output element\n",
        "                out = gr.HTML(label=\"Neuron Activations\", value=\"\")\n",
        "        def update_output(text_input, feature_idx, max_value):\n",
        "            return basic_feature_vis(text_input, int(feature_idx), max_value)\n",
        "        for inp in inputs:\n",
        "            inp.change(update_output, inputs, out)\n",
        "    demo.launch(share=True)\n",
        "\n",
        "\n",
        "# def make_feature_vis_gradio(feature_id, starting_text=None):\n",
        "#     if starting_text is None:\n",
        "#         starting_text = \"Sample text for visualization\"\n",
        "\n",
        "#     with gr.Blocks() as demo:\n",
        "#         gr.HTML(value=f\"Hacky Interactive Neuroscope for cursivetransformer\")\n",
        "#         # The input elements\n",
        "#         with gr.Row():\n",
        "#             with gr.Column():\n",
        "#                 text = gr.Textbox(label=\"Context Text\", value=starting_text)\n",
        "#                 feature_index = gr.Number(\n",
        "#                     label=\"Feature Index\", value=feature_id, precision=0\n",
        "#                 )\n",
        "#                 max_val = gr.Number(label=\"Max Value\", value=None)\n",
        "#                 inputs = [text, feature_index, max_val]\n",
        "#         with gr.Row():\n",
        "#             with gr.Column():\n",
        "#                 # The output element\n",
        "#                 out = gr.HTML(label=\"Neuron Acts\", value=basic_feature_vis(feature_id))\n",
        "#         def update_output(text, feature_index, max_val):\n",
        "#             return basic_feature_vis(text, int(feature_index), max_val)\n",
        "#         for inp in inputs:\n",
        "#             inp.change(update_output, inputs, out)\n",
        "#     demo.launch(share=True)\n",
        "\n",
        "# # Visualize the feature activations\n",
        "starting_text = \"Sample text to test feature activations in cursivetransformer\"\n",
        "make_feature_vis_gradio(feature_id, starting_text)"
      ],
      "metadata": {
        "id": "KvYERycr4bz5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "outputId": "3e9c0fae-a5d6-47ce-b442-dc326cce7723"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://5118b30898a260a4c2.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5118b30898a260a4c2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b4EPQKNY_vka"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}