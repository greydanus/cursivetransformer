{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN2/9v2BZnoVc+z9PXv+cuO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a51eef49051d414c8b3820cbc7fccbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0571b375cbcb4e97866d02472bac7704",
              "IPY_MODEL_e791c78e9f1b4433bb290ed981480495",
              "IPY_MODEL_65b27b7e83ab46d386ff30511e71a70a"
            ],
            "layout": "IPY_MODEL_2c69eef9c35f41b5b2583934656d92c8"
          }
        },
        "0571b375cbcb4e97866d02472bac7704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984b02ed8be2458c8c70ff9df66da74d",
            "placeholder": "​",
            "style": "IPY_MODEL_13861f7d0891488583697235fc5031f0",
            "value": "100%"
          }
        },
        "e791c78e9f1b4433bb290ed981480495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75b7c01cf9314250b85bca9ce1643dd8",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a619f54495ad4208827293d9bd01a8bf",
            "value": 100
          }
        },
        "65b27b7e83ab46d386ff30511e71a70a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984da99d3d2043cba8e3c381c6a569ec",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ac29e6205e4f2b8074222d6920a288",
            "value": " 100/100 [00:13&lt;00:00,  8.21it/s]"
          }
        },
        "2c69eef9c35f41b5b2583934656d92c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984b02ed8be2458c8c70ff9df66da74d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "13861f7d0891488583697235fc5031f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75b7c01cf9314250b85bca9ce1643dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a619f54495ad4208827293d9bd01a8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "984da99d3d2043cba8e3c381c6a569ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ac29e6205e4f2b8074222d6920a288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "424adc9f4a0348989ef94b82fef23797": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b373ed3f6f1a484c920533065a130086",
              "IPY_MODEL_6b1e130bd2b34440be27d9b63d356c41",
              "IPY_MODEL_2c335e2902e64c4bb09764537497cefc"
            ],
            "layout": "IPY_MODEL_c63e6598c602430fba3160cc11fe9707"
          }
        },
        "b373ed3f6f1a484c920533065a130086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecfb04d0f53d4968a407d3c3cb90a646",
            "placeholder": "​",
            "style": "IPY_MODEL_3f4a0e020b63485dae8696e354256a19",
            "value": "100%"
          }
        },
        "6b1e130bd2b34440be27d9b63d356c41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97fa6733e1ae4e159c1e5ad841cfae6a",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34e4aef27a634a3282f884f10e4218ca",
            "value": 25
          }
        },
        "2c335e2902e64c4bb09764537497cefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a61fba88719b4ec3916d15c2248c5625",
            "placeholder": "​",
            "style": "IPY_MODEL_78f48496fbd0415cadfdef2bbb5ff80f",
            "value": " 25/25 [00:01&lt;00:00, 16.62it/s]"
          }
        },
        "c63e6598c602430fba3160cc11fe9707": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecfb04d0f53d4968a407d3c3cb90a646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f4a0e020b63485dae8696e354256a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97fa6733e1ae4e159c1e5ad841cfae6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34e4aef27a634a3282f884f10e4218ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a61fba88719b4ec3916d15c2248c5625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f48496fbd0415cadfdef2bbb5ff80f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zwimpee/cursivetransformer/blob/main/cursivetransformer_dictionary_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cursive Transformer Mechanistic Interpretability\n",
        "\n",
        "The purpose of this notebook is to apply the techniques of mechanistic interpretability, in particular dictionary learning, to our cursive transformer. The goal of this exercise is two-fold:\n",
        "1. Attempt to gain insight into the structure and orientation of the features being learned by the model, in particular in the cross-attention and feed-forward layers\n",
        "2. More generally become familiar with the latest ME techniques, as they can easily transfer to be applied beyond the scope of this project to essentially ANY transformer-based model\n",
        "\n",
        "To this end, we will reference the following resources throughout this document:\n",
        "- https://transformer-circuits.pub/2023/monosemantic-features\n",
        "- https://www.alignmentforum.org/posts/fKuugaxt2XLTkASkk/open-source-replication-and-commentary-on-anthropic-s\n",
        "- https://colab.research.google.com/drive/1u8larhpxy8w4mMsJiSBddNOzFGj7_RTn?usp=sharing\n",
        "- https://github.com/TransformerLensOrg/TransformerLens\n",
        "- https://arena3-chapter1-transformer-interp.streamlit.app/"
      ],
      "metadata": {
        "id": "GdwBlsu_am35"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TODO\n",
        "1. Train the autoencoder"
      ],
      "metadata": {
        "id": "Adz0ylO5CkOi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "JuHwKIaP3Oyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -V"
      ],
      "metadata": {
        "id": "12UmRQ9N3Rav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "5BpggN2t3Qr4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary packages\n",
        "!python3 -V\n",
        "\n",
        "!pip install transformer_lens\n",
        "!pip install gradio\n",
        "!pip install wandb\n",
        "!pip install einops\n",
        "!pip install matplotlib\n",
        "!pip install datasets\n",
        "\n",
        "# Clone the cursivetransformer repository and install its requirements\n",
        "!rm -rf cursivetransformer && git clone https://github.com/zwimpee/cursivetransformer.git\n",
        "!pip install -r cursivetransformer/requirements.txt\n",
        "\n",
        "# Login to Weights & Biases (replace 'your_api_key' with your actual API key)\n",
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "VY-xjph_3QkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "cWhbLc-33V2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/cursivetransformer')  # Adjust the path if necessary\n",
        "\n",
        "# Import cursivetransformer modules\n",
        "from cursivetransformer.model import get_all_args, get_checkpoint\n",
        "from cursivetransformer.data import create_datasets\n",
        "\n",
        "# Import other necessary libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import pprint\n",
        "import json\n",
        "from datasets import load_dataset\n",
        "from IPython.display import HTML, display\n",
        "from functools import partial\n",
        "import tqdm.notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from einops import rearrange"
      ],
      "metadata": {
        "id": "xit1BQED3ZK_"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Autoencoder"
      ],
      "metadata": {
        "id": "NkFwM1If3bbO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1p4_vsXeZigM"
      },
      "outputs": [],
      "source": [
        "# Configuration for the autoencoder\n",
        "cfg = {\n",
        "    \"seed\": 49,\n",
        "    \"batch_size\": 4096,\n",
        "    \"buffer_mult\": 384,\n",
        "    \"lr\": 1e-4,\n",
        "    \"num_tokens\": int(2e9),\n",
        "    \"l1_coeff\": 3e-4,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.99,\n",
        "    \"dict_mult\": 8,\n",
        "    \"seq_len\": 128,\n",
        "    \"d_mlp\": None,  # To be set after loading the model\n",
        "    \"enc_dtype\": \"fp32\",\n",
        "    \"remove_rare_dir\": False,\n",
        "}\n",
        "\n",
        "cfg[\"model_batch_size\"] = 64\n",
        "cfg[\"buffer_size\"] = cfg[\"batch_size\"] * cfg[\"buffer_mult\"]\n",
        "cfg[\"buffer_batches\"] = cfg[\"buffer_size\"] // cfg[\"seq_len\"]\n",
        "\n",
        "DTYPES = {\"fp32\": torch.float32, \"fp16\": torch.float16, \"bf16\": torch.bfloat16}\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        d_hidden = cfg[\"d_mlp\"] * cfg[\"dict_mult\"]\n",
        "        d_mlp = cfg[\"d_mlp\"]\n",
        "        l1_coeff = cfg[\"l1_coeff\"]\n",
        "        dtype = DTYPES[cfg[\"enc_dtype\"]]\n",
        "        torch.manual_seed(cfg[\"seed\"])\n",
        "        self.W_enc = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_mlp, d_hidden, dtype=dtype)))\n",
        "        self.W_dec = nn.Parameter(torch.nn.init.kaiming_uniform_(torch.empty(d_hidden, d_mlp, dtype=dtype)))\n",
        "        self.b_enc = nn.Parameter(torch.zeros(d_hidden, dtype=dtype))\n",
        "        self.b_dec = nn.Parameter(torch.zeros(d_mlp, dtype=dtype))\n",
        "\n",
        "        self.W_dec.data[:] = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        self.d_hidden = d_hidden\n",
        "        self.l1_coeff = l1_coeff\n",
        "\n",
        "        self.to(\"cuda\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_cent = x - self.b_dec\n",
        "        acts = F.relu(x_cent @ self.W_enc + self.b_enc)\n",
        "        x_reconstruct = acts @ self.W_dec + self.b_dec\n",
        "        l2_loss = (x_reconstruct.float() - x.float()).pow(2).sum(-1).mean(0)\n",
        "        l1_loss = self.l1_coeff * (acts.float().abs().sum())\n",
        "        loss = l2_loss + l1_loss\n",
        "        return loss, x_reconstruct, acts, l2_loss, l1_loss\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def remove_parallel_component_of_grads(self):\n",
        "        W_dec_normed = self.W_dec / self.W_dec.norm(dim=-1, keepdim=True)\n",
        "        W_dec_grad_proj = (self.W_dec.grad * W_dec_normed).sum(-1, keepdim=True) * W_dec_normed\n",
        "        self.W_dec.grad -= W_dec_grad_proj"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils\n",
        "\n"
      ],
      "metadata": {
        "id": "TDksX_ZQ3lcD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Reconstruction Loss"
      ],
      "metadata": {
        "id": "iDiByoQV3kvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_recons_loss(num_batches=5, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    loss_list = []\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "    for i in range(num_batches):\n",
        "        idx = torch.randperm(len(all_tokens))[:cfg[\"model_batch_size\"]]\n",
        "        tokens = all_tokens[idx].to(model_device)\n",
        "        context = all_contexts[idx].to(model_device)\n",
        "        targets = all_targets[idx].to(model_device)\n",
        "\n",
        "        # Capture MLP activations\n",
        "        mlp_activations = []\n",
        "\n",
        "        def capture_mlp_activations(module, input, output):\n",
        "            mlp_activations.append(output.detach())\n",
        "\n",
        "        # Register the hook on the MLP output layer\n",
        "        mlp_layer = model.transformer.h[0].mlp.c_proj  # Adjust layer index as needed\n",
        "        hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "        # Forward pass without hooks\n",
        "        logits, loss = model(tokens, context, targets=targets)\n",
        "        loss = loss.item()\n",
        "\n",
        "        # Remove the hook\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Get the activations\n",
        "        mlp_acts = mlp_activations[0]  # Shape: [batch_size, seq_len, d_mlp]\n",
        "\n",
        "        # Flatten activations\n",
        "        mlp_acts_flattened = mlp_acts.reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "        # Reconstruct activations using encoder\n",
        "        loss_enc, x_reconstruct, hidden_acts, l2_loss, l1_loss = local_encoder(mlp_acts_flattened)\n",
        "\n",
        "        # Reconstructed activations reshaped back to original shape\n",
        "        reconstructed_acts = x_reconstruct.view_as(mlp_acts)\n",
        "\n",
        "        # Define the hook to replace activations\n",
        "        def reconstruction_hook(module, input, output):\n",
        "            return reconstructed_acts\n",
        "\n",
        "        # Register the reconstruction hook\n",
        "        hook_handle = mlp_layer.register_forward_hook(reconstruction_hook)\n",
        "        # Forward pass with reconstructed activations\n",
        "        logits_recons, loss_recons = model(tokens, context, targets=targets)\n",
        "        recons_loss = loss_recons.item()\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Zero ablation\n",
        "        def zero_ablation_hook(module, input, output):\n",
        "            return torch.zeros_like(output)\n",
        "\n",
        "        hook_handle = mlp_layer.register_forward_hook(zero_ablation_hook)\n",
        "        logits_zero_abl, loss_zero_abl = model(tokens, context, targets=targets)\n",
        "        zero_abl_loss = loss_zero_abl.item()\n",
        "        hook_handle.remove()\n",
        "\n",
        "        loss_list.append((loss, recons_loss, zero_abl_loss))\n",
        "    losses = torch.tensor(loss_list)\n",
        "    loss, recons_loss, zero_abl_loss = losses.mean(0).tolist()\n",
        "\n",
        "    print(f\"loss: {loss:.4f}, recons_loss: {recons_loss:.4f}, zero_abl_loss: {zero_abl_loss:.4f}\")\n",
        "    score = ((zero_abl_loss - recons_loss) / (zero_abl_loss - loss))\n",
        "    print(f\"Reconstruction Score: {score:.2%}\")\n",
        "    return score, loss, recons_loss, zero_abl_loss"
      ],
      "metadata": {
        "id": "pxQjA1Xh3pgP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get Frequencies"
      ],
      "metadata": {
        "id": "j1dKdlV13rTg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def get_freqs(num_batches=25, local_encoder=None):\n",
        "    if local_encoder is None:\n",
        "        local_encoder = encoder\n",
        "    act_freq_scores = torch.zeros(local_encoder.d_hidden, dtype=torch.float32).cuda()\n",
        "    total = 0\n",
        "    for i in tqdm.trange(num_batches):\n",
        "        idx = torch.randperm(len(all_tokens))[:cfg[\"model_batch_size\"]]\n",
        "        tokens = all_tokens[idx].to(model_device)\n",
        "        context = all_contexts[idx].to(model_device)\n",
        "\n",
        "        mlp_activations = []\n",
        "\n",
        "        def capture_mlp_activations(module, input, output):\n",
        "            mlp_activations.append(output.detach())\n",
        "\n",
        "        # Register the hook on the MLP output layer\n",
        "        mlp_layer = model.transformer.h[0].mlp.c_proj  # Adjust layer index as needed\n",
        "        hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "        # Forward pass\n",
        "        logits, _ = model(tokens, context)\n",
        "        # Remove the hook\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Get the activations\n",
        "        mlp_acts = mlp_activations[0]  # Shape: [batch_size, seq_len, d_mlp]\n",
        "        mlp_acts_flattened = mlp_acts.reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "        # Pass through encoder\n",
        "        hidden = local_encoder(mlp_acts_flattened)[2]  # Get the activations\n",
        "\n",
        "        act_freq_scores += (hidden > 0).sum(0)\n",
        "        total += hidden.shape[0]\n",
        "    act_freq_scores /= total\n",
        "    num_dead = (act_freq_scores == 0).float().mean()\n",
        "    print(\"Num dead\", num_dead.item())\n",
        "    return act_freq_scores\n"
      ],
      "metadata": {
        "id": "kbDgvhpS3vnU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualise Feature Utils"
      ],
      "metadata": {
        "id": "kk1mA6FK3y0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from html import escape\n",
        "import colorsys\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "SPACE = \"·\"\n",
        "NEWLINE = \"↩\"\n",
        "TAB = \"→\"\n",
        "\n",
        "\n",
        "\n",
        "def create_html(strings, values, max_value=None, saturation=0.5, allow_different_length=False, return_string=False):\n",
        "    # Escape strings to deal with tabs, newlines, etc.\n",
        "    escaped_strings = [escape(s, quote=True) for s in strings]\n",
        "    processed_strings = [\n",
        "        s.replace(\"\\n\", f\"{NEWLINE}<br/>\").replace(\"\\t\", f\"{TAB}&emsp;\").replace(\" \", \"&nbsp;\")\n",
        "        for s in escaped_strings\n",
        "    ]\n",
        "\n",
        "    if isinstance(values, torch.Tensor) and len(values.shape) > 1:\n",
        "        values = values.flatten().tolist()\n",
        "\n",
        "    if not allow_different_length:\n",
        "        assert len(processed_strings) == len(values)\n",
        "\n",
        "    # Scale values\n",
        "    if max_value is None:\n",
        "        max_value = max(max(values), -min(values)) + 1e-3\n",
        "    scaled_values = [v / max_value * saturation for v in values]\n",
        "\n",
        "    # Create HTML\n",
        "    html = \"\"\n",
        "    for i, s in enumerate(processed_strings):\n",
        "        if i < len(scaled_values):\n",
        "            v = scaled_values[i]\n",
        "        else:\n",
        "            v = 0\n",
        "        if v < 0:\n",
        "            hue = 0  # Red in HSV\n",
        "        else:\n",
        "            hue = 0.66  # Blue in HSV\n",
        "        rgb_color = colorsys.hsv_to_rgb(\n",
        "            hue, v, 1\n",
        "        )\n",
        "        hex_color = \"#%02x%02x%02x\" % (\n",
        "            int(rgb_color[0] * 255),\n",
        "            int(rgb_color[1] * 255),\n",
        "            int(rgb_color[2] * 255),\n",
        "        )\n",
        "        html += f'<span style=\"background-color: {hex_color}; border: 1px solid lightgray; font-size: 16px; border-radius: 3px;\">{s}</span>'\n",
        "    if return_string:\n",
        "        return html\n",
        "    else:\n",
        "        display(HTML(html))\n",
        "\n",
        "def basic_feature_vis(feature_index, max_val=0):\n",
        "    feature_in = encoder.W_enc[:, feature_index]\n",
        "    feature_bias = encoder.b_enc[feature_index]\n",
        "\n",
        "    # Get a sample stroke sequence and context from the dataset\n",
        "    x, c, _ = test_dataset[0]  # You can choose any index or randomize\n",
        "    tokens = x.unsqueeze(0).to(model_device)  # Stroke tokens\n",
        "    context = c.unsqueeze(0).to(model_device)  # Context tokens\n",
        "\n",
        "    # Capture MLP activations\n",
        "    mlp_activations = []\n",
        "\n",
        "    def capture_mlp_activations(module, input, output):\n",
        "        mlp_activations.append(output.detach())\n",
        "\n",
        "    # Register the hook\n",
        "    mlp_layer = model.transformer.h[0].mlp.c_proj\n",
        "    hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "    # Forward pass\n",
        "    logits, _ = model(tokens, context)\n",
        "    # Remove the hook\n",
        "    hook_handle.remove()\n",
        "\n",
        "    # Get the activations\n",
        "    mlp_acts = mlp_activations[0][0].cpu()  # Shape: [seq_len, d_mlp]\n",
        "    feature_acts = F.relu((mlp_acts - encoder.b_dec.cpu()) @ feature_in.cpu() + feature_bias.cpu())\n",
        "    if max_val == 0:\n",
        "        max_val = max(1e-7, feature_acts.max().item())\n",
        "\n",
        "    # Visualization\n",
        "    tokens_str = ['[Stroke]' for _ in range(tokens.shape[1])]\n",
        "\n",
        "    return basic_token_vis_make_str(tokens_str, feature_acts, max_val)\n",
        "\n",
        "\n",
        "def basic_token_vis_make_str(strings, values, max_val=None):\n",
        "    if not isinstance(strings, list):\n",
        "        strings = list(strings)\n",
        "    values = values.detach().numpy()\n",
        "    if max_val is None:\n",
        "        max_val = values.max()\n",
        "    header_string = f\"<h4>Max Range <b>{values.max():.4f}</b> Min Range: <b>{values.min():.4f}</b></h4>\"\n",
        "    header_string += f\"<h4>Set Max Range <b>{max_val:.4f}</b></h4>\"\n",
        "    body_string = create_html(strings, values, max_value=max_val, return_string=True)\n",
        "    return header_string + body_string\n",
        "\n",
        "def list_flatten(nested_list):\n",
        "    return [x for y in nested_list for x in y]\n",
        "\n",
        "def make_token_df(tokens, len_prefix=5, len_suffix=1):\n",
        "    str_tokens = [idx2char.get(t.item(), '') for t in tokens]\n",
        "    unique_token = [f\"{s}/{i}\" for i, s in enumerate(str_tokens)]\n",
        "\n",
        "    context = []\n",
        "    batch = []\n",
        "    pos = []\n",
        "    label = []\n",
        "    for p in range(len(tokens)):\n",
        "        prefix = \"\".join(str_tokens[max(0, p - len_prefix):p])\n",
        "        if p == len(tokens) - 1:\n",
        "            suffix = \"\"\n",
        "        else:\n",
        "            suffix = \"\".join(str_tokens[p + 1:min(len(tokens), p + 1 + len_suffix)])\n",
        "        current = str_tokens[p]\n",
        "        context.append(f\"{prefix}|{current}|{suffix}\")\n",
        "        batch.append(0)  # Since we have a single batch\n",
        "        pos.append(p)\n",
        "        label.append(f\"{0}/{p}\")\n",
        "    return pd.DataFrame(dict(\n",
        "        str_tokens=str_tokens,\n",
        "        unique_token=unique_token,\n",
        "        context=context,\n",
        "        batch=batch,\n",
        "        pos=pos,\n",
        "        label=label,\n",
        "    ))"
      ],
      "metadata": {
        "id": "I9jLMFym32Yw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Token DataFrame"
      ],
      "metadata": {
        "id": "NZmEcWIx34gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def list_flatten(nested_list):\n",
        "    return [x for y in nested_list for x in y]\n",
        "\n",
        "def make_token_df(tokens, len_prefix=5, len_suffix=1):\n",
        "    str_tokens = [str(t.item()) for t in tokens]\n",
        "    unique_token = [f\"{s}/{i}\" for i, s in enumerate(str_tokens)]\n",
        "\n",
        "    context = []\n",
        "    batch = []\n",
        "    pos = []\n",
        "    label = []\n",
        "    for p in range(len(tokens)):\n",
        "        prefix = \"\".join(str_tokens[max(0, p - len_prefix):p])\n",
        "        if p == len(tokens) - 1:\n",
        "            suffix = \"\"\n",
        "        else:\n",
        "            suffix = \"\".join(str_tokens[p + 1:min(len(tokens) - 1, p + 1 + len_suffix)])\n",
        "        current = str_tokens[p]\n",
        "        context.append(f\"{prefix}|{current}|{suffix}\")\n",
        "        batch.append(0)  # Since we have a single batch\n",
        "        pos.append(p)\n",
        "        label.append(f\"{0}/{p}\")\n",
        "    return pd.DataFrame(dict(\n",
        "        str_tokens=str_tokens,\n",
        "        unique_token=unique_token,\n",
        "        context=context,\n",
        "        batch=batch,\n",
        "        pos=pos,\n",
        "        label=label,\n",
        "    ))"
      ],
      "metadata": {
        "id": "j3py2Keq37VI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Model"
      ],
      "metadata": {
        "id": "rpgE-1vu37QZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = get_all_args(False)\n",
        "args.sample_only = True\n",
        "args.load_from_run_id = '6le6tujz'  # Replace with your actual run ID\n",
        "args.wandb_entity = 'sam-greydanus'\n",
        "args.dataset_name = 'bigbank'  # Replace with your dataset name\n",
        "args.wandb_run_name = 'cursivetransformer_dictionary_learning'\n",
        "\n",
        "torch.manual_seed(args.seed)\n",
        "torch.cuda.manual_seed_all(args.seed)\n",
        "\n",
        "train_dataset, test_dataset = create_datasets(args)\n",
        "\n",
        "args.block_size = train_dataset.get_stroke_seq_length()\n",
        "args.context_block_size = train_dataset.get_text_seq_length()\n",
        "args.vocab_size = train_dataset.get_vocab_size()\n",
        "args.context_vocab_size = train_dataset.get_char_vocab_size()\n",
        "\n",
        "model, optimizer, scheduler, step, best_loss = get_checkpoint(args)\n",
        "\n",
        "\n",
        "cfg[\"d_mlp\"] = args.n_embd  # Assuming n_embd is the MLP dimension\n",
        "args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb6qP_3i72fU",
        "outputId": "b1df1c37-b277-42ad-87a4-6740d6acf1d1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trying to load dataset file from /content/cursivetransformer/data/bigbank.json.zip\n",
            "Succeeded in loading the bigbank dataset; contains 1900 items.\n",
            "For a dataset of 1805 examples we can generate 440811596555 combinations of 4 examples.\n",
            "Generating 497000 4-word examples.\n",
            "For a dataset of 95 examples we can generate 3183545 combinations of 4 examples.\n",
            "Generating 3000 4-word examples.\n",
            "Number of examples in the train dataset: 497000\n",
            "Number of examples in the test dataset: 3000\n",
            "Max token sequence length: 1000\n",
            "Number of unique characters in the ascii vocabulary: 71\n",
            "Ascii vocabulary:\n",
            "\t\" enaitoshrdx.vpukbgfcymzw1lqj804I92637OTAS5N)EHR\"'(BCQLMWYU,ZF!DXV?KPGJ\"\n",
            "Split up the dataset into 497000 training examples and 3000 test examples\n",
            "Number of Transformer parameters: 368064\n",
            "Model #params: 397184\n",
            "Loaded model from local path: best_checkpoint.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "namespace(max_steps=110000,\n",
              "          print_every=100,\n",
              "          log_every=2500,\n",
              "          lr_decay=0.333,\n",
              "          step_lr_every=33000,\n",
              "          device='cuda',\n",
              "          seed=42,\n",
              "          n_layer=4,\n",
              "          n_embd=64,\n",
              "          n_embd2=64,\n",
              "          n_ctx_head=4,\n",
              "          learning_rate=0.01,\n",
              "          weight_decay=0.0001,\n",
              "          batch_size=32,\n",
              "          train_size=497000,\n",
              "          test_size=3000,\n",
              "          num_words=4,\n",
              "          max_seq_length=1000,\n",
              "          augment=True,\n",
              "          ablate_cross_attention=False,\n",
              "          downsample_mean=0.65,\n",
              "          downsample_width=0.1,\n",
              "          add_digits=True,\n",
              "          alphabet=' enaitoshrdx.vpukbgfcymzw1lqj804I92637OTAS5N)EHR\"\\'(BCQLMWYU,ZF!DXV?KPGJ',\n",
              "          dataset_name='bigbank',\n",
              "          wandb_project='bigbank_experiments',\n",
              "          wandb_entity='sam-greydanus',\n",
              "          wandb_run_name='cursivetransformer_dictionary_learning',\n",
              "          wandb_api_key=None,\n",
              "          load_from_run_id='6le6tujz',\n",
              "          sample_only=True,\n",
              "          local_checkpoint_path='best_checkpoint.pt',\n",
              "          block_size=1000,\n",
              "          context_block_size=50,\n",
              "          vocab_size=455,\n",
              "          context_vocab_size=72)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_device = 'cuda'\n",
        "model = model.to(model_device)\n",
        "model = model.eval()  # Set model to evaluation mode"
      ],
      "metadata": {
        "id": "f650Kjl_O-P4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Data"
      ],
      "metadata": {
        "id": "hTPC8yxS4DNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "batch_size = cfg[\"model_batch_size\"]\n",
        "num_samples = 1000  # Adjust based on your dataset size\n",
        "stroke_seqs = []\n",
        "contexts = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "    x, c, y = test_dataset[i]\n",
        "    stroke_seqs.append(x)\n",
        "    contexts.append(c)\n",
        "\n",
        "all_tokens = torch.stack(stroke_seqs)\n",
        "all_contexts = torch.stack(contexts)"
      ],
      "metadata": {
        "id": "nAEcf7h_4DFN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "q7_RwgFV4Mln"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize the Autoencoder"
      ],
      "metadata": {
        "id": "JwmkLrrc4Cv3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = AutoEncoder(cfg)"
      ],
      "metadata": {
        "id": "Yiea6x6o4Q69"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Autoencoder"
      ],
      "metadata": {
        "id": "u4f-J5kyOa9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sae(model, encoder, num_batches=100, batch_size=128):\n",
        "    optimizer = torch.optim.Adam(encoder.parameters(), lr=cfg['lr'], betas=(cfg['beta1'], cfg['beta2']))\n",
        "\n",
        "    for batch in tqdm.tqdm(range(num_batches)):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Sample data\n",
        "        idx = torch.randperm(len(all_tokens))[:batch_size]\n",
        "        tokens = all_tokens[idx].to(model_device)\n",
        "        contexts = all_contexts[idx].to(model_device)\n",
        "\n",
        "        # Capture MLP activations\n",
        "        mlp_activations = []\n",
        "        def capture_mlp_activations(module, input, output):\n",
        "            mlp_activations.append(output.detach())\n",
        "\n",
        "        # Register the hook\n",
        "        mlp_layer = model.transformer.h[0].mlp.c_proj\n",
        "        hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            _ = model(tokens, contexts)\n",
        "\n",
        "        # Remove the hook\n",
        "        hook_handle.remove()\n",
        "\n",
        "        # Get the activations\n",
        "        mlp_acts = mlp_activations[0].reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "        # Pass through encoder\n",
        "        loss, _, _, l2_loss, l1_loss = encoder(mlp_acts)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 10 == 0:\n",
        "            print(f\"Batch {batch}, Loss: {loss.item():.4f}, L2 Loss: {l2_loss.item():.4f}, L1 Loss: {l1_loss.item():.4f}\")\n",
        "\n",
        "    print(\"SAE training completed.\")\n",
        "\n",
        "# Train the SAE\n",
        "train_sae(model, encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240,
          "referenced_widgets": [
            "a51eef49051d414c8b3820cbc7fccbd4",
            "0571b375cbcb4e97866d02472bac7704",
            "e791c78e9f1b4433bb290ed981480495",
            "65b27b7e83ab46d386ff30511e71a70a",
            "2c69eef9c35f41b5b2583934656d92c8",
            "984b02ed8be2458c8c70ff9df66da74d",
            "13861f7d0891488583697235fc5031f0",
            "75b7c01cf9314250b85bca9ce1643dd8",
            "a619f54495ad4208827293d9bd01a8bf",
            "984da99d3d2043cba8e3c381c6a569ec",
            "a5ac29e6205e4f2b8074222d6920a288"
          ]
        },
        "id": "FAgTAimjOajl",
        "outputId": "084fedb5-5a41-4d46-f3cc-9b42f932a573"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/100 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a51eef49051d414c8b3820cbc7fccbd4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0, Loss: 148600.3125, L2 Loss: 68905.7578, L1 Loss: 79694.5469\n",
            "Batch 10, Loss: 136006.0781, L2 Loss: 56023.0664, L1 Loss: 79983.0156\n",
            "Batch 20, Loss: 119153.3828, L2 Loss: 41808.9766, L1 Loss: 77344.4062\n",
            "Batch 30, Loss: 102777.5859, L2 Loss: 30336.7734, L1 Loss: 72440.8125\n",
            "Batch 40, Loss: 98984.3828, L2 Loss: 25417.9688, L1 Loss: 73566.4141\n",
            "Batch 50, Loss: 87708.1250, L2 Loss: 20074.7910, L1 Loss: 67633.3359\n",
            "Batch 60, Loss: 80645.4844, L2 Loss: 16945.4043, L1 Loss: 63700.0820\n",
            "Batch 70, Loss: 77531.1094, L2 Loss: 15202.6943, L1 Loss: 62328.4141\n",
            "Batch 80, Loss: 74130.2969, L2 Loss: 13975.5703, L1 Loss: 60154.7266\n",
            "Batch 90, Loss: 69722.4375, L2 Loss: 12990.1641, L1 Loss: 56732.2773\n",
            "SAE training completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the Autoencoder"
      ],
      "metadata": {
        "id": "4G3YdRYB4RZr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data\n",
        "batch_size = cfg[\"model_batch_size\"]\n",
        "num_samples = 1000  # Adjust based on your dataset size\n",
        "stroke_seqs = []\n",
        "contexts = []\n",
        "targets = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "    x, c, y = test_dataset[i]\n",
        "    stroke_seqs.append(x)\n",
        "    contexts.append(c)\n",
        "    targets.append(y)\n",
        "\n",
        "all_tokens = torch.stack(stroke_seqs)\n",
        "all_contexts = torch.stack(contexts)\n",
        "all_targets = torch.stack(targets)\n",
        "\n",
        "# Define hook name based on your model's architecture\n",
        "mlp_hook_name = 'transformer.h.0.mlp.c_proj'  # Adjust as per your model\n",
        "\n",
        "# Run the reconstruction loss function\n",
        "_ = get_recons_loss(num_batches=5, local_encoder=encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BewccqL4Uj1",
        "outputId": "63486e9b-91aa-48a4-ffbe-bbd828674d08"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: 1.1181, recons_loss: 8.6318, zero_abl_loss: 14.6293\n",
            "Reconstruction Score: 44.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get Frequencies"
      ],
      "metadata": {
        "id": "9XdD3DmT4Vgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freqs = get_freqs(num_batches=25, local_encoder=encoder)\n",
        "\n",
        "# Add 1e-6.5 so that dead features show up as log_freq -6.5\n",
        "log_freq = (freqs + 10 ** -6.5).log10().cpu().numpy()\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(log_freq, bins=50, color='skyblue', edgecolor='black')\n",
        "plt.title(\"Log Frequency of Features\")\n",
        "plt.xlabel(\"Log Frequency\")\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595,
          "referenced_widgets": [
            "424adc9f4a0348989ef94b82fef23797",
            "b373ed3f6f1a484c920533065a130086",
            "6b1e130bd2b34440be27d9b63d356c41",
            "2c335e2902e64c4bb09764537497cefc",
            "c63e6598c602430fba3160cc11fe9707",
            "ecfb04d0f53d4968a407d3c3cb90a646",
            "3f4a0e020b63485dae8696e354256a19",
            "97fa6733e1ae4e159c1e5ad841cfae6a",
            "34e4aef27a634a3282f884f10e4218ca",
            "a61fba88719b4ec3916d15c2248c5625",
            "78f48496fbd0415cadfdef2bbb5ff80f"
          ]
        },
        "id": "JmvsQC9y4a2H",
        "outputId": "f9b8ec3b-9bec-441c-a5a0-f1bfb2f35c16"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/25 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "424adc9f4a0348989ef94b82fef23797"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num dead 0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interpreting A Feature"
      ],
      "metadata": {
        "id": "mdR_2rtj4cWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's investigate a non-rare feature, for example, `feature_id = 7`."
      ],
      "metadata": {
        "id": "LfbqK50lBl-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "feature_id = 7  # Change as needed\n",
        "batch_size = 128  # Adjust as needed\n",
        "\n",
        "print(f\"Feature freq: {freqs[feature_id].item():.4f}\")\n",
        "\n",
        "# Get activations\n",
        "idx = torch.randperm(len(all_tokens))[:batch_size]\n",
        "tokens = all_tokens[idx].to(model_device)\n",
        "contexts = all_contexts[idx].to(model_device)\n",
        "targets = all_targets[idx].to(model_device)\n",
        "\n",
        "mlp_activations = []\n",
        "\n",
        "def capture_mlp_activations(module, input, output):\n",
        "    mlp_activations.append(output.detach())\n",
        "\n",
        "# Register the hook\n",
        "mlp_layer = model.transformer.h[0].mlp.c_proj\n",
        "hook_handle = mlp_layer.register_forward_hook(capture_mlp_activations)\n",
        "\n",
        "# Forward pass\n",
        "logits, _ = model(tokens, contexts)\n",
        "# Remove the hook\n",
        "hook_handle.remove()\n",
        "\n",
        "# Get the activations\n",
        "mlp_acts = mlp_activations[0]  # Shape: [batch_size, seq_len, d_mlp]\n",
        "mlp_acts_flattened = mlp_acts.reshape(-1, cfg[\"d_mlp\"])\n",
        "\n",
        "# Pass through encoder\n",
        "loss_enc, x_reconstruct, hidden_acts, l2_loss, l1_loss = encoder(mlp_acts_flattened)\n",
        "print(\"hidden_acts.shape\", hidden_acts.shape)\n",
        "\n",
        "# Create token dataframe\n",
        "token_df = make_token_df(tokens.cpu().flatten())\n",
        "token_df[\"feature\"] = hidden_acts[:, feature_id].detach().cpu().numpy()\n",
        "display(token_df.sort_values(\"feature\", ascending=False).head(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 711
        },
        "id": "UYT7m6vp4cPn",
        "outputId": "3ef8cbb2-c223-4582-d6e4-367f3d59c6b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature freq: 0.3856\n",
            "hidden_acts.shape torch.Size([128000, 512])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       str_tokens unique_token context  batch     pos     label    feature\n",
              "100938                 /100938    m||b      0  100938  0/100938  19.185392\n",
              "115878                 /115878    jT||      0  115878  0/115878  18.702106\n",
              "115832                 /115832  3Aj||j      0  115832  0/115832  18.427021\n",
              "33978                   /33978  N7I||z      0   33978   0/33978  18.078495\n",
              "24708                   /24708  0)4||6      0   24708   0/24708  18.064522\n",
              "53722                   /53722  4I8||0      0   53722   0/53722  17.986200\n",
              "77724                   /77724  83j||j      0   77724   0/77724  17.956104\n",
              "1776                     /1776  0qI||9      0    1776    0/1776  17.907314\n",
              "66768                   /66768  Rz4||.      0   66768   0/66768  17.892258\n",
              "100650                 /100650    j0||      0  100650  0/100650  17.744642\n",
              "74592                   /74592    A||8      0   74592   0/74592  17.661856\n",
              "40828                   /40828    qT||      0   40828   0/40828  17.600111\n",
              "104674                 /104674  4EI||z      0  104674  0/104674  17.566229\n",
              "53736                   /53736  bzp||z      0   53736   0/53736  17.553413\n",
              "37986                   /37986  j0f||q      0   37986   0/37986  17.310442\n",
              "62738                   /62738  80N||z      0   62738   0/62738  17.249142\n",
              "60256                   /60256  0T0||5      0   60256   0/60256  17.242119\n",
              "39714                   /39714  200||x      0   39714   0/39714  17.199339\n",
              "31858                   /31858  q08||q      0   31858   0/31858  17.125648\n",
              "2976                     /2976    l4||      0    2976    0/2976  17.110193"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab0fa902-e03e-4e32-8e09-59d4e262c947\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>str_tokens</th>\n",
              "      <th>unique_token</th>\n",
              "      <th>context</th>\n",
              "      <th>batch</th>\n",
              "      <th>pos</th>\n",
              "      <th>label</th>\n",
              "      <th>feature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100938</th>\n",
              "      <td></td>\n",
              "      <td>/100938</td>\n",
              "      <td>m||b</td>\n",
              "      <td>0</td>\n",
              "      <td>100938</td>\n",
              "      <td>0/100938</td>\n",
              "      <td>19.185392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115878</th>\n",
              "      <td></td>\n",
              "      <td>/115878</td>\n",
              "      <td>jT||</td>\n",
              "      <td>0</td>\n",
              "      <td>115878</td>\n",
              "      <td>0/115878</td>\n",
              "      <td>18.702106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115832</th>\n",
              "      <td></td>\n",
              "      <td>/115832</td>\n",
              "      <td>3Aj||j</td>\n",
              "      <td>0</td>\n",
              "      <td>115832</td>\n",
              "      <td>0/115832</td>\n",
              "      <td>18.427021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33978</th>\n",
              "      <td></td>\n",
              "      <td>/33978</td>\n",
              "      <td>N7I||z</td>\n",
              "      <td>0</td>\n",
              "      <td>33978</td>\n",
              "      <td>0/33978</td>\n",
              "      <td>18.078495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24708</th>\n",
              "      <td></td>\n",
              "      <td>/24708</td>\n",
              "      <td>0)4||6</td>\n",
              "      <td>0</td>\n",
              "      <td>24708</td>\n",
              "      <td>0/24708</td>\n",
              "      <td>18.064522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53722</th>\n",
              "      <td></td>\n",
              "      <td>/53722</td>\n",
              "      <td>4I8||0</td>\n",
              "      <td>0</td>\n",
              "      <td>53722</td>\n",
              "      <td>0/53722</td>\n",
              "      <td>17.986200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77724</th>\n",
              "      <td></td>\n",
              "      <td>/77724</td>\n",
              "      <td>83j||j</td>\n",
              "      <td>0</td>\n",
              "      <td>77724</td>\n",
              "      <td>0/77724</td>\n",
              "      <td>17.956104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1776</th>\n",
              "      <td></td>\n",
              "      <td>/1776</td>\n",
              "      <td>0qI||9</td>\n",
              "      <td>0</td>\n",
              "      <td>1776</td>\n",
              "      <td>0/1776</td>\n",
              "      <td>17.907314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66768</th>\n",
              "      <td></td>\n",
              "      <td>/66768</td>\n",
              "      <td>Rz4||.</td>\n",
              "      <td>0</td>\n",
              "      <td>66768</td>\n",
              "      <td>0/66768</td>\n",
              "      <td>17.892258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100650</th>\n",
              "      <td></td>\n",
              "      <td>/100650</td>\n",
              "      <td>j0||</td>\n",
              "      <td>0</td>\n",
              "      <td>100650</td>\n",
              "      <td>0/100650</td>\n",
              "      <td>17.744642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74592</th>\n",
              "      <td></td>\n",
              "      <td>/74592</td>\n",
              "      <td>A||8</td>\n",
              "      <td>0</td>\n",
              "      <td>74592</td>\n",
              "      <td>0/74592</td>\n",
              "      <td>17.661856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40828</th>\n",
              "      <td></td>\n",
              "      <td>/40828</td>\n",
              "      <td>qT||</td>\n",
              "      <td>0</td>\n",
              "      <td>40828</td>\n",
              "      <td>0/40828</td>\n",
              "      <td>17.600111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104674</th>\n",
              "      <td></td>\n",
              "      <td>/104674</td>\n",
              "      <td>4EI||z</td>\n",
              "      <td>0</td>\n",
              "      <td>104674</td>\n",
              "      <td>0/104674</td>\n",
              "      <td>17.566229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53736</th>\n",
              "      <td></td>\n",
              "      <td>/53736</td>\n",
              "      <td>bzp||z</td>\n",
              "      <td>0</td>\n",
              "      <td>53736</td>\n",
              "      <td>0/53736</td>\n",
              "      <td>17.553413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37986</th>\n",
              "      <td></td>\n",
              "      <td>/37986</td>\n",
              "      <td>j0f||q</td>\n",
              "      <td>0</td>\n",
              "      <td>37986</td>\n",
              "      <td>0/37986</td>\n",
              "      <td>17.310442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62738</th>\n",
              "      <td></td>\n",
              "      <td>/62738</td>\n",
              "      <td>80N||z</td>\n",
              "      <td>0</td>\n",
              "      <td>62738</td>\n",
              "      <td>0/62738</td>\n",
              "      <td>17.249142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60256</th>\n",
              "      <td></td>\n",
              "      <td>/60256</td>\n",
              "      <td>0T0||5</td>\n",
              "      <td>0</td>\n",
              "      <td>60256</td>\n",
              "      <td>0/60256</td>\n",
              "      <td>17.242119</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39714</th>\n",
              "      <td></td>\n",
              "      <td>/39714</td>\n",
              "      <td>200||x</td>\n",
              "      <td>0</td>\n",
              "      <td>39714</td>\n",
              "      <td>0/39714</td>\n",
              "      <td>17.199339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31858</th>\n",
              "      <td></td>\n",
              "      <td>/31858</td>\n",
              "      <td>q08||q</td>\n",
              "      <td>0</td>\n",
              "      <td>31858</td>\n",
              "      <td>0/31858</td>\n",
              "      <td>17.125648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2976</th>\n",
              "      <td></td>\n",
              "      <td>/2976</td>\n",
              "      <td>l4||</td>\n",
              "      <td>0</td>\n",
              "      <td>2976</td>\n",
              "      <td>0/2976</td>\n",
              "      <td>17.110193</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab0fa902-e03e-4e32-8e09-59d4e262c947')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ab0fa902-e03e-4e32-8e09-59d4e262c947 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ab0fa902-e03e-4e32-8e09-59d4e262c947');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-541a3fba-8b2d-458d-957f-e3dd3094c7df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-541a3fba-8b2d-458d-957f-e3dd3094c7df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-541a3fba-8b2d-458d-957f-e3dd3094c7df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "repr_error": "0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing Feature Activations"
      ],
      "metadata": {
        "id": "h-yvVk0v4cFG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the character-to-index and index-to-character mappings from the dataset\n",
        "char2idx = train_dataset.stoi  # Character to index mapping\n",
        "idx2char = train_dataset.itos  # Index to character mapping\n",
        "\n",
        "# Define the tokenization function using the dataset's mapping\n",
        "def tokenize_text(text):\n",
        "    # Map each character to its index, default to PAD token (0) for unknown characters\n",
        "    return [char2idx.get(ch, train_dataset.char_PAD_TOKEN) for ch in text]\n",
        "\n",
        "\n",
        "\n",
        "def make_feature_vis_gradio(feature_id, starting_text=None):\n",
        "    if starting_text is None:\n",
        "        starting_text = \"Sample text for visualization\"\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.HTML(value=f\"Hacky Interactive Neuroscope for cursivetransformer\")\n",
        "        # The input elements\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                text = gr.Textbox(label=\"Context Text\", value=starting_text)\n",
        "                feature_index = gr.Number(\n",
        "                    label=\"Feature Index\", value=feature_id, precision=0\n",
        "                )\n",
        "                max_val = gr.Number(label=\"Max Value\", value=None)\n",
        "                inputs = [text, feature_index, max_val]\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                # The output element\n",
        "                out = gr.HTML(label=\"Neuron Acts\", value=basic_feature_vis(feature_id))\n",
        "        def update_output(text, feature_index, max_val):\n",
        "            return basic_feature_vis(text, int(feature_index), max_val)\n",
        "        for inp in inputs:\n",
        "            inp.change(update_output, inputs, out)\n",
        "    demo.launch(share=True)\n",
        "\n",
        "# Visualize the feature activations\n",
        "starting_text = \"Sample text to test feature activations in cursivetransformer\"\n",
        "make_feature_vis_gradio(feature_id, starting_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "KvYERycr4bz5",
        "outputId": "875cd395-8199-4353-ec4f-10549eefd4bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://a3c04f1e10305d41f0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://a3c04f1e10305d41f0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p4o5BPGlB6iD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}